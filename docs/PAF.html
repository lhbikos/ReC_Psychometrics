<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Principal Axis Factoring | ReCentering Psych Stats: Psychometrics</title>
  <meta name="description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Principal Axis Factoring | ReCentering Psych Stats: Psychometrics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://lhbikos.github.io/ReC_Psychometrics/images/ReCenterPsychStats-Psychometrics-bookcover.png" />
  <meta property="og:description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="github-repo" content="lhbikos/ReC_Psychometrics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Principal Axis Factoring | ReCentering Psych Stats: Psychometrics" />
  
  <meta name="twitter:description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="twitter:image" content="https://lhbikos.github.io/ReC_Psychometrics/images/ReCenterPsychStats-Psychometrics-bookcover.png" />

<meta name="author" content="Lynette H. Bikos, PhD, ABPP (she/her)" />


<meta name="date" content="2024-03-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="PCA.html"/>
<link rel="next" href="confirmatory-factor-analysis-1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ReCentering Psych Stats: Psychometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BOOK COVER</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>PREFACE</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#copyright-with-open-access"><i class="fa fa-check"></i>Copyright with Open Access</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>ACKNOWLEDGEMENTS</a></li>
<li class="chapter" data-level="1" data-path="ReCintro.html"><a href="ReCintro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ReCintro.html"><a href="ReCintro.html#what-to-expect-in-each-chapter"><i class="fa fa-check"></i><b>1.1</b> What to expect in each chapter</a></li>
<li class="chapter" data-level="1.2" data-path="ReCintro.html"><a href="ReCintro.html#strategies-for-accessing-and-using-this-oer"><i class="fa fa-check"></i><b>1.2</b> Strategies for Accessing and Using this OER</a></li>
<li class="chapter" data-level="1.3" data-path="ReCintro.html"><a href="ReCintro.html#if-you-are-new-to-r"><i class="fa fa-check"></i><b>1.3</b> If You are New to R</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ReCintro.html"><a href="ReCintro.html#base-r"><i class="fa fa-check"></i><b>1.3.1</b> Base R</a></li>
<li class="chapter" data-level="1.3.2" data-path="ReCintro.html"><a href="ReCintro.html#r-studio"><i class="fa fa-check"></i><b>1.3.2</b> R Studio</a></li>
<li class="chapter" data-level="1.3.3" data-path="ReCintro.html"><a href="ReCintro.html#r-hygiene"><i class="fa fa-check"></i><b>1.3.3</b> R Hygiene</a></li>
<li class="chapter" data-level="1.3.4" data-path="ReCintro.html"><a href="ReCintro.html#troubleshooting-in-r-markdown"><i class="fa fa-check"></i><b>1.3.4</b> tRoubleshooting in R maRkdown</a></li>
<li class="chapter" data-level="1.3.5" data-path="ReCintro.html"><a href="ReCintro.html#strategies-for-success"><i class="fa fa-check"></i><b>1.3.5</b> stRategies for success</a></li>
<li class="chapter" data-level="1.3.6" data-path="ReCintro.html"><a href="ReCintro.html#resources-for-getting-started"><i class="fa fa-check"></i><b>1.3.6</b> Resources for getting staRted</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="QuestCon.html"><a href="QuestCon.html"><i class="fa fa-check"></i><b>2</b> Questionnaire Construction: The Fundamentals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="QuestCon.html"><a href="QuestCon.html#navigating-this-lesson"><i class="fa fa-check"></i><b>2.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="QuestCon.html"><a href="QuestCon.html#learning-objectives"><i class="fa fa-check"></i><b>2.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.1.2" data-path="QuestCon.html"><a href="QuestCon.html#planning-for-practice"><i class="fa fa-check"></i><b>2.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="2.1.3" data-path="QuestCon.html"><a href="QuestCon.html#readings-resources"><i class="fa fa-check"></i><b>2.1.3</b> Readings &amp; Resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="QuestCon.html"><a href="QuestCon.html#components-of-the-questionnaire"><i class="fa fa-check"></i><b>2.2</b> Components of the Questionnaire</a></li>
<li class="chapter" data-level="2.3" data-path="QuestCon.html"><a href="QuestCon.html#what-improves-or-threatens-response-rates-and-bias"><i class="fa fa-check"></i><b>2.3</b> What Improves (or Threatens) Response Rates and Bias?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="QuestCon.html"><a href="QuestCon.html#should-likert-type-scales-include-a-midpoint"><i class="fa fa-check"></i><b>2.3.1</b> Should Likert-type scales include a midpoint?</a></li>
<li class="chapter" data-level="2.3.2" data-path="QuestCon.html"><a href="QuestCon.html#should-continuous-rating-scales-be-used-in-surveys"><i class="fa fa-check"></i><b>2.3.2</b> Should <em>continuous rating scales</em> be used in surveys?</a></li>
<li class="chapter" data-level="2.3.3" data-path="QuestCon.html"><a href="QuestCon.html#should-likert-type-response-options-use-an-ascending-or-descending-order"><i class="fa fa-check"></i><b>2.3.3</b> Should Likert-type response options use an ascending or descending order?</a></li>
<li class="chapter" data-level="2.3.4" data-path="QuestCon.html"><a href="QuestCon.html#should-surveys-include-negatively-worded-items"><i class="fa fa-check"></i><b>2.3.4</b> Should surveys include negatively worded items?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="QuestCon.html"><a href="QuestCon.html#construct-specific-guidance"><i class="fa fa-check"></i><b>2.4</b> Construct-specific guidance</a></li>
<li class="chapter" data-level="2.5" data-path="QuestCon.html"><a href="QuestCon.html#surveying-in-the-online-environment"><i class="fa fa-check"></i><b>2.5</b> Surveying in the Online Environment</a></li>
<li class="chapter" data-level="2.6" data-path="QuestCon.html"><a href="QuestCon.html#in-my-surveys"><i class="fa fa-check"></i><b>2.6</b> In my Surveys</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="QuestCon.html"><a href="QuestCon.html#demographics-and-background-information"><i class="fa fa-check"></i><b>2.6.1</b> Demographics and Background Information</a></li>
<li class="chapter" data-level="2.6.2" data-path="QuestCon.html"><a href="QuestCon.html#survey-order"><i class="fa fa-check"></i><b>2.6.2</b> Survey Order</a></li>
<li class="chapter" data-level="2.6.3" data-path="QuestCon.html"><a href="QuestCon.html#forced-responses"><i class="fa fa-check"></i><b>2.6.3</b> Forced Responses</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="QuestCon.html"><a href="QuestCon.html#practice-problems"><i class="fa fa-check"></i><b>2.7</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="qualTRIX.html"><a href="qualTRIX.html"><i class="fa fa-check"></i><b>3</b> Be a QualTRIXter</a>
<ul>
<li class="chapter" data-level="3.1" data-path="qualTRIX.html"><a href="qualTRIX.html#navigating-this-lesson-1"><i class="fa fa-check"></i><b>3.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="qualTRIX.html"><a href="qualTRIX.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="qualTRIX.html"><a href="qualTRIX.html#planning-for-practice-1"><i class="fa fa-check"></i><b>3.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="3.1.3" data-path="qualTRIX.html"><a href="qualTRIX.html#readings-resources-1"><i class="fa fa-check"></i><b>3.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="3.1.4" data-path="qualTRIX.html"><a href="qualTRIX.html#packages-1"><i class="fa fa-check"></i><b>3.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="qualTRIX.html"><a href="qualTRIX.html#research-vignette"><i class="fa fa-check"></i><b>3.2</b> Research Vignette</a></li>
<li class="chapter" data-level="3.3" data-path="qualTRIX.html"><a href="qualTRIX.html#qualtrics-essentials"><i class="fa fa-check"></i><b>3.3</b> Qualtrics Essentials</a></li>
<li class="chapter" data-level="3.4" data-path="qualTRIX.html"><a href="qualTRIX.html#qual-trix"><i class="fa fa-check"></i><b>3.4</b> Qual-TRIX</a></li>
<li class="chapter" data-level="3.5" data-path="qualTRIX.html"><a href="qualTRIX.html#even-more-particularly-relevant-to-irb"><i class="fa fa-check"></i><b>3.5</b> Even moRe, particularly relevant to iRb</a></li>
<li class="chapter" data-level="3.6" data-path="qualTRIX.html"><a href="qualTRIX.html#intravenous-qualtrics"><i class="fa fa-check"></i><b>3.6</b> intRavenous Qualtrics</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="qualTRIX.html"><a href="qualTRIX.html#the-codebook"><i class="fa fa-check"></i><b>3.6.1</b> The Codebook</a></li>
<li class="chapter" data-level="3.6.2" data-path="qualTRIX.html"><a href="qualTRIX.html#using-data-from-an-exported-qualtrics-.csv-file"><i class="fa fa-check"></i><b>3.6.2</b> Using data from an exported Qualtrics .csv file</a></li>
<li class="chapter" data-level="3.6.3" data-path="qualTRIX.html"><a href="qualTRIX.html#tweaking-data-format"><i class="fa fa-check"></i><b>3.6.3</b> Tweaking Data Format</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="qualTRIX.html"><a href="qualTRIX.html#practice-problems-1"><i class="fa fa-check"></i><b>3.7</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="rxy.html"><a href="rxy.html"><i class="fa fa-check"></i><b>4</b> Psychometric Validity: Basic Concepts</a>
<ul>
<li class="chapter" data-level="4.1" data-path="rxy.html"><a href="rxy.html#navigating-this-lesson-2"><i class="fa fa-check"></i><b>4.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="rxy.html"><a href="rxy.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.1.2" data-path="rxy.html"><a href="rxy.html#planning-for-practice-2"><i class="fa fa-check"></i><b>4.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="4.1.3" data-path="rxy.html"><a href="rxy.html#readings-resources-2"><i class="fa fa-check"></i><b>4.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="4.1.4" data-path="rxy.html"><a href="rxy.html#packages-2"><i class="fa fa-check"></i><b>4.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="rxy.html"><a href="rxy.html#research-vignette-1"><i class="fa fa-check"></i><b>4.2</b> Research Vignette</a></li>
<li class="chapter" data-level="4.3" data-path="rxy.html"><a href="rxy.html#fundamentals-of-validity"><i class="fa fa-check"></i><b>4.3</b> Fundamentals of Validity</a></li>
<li class="chapter" data-level="4.4" data-path="rxy.html"><a href="rxy.html#validity-criteria"><i class="fa fa-check"></i><b>4.4</b> Validity Criteria</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="rxy.html"><a href="rxy.html#content-validity"><i class="fa fa-check"></i><b>4.4.1</b> Content Validity</a></li>
<li class="chapter" data-level="4.4.2" data-path="rxy.html"><a href="rxy.html#face-validity-the-unvalidity"><i class="fa fa-check"></i><b>4.4.2</b> Face Validity: The “Un”validity</a></li>
<li class="chapter" data-level="4.4.3" data-path="rxy.html"><a href="rxy.html#criterion-related-validity"><i class="fa fa-check"></i><b>4.4.3</b> Criterion-Related Validity</a></li>
<li class="chapter" data-level="4.4.4" data-path="rxy.html"><a href="rxy.html#construct-validity"><i class="fa fa-check"></i><b>4.4.4</b> Construct Validity</a></li>
<li class="chapter" data-level="4.4.5" data-path="rxy.html"><a href="rxy.html#internal-consistency"><i class="fa fa-check"></i><b>4.4.5</b> Internal Consistency</a></li>
<li class="chapter" data-level="4.4.6" data-path="rxy.html"><a href="rxy.html#structural-validity"><i class="fa fa-check"></i><b>4.4.6</b> Structural Validity</a></li>
<li class="chapter" data-level="4.4.7" data-path="rxy.html"><a href="rxy.html#experimental-interventions"><i class="fa fa-check"></i><b>4.4.7</b> Experimental Interventions</a></li>
<li class="chapter" data-level="4.4.8" data-path="rxy.html"><a href="rxy.html#convergent-and-discriminant-validity"><i class="fa fa-check"></i><b>4.4.8</b> Convergent and Discriminant Validity</a></li>
<li class="chapter" data-level="4.4.9" data-path="rxy.html"><a href="rxy.html#incremental-validity"><i class="fa fa-check"></i><b>4.4.9</b> Incremental Validity</a></li>
<li class="chapter" data-level="4.4.10" data-path="rxy.html"><a href="rxy.html#considering-the-individual-and-social-consequences-of-testing"><i class="fa fa-check"></i><b>4.4.10</b> Considering the Individual and Social Consequences of Testing</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="rxy.html"><a href="rxy.html#factors-affecting-validity-coefficients"><i class="fa fa-check"></i><b>4.5</b> Factors Affecting Validity Coefficients</a></li>
<li class="chapter" data-level="4.6" data-path="rxy.html"><a href="rxy.html#practice-problems-2"><i class="fa fa-check"></i><b>4.6</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="rxy.html"><a href="rxy.html#problem-1-play-around-with-this-simulation."><i class="fa fa-check"></i><b>4.6.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="4.6.2" data-path="rxy.html"><a href="rxy.html#problem-2-conduct-the-reliability-analysis-selecting-different-variables."><i class="fa fa-check"></i><b>4.6.2</b> Problem #2: Conduct the reliability analysis selecting different variables.</a></li>
<li class="chapter" data-level="4.6.3" data-path="rxy.html"><a href="rxy.html#problem-3-try-something-entirely-new."><i class="fa fa-check"></i><b>4.6.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="4.6.4" data-path="rxy.html"><a href="rxy.html#grading-rubric"><i class="fa fa-check"></i><b>4.6.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rxy.html"><a href="rxy.html#homeworked-example"><i class="fa fa-check"></i><b>4.7</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="rxy.html"><a href="rxy.html#check-and-if-needed-format-data"><i class="fa fa-check"></i><b>4.7.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="4.7.2" data-path="rxy.html"><a href="rxy.html#create-a-correlation-matrix-that-includes-the-instrument-of-interest-and-the-variables-that-will-have-varying-degrees-of-relation"><i class="fa fa-check"></i><b>4.7.2</b> Create a correlation matrix that includes the instrument-of-interest and the variables that will have varying degrees of relation</a></li>
<li class="chapter" data-level="4.7.3" data-path="rxy.html"><a href="rxy.html#with-convergent-and-discriminant-validity-in-mind-interpret-the-validity-coefficients-this-should-include-an-assessment-about-whether-the-correlation-coefficients-at-least-two-different-pairings-are-statistically-significantly-different-from-each-other."><i class="fa fa-check"></i><b>4.7.3</b> With convergent and discriminant validity in mind, interpret the validity coefficients; this should include an assessment about whether the correlation coefficients (at least two different pairings) are statistically significantly different from each other.</a></li>
<li class="chapter" data-level="4.7.4" data-path="rxy.html"><a href="rxy.html#with-at-least-three-variables-evaluate-the-degree-to-which-the-instrument-demonstrates-incremental-validity-this-should-involve-two-regression-equations-and-their-statistical-comparison"><i class="fa fa-check"></i><b>4.7.4</b> With at least three variables, evaluate the degree to which the instrument demonstrates incremental validity (this should involve two regression equations and their statistical comparison)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rxx.html"><a href="rxx.html"><i class="fa fa-check"></i><b>5</b> Reliability</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rxx.html"><a href="rxx.html#navigating-this-lesson-3"><i class="fa fa-check"></i><b>5.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="rxx.html"><a href="rxx.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.1.2" data-path="rxx.html"><a href="rxx.html#planning-for-practice-3"><i class="fa fa-check"></i><b>5.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="5.1.3" data-path="rxx.html"><a href="rxx.html#readings-resources-3"><i class="fa fa-check"></i><b>5.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="5.1.4" data-path="rxx.html"><a href="rxx.html#packages-3"><i class="fa fa-check"></i><b>5.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="rxx.html"><a href="rxx.html#defining-reliability"><i class="fa fa-check"></i><b>5.2</b> Defining Reliability</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="rxx.html"><a href="rxx.html#begins-with-classical-test-theory-ctt"><i class="fa fa-check"></i><b>5.2.1</b> Begins with Classical Test Theory (CTT)</a></li>
<li class="chapter" data-level="5.2.2" data-path="rxx.html"><a href="rxx.html#why-are-we-concerned-with-reliability-error"><i class="fa fa-check"></i><b>5.2.2</b> Why are we concerned with reliability? Error!</a></li>
<li class="chapter" data-level="5.2.3" data-path="rxx.html"><a href="rxx.html#the-reliability-coefficient"><i class="fa fa-check"></i><b>5.2.3</b> The Reliability Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="rxx.html"><a href="rxx.html#research-vignette-2"><i class="fa fa-check"></i><b>5.3</b> Research Vignette</a></li>
<li class="chapter" data-level="5.4" data-path="rxx.html"><a href="rxx.html#a-parade-of-reliability-coefficients"><i class="fa fa-check"></i><b>5.4</b> A Parade of Reliability Coefficients</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rxx.html"><a href="rxx.html#reliability-options-for-a-single-administration"><i class="fa fa-check"></i><b>5.4.1</b> Reliability Options for a Single Administration</a></li>
<li class="chapter" data-level="5.4.2" data-path="rxx.html"><a href="rxx.html#reliability-options-for-two-or-more-administrations"><i class="fa fa-check"></i><b>5.4.2</b> Reliability Options for Two or more Administrations</a></li>
<li class="chapter" data-level="5.4.3" data-path="rxx.html"><a href="rxx.html#interrater-reliability"><i class="fa fa-check"></i><b>5.4.3</b> Interrater Reliability</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rxx.html"><a href="rxx.html#what-do-we-do-with-these-coefficients"><i class="fa fa-check"></i><b>5.5</b> What do we do with these coefficients?</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="rxx.html"><a href="rxx.html#corrections-for-attenuation"><i class="fa fa-check"></i><b>5.5.1</b> Corrections for attenuation</a></li>
<li class="chapter" data-level="5.5.2" data-path="rxx.html"><a href="rxx.html#predicting-true-scores-and-their-cis"><i class="fa fa-check"></i><b>5.5.2</b> Predicting true scores (and their CIs)</a></li>
<li class="chapter" data-level="5.5.3" data-path="rxx.html"><a href="rxx.html#how-do-i-keep-it-all-straight"><i class="fa fa-check"></i><b>5.5.3</b> How do I keep it all straight?</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rxx.html"><a href="rxx.html#practice-problems-3"><i class="fa fa-check"></i><b>5.6</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="rxx.html"><a href="rxx.html#problem-1-play-around-with-this-simulation.-1"><i class="fa fa-check"></i><b>5.6.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="5.6.2" data-path="rxx.html"><a href="rxx.html#problem-2-use-the-data-from-the-live-recentering-psych-stats-survey."><i class="fa fa-check"></i><b>5.6.2</b> Problem #2: Use the data from the live ReCentering Psych Stats survey.</a></li>
<li class="chapter" data-level="5.6.3" data-path="rxx.html"><a href="rxx.html#problem-3-try-something-entirely-new.-1"><i class="fa fa-check"></i><b>5.6.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="5.6.4" data-path="rxx.html"><a href="rxx.html#grading-rubric-1"><i class="fa fa-check"></i><b>5.6.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="rxx.html"><a href="rxx.html#homeworked-example-1"><i class="fa fa-check"></i><b>5.7</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="rxx.html"><a href="rxx.html#check-and-if-needed-format-the-data"><i class="fa fa-check"></i><b>5.7.1</b> Check and, if needed, format the data</a></li>
<li class="chapter" data-level="5.7.2" data-path="rxx.html"><a href="rxx.html#calculate-and-report-the-alpha-coefficient-for-a-total-scale-score-and-subscales-if-the-scale-has-them"><i class="fa fa-check"></i><b>5.7.2</b> Calculate and report the alpha coefficient for a total scale score and subscales (if the scale has them)</a></li>
<li class="chapter" data-level="5.7.3" data-path="rxx.html"><a href="rxx.html#subscale-alphas"><i class="fa fa-check"></i><b>5.7.3</b> Subscale alphas</a></li>
<li class="chapter" data-level="5.7.4" data-path="rxx.html"><a href="rxx.html#calculate-and-report-ωt-and-ωh"><i class="fa fa-check"></i><b>5.7.4</b> Calculate and report ωt and ωh</a></li>
<li class="chapter" data-level="5.7.5" data-path="rxx.html"><a href="rxx.html#with-these-two-determine-what-proportion-of-the-variance-is-due-to-all-the-factors-error-and-g."><i class="fa fa-check"></i><b>5.7.5</b> With these two determine what proportion of the variance is due to all the factors, error, and g.</a></li>
<li class="chapter" data-level="5.7.6" data-path="rxx.html"><a href="rxx.html#calculate-total-and-subscale-scores."><i class="fa fa-check"></i><b>5.7.6</b> Calculate total and subscale scores.</a></li>
<li class="chapter" data-level="5.7.7" data-path="rxx.html"><a href="rxx.html#describe-other-reliability-estimates-that-would-be-appropriate-for-the-measure-you-are-evaluating."><i class="fa fa-check"></i><b>5.7.7</b> Describe other reliability estimates that would be appropriate for the measure you are evaluating.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html"><i class="fa fa-check"></i><b>6</b> Item Analysis for Educational Achievement Tests (Exams)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#navigating-this-lesson-4"><i class="fa fa-check"></i><b>6.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.1.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#planning-for-practice-4"><i class="fa fa-check"></i><b>6.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="6.1.3" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#readings-resources-4"><i class="fa fa-check"></i><b>6.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="6.1.4" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#packages-4"><i class="fa fa-check"></i><b>6.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#research-vignette-3"><i class="fa fa-check"></i><b>6.2</b> Research Vignette</a></li>
<li class="chapter" data-level="6.3" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-analysis-in-the-educationalachievement-context"><i class="fa fa-check"></i><b>6.3</b> Item Analysis in the Educational/Achievement Context</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#and-now-a-quiz-please-take-it."><i class="fa fa-check"></i><b>6.3.1</b> And now a quiz! Please take it.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-difficulty"><i class="fa fa-check"></i><b>6.4</b> Item Difficulty</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#percent-passing"><i class="fa fa-check"></i><b>6.4.1</b> Percent passing</a></li>
<li class="chapter" data-level="6.4.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#several-factors-prevent-.50-from-being-the-ideal-difficulty-level"><i class="fa fa-check"></i><b>6.4.2</b> Several factors prevent .50 from being the ideal difficulty level</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-discrimination"><i class="fa fa-check"></i><b>6.5</b> Item Discrimination</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#index-of-discrimination"><i class="fa fa-check"></i><b>6.5.1</b> Index of Discrimination</a></li>
<li class="chapter" data-level="6.5.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#application-of-item-difficulty-and-discrimination"><i class="fa fa-check"></i><b>6.5.2</b> Application of Item Difficulty and Discrimination</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#in-the-psych-package"><i class="fa fa-check"></i><b>6.6</b> In the <em>psych</em> Package</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#a-mini-introduction-to-irt"><i class="fa fa-check"></i><b>6.6.1</b> A Mini-Introduction to IRT</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#closing-thoughts-on-developing-measures-in-the-educationachievement-context"><i class="fa fa-check"></i><b>6.7</b> Closing Thoughts on Developing Measures in the Education/Achievement Context</a></li>
<li class="chapter" data-level="6.8" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#practice-problems-4"><i class="fa fa-check"></i><b>6.8</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html"><i class="fa fa-check"></i><b>7</b> Item Analysis for Likert Type Scale Construction</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#navigating-this-lesson-5"><i class="fa fa-check"></i><b>7.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.1.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#planning-for-practice-5"><i class="fa fa-check"></i><b>7.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="7.1.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#readings-resources-5"><i class="fa fa-check"></i><b>7.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="7.1.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#packages-5"><i class="fa fa-check"></i><b>7.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#introducing-item-analysis-for-survey-development"><i class="fa fa-check"></i><b>7.2</b> Introducing Item Analysis for Survey Development</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#workflow-for-item-analysis"><i class="fa fa-check"></i><b>7.2.1</b> Workflow for Item Analysis</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#research-vignette-4"><i class="fa fa-check"></i><b>7.3</b> Research Vignette</a></li>
<li class="chapter" data-level="7.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-i-corrected-item-total-correlations"><i class="fa fa-check"></i><b>7.4</b> Step I: Corrected item-total correlations</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#data-prep"><i class="fa fa-check"></i><b>7.4.1</b> Data Prep</a></li>
<li class="chapter" data-level="7.4.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#calculating-item-total-correlation-coefficients"><i class="fa fa-check"></i><b>7.4.2</b> Calculating Item-Total Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-ii-correlating-items-with-other-scale-totals"><i class="fa fa-check"></i><b>7.5</b> Step II: Correlating Items with Other Scale Totals</a></li>
<li class="chapter" data-level="7.6" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-iii-interpreting-and-writing-up-the-results"><i class="fa fa-check"></i><b>7.6</b> Step III: Interpreting and Writing up the Results</a></li>
<li class="chapter" data-level="7.7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#a-conversation-with-dr.-szymanski"><i class="fa fa-check"></i><b>7.7</b> A Conversation with Dr. Szymanski</a></li>
<li class="chapter" data-level="7.8" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#practice-problems-5"><i class="fa fa-check"></i><b>7.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-1-play-around-with-this-simulation.-2"><i class="fa fa-check"></i><b>7.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="7.8.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-2-use-raw-data-from-the-recentering-psych-stats-survey-on-qualtrics."><i class="fa fa-check"></i><b>7.8.2</b> Problem #2: Use raw data from the ReCentering Psych Stats survey on Qualtrics.</a></li>
<li class="chapter" data-level="7.8.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-3-try-something-entirely-new.-2"><i class="fa fa-check"></i><b>7.8.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="7.8.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#grading-rubric-2"><i class="fa fa-check"></i><b>7.8.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#bonus-reel"><i class="fa fa-check"></i><b>7.9</b> Bonus Reel:</a></li>
<li class="chapter" data-level="7.10" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#homeworked-example-2"><i class="fa fa-check"></i><b>7.10</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#check-and-if-needed-format-and-score-data"><i class="fa fa-check"></i><b>7.10.1</b> Check and, if needed, format and score data</a></li>
<li class="chapter" data-level="7.10.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#report-alpha-coefficients-and-average-inter-item-correlations-for-the-total-and-subscales"><i class="fa fa-check"></i><b>7.10.2</b> Report alpha coefficients and average inter-item correlations for the total and subscales</a></li>
<li class="chapter" data-level="7.10.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#produce-and-interpret-corrected-item-total-correlations-for-total-and-subscales-separately"><i class="fa fa-check"></i><b>7.10.3</b> Produce and interpret corrected item-total correlations for total and subscales, separately</a></li>
<li class="chapter" data-level="7.10.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#produce-and-interpret-correlations-between-the-individual-items-of-a-given-subscale-and-the-subscale-scores-of-all-other-subscales"><i class="fa fa-check"></i><b>7.10.4</b> Produce and interpret correlations between the individual items of a given subscale and the subscale scores of all other subscales</a></li>
<li class="chapter" data-level="7.10.5" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#traditional-pedagogy-items-1"><i class="fa fa-check"></i><b>7.10.5</b> Traditional Pedagogy Items</a></li>
<li class="chapter" data-level="7.10.6" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#apa-style-results-section-with-table"><i class="fa fa-check"></i><b>7.10.6</b> APA style results section with table</a></li>
<li class="chapter" data-level="7.10.7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#explanation-to-grader"><i class="fa fa-check"></i><b>7.10.7</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="exploratory-factor-analysis-1.html"><a href="exploratory-factor-analysis-1.html"><i class="fa fa-check"></i>EXPLORATORY <em>FACTOR</em> ANALYSIS</a></li>
<li class="chapter" data-level="8" data-path="PCA.html"><a href="PCA.html"><i class="fa fa-check"></i><b>8</b> Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="PCA.html"><a href="PCA.html#navigating-this-lesson-6"><i class="fa fa-check"></i><b>8.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="PCA.html"><a href="PCA.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.1.2" data-path="PCA.html"><a href="PCA.html#planning-for-practice-6"><i class="fa fa-check"></i><b>8.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="8.1.3" data-path="PCA.html"><a href="PCA.html#readings-resources-6"><i class="fa fa-check"></i><b>8.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="8.1.4" data-path="PCA.html"><a href="PCA.html#packages-6"><i class="fa fa-check"></i><b>8.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="PCA.html"><a href="PCA.html#exploratory-principal-components-analysis"><i class="fa fa-check"></i><b>8.2</b> Exploratory Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="PCA.html"><a href="PCA.html#some-framing-ideas-in-very-lay-terms"><i class="fa fa-check"></i><b>8.2.1</b> Some Framing Ideas (in very lay terms)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="PCA.html"><a href="PCA.html#pca-workflow"><i class="fa fa-check"></i><b>8.3</b> PCA Workflow</a></li>
<li class="chapter" data-level="8.4" data-path="PCA.html"><a href="PCA.html#research-vignette-5"><i class="fa fa-check"></i><b>8.4</b> Research Vignette</a></li>
<li class="chapter" data-level="8.5" data-path="PCA.html"><a href="PCA.html#working-the-vignette"><i class="fa fa-check"></i><b>8.5</b> Working the Vignette</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="PCA.html"><a href="PCA.html#three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factor-analysis"><i class="fa fa-check"></i><b>8.5.1</b> Three Diagnostic Tests to Evaluate the Appropriateness of the Data for Component-or-Factor Analysis</a></li>
<li class="chapter" data-level="8.5.2" data-path="PCA.html"><a href="PCA.html#principal-components-analysis"><i class="fa fa-check"></i><b>8.5.2</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="8.5.3" data-path="PCA.html"><a href="PCA.html#specifying-the-number-of-components"><i class="fa fa-check"></i><b>8.5.3</b> Specifying the Number of Components</a></li>
<li class="chapter" data-level="8.5.4" data-path="PCA.html"><a href="PCA.html#component-rotation"><i class="fa fa-check"></i><b>8.5.4</b> Component Rotation</a></li>
<li class="chapter" data-level="8.5.5" data-path="PCA.html"><a href="PCA.html#component-scores"><i class="fa fa-check"></i><b>8.5.5</b> Component Scores</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="PCA.html"><a href="PCA.html#apa-style-results"><i class="fa fa-check"></i><b>8.6</b> APA Style Results</a></li>
<li class="chapter" data-level="8.7" data-path="PCA.html"><a href="PCA.html#back-to-the-future-the-relationship-between-pca-and-item-analysis"><i class="fa fa-check"></i><b>8.7</b> Back to the FutuRe: The relationship between PCA and item analysis</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="PCA.html"><a href="PCA.html#calculating-and-extracting-item-total-correlation-coefficients"><i class="fa fa-check"></i><b>8.7.1</b> Calculating and Extracting Item-Total Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="PCA.html"><a href="PCA.html#practice-problems-6"><i class="fa fa-check"></i><b>8.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="PCA.html"><a href="PCA.html#problem-1-play-around-with-this-simulation.-3"><i class="fa fa-check"></i><b>8.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="8.8.2" data-path="PCA.html"><a href="PCA.html#problem-2-conduct-a-pca-with-another-simulated-set-of-data-in-the-oer."><i class="fa fa-check"></i><b>8.8.2</b> Problem #2: Conduct a PCA with another simulated set of data in the OER.</a></li>
<li class="chapter" data-level="8.8.3" data-path="PCA.html"><a href="PCA.html#problem-3-try-something-entirely-new.-3"><i class="fa fa-check"></i><b>8.8.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="8.8.4" data-path="PCA.html"><a href="PCA.html#grading-rubric-3"><i class="fa fa-check"></i><b>8.8.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="PCA.html"><a href="PCA.html#homeworked-example-3"><i class="fa fa-check"></i><b>8.9</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="PCA.html"><a href="PCA.html#check-and-if-needed-format-data-1"><i class="fa fa-check"></i><b>8.9.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="8.9.2" data-path="PCA.html"><a href="PCA.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant"><i class="fa fa-check"></i><b>8.9.2</b> Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant)</a></li>
<li class="chapter" data-level="8.9.3" data-path="PCA.html"><a href="PCA.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory"><i class="fa fa-check"></i><b>8.9.3</b> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)</a></li>
<li class="chapter" data-level="8.9.4" data-path="PCA.html"><a href="PCA.html#conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>8.9.4</b> Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="8.9.5" data-path="PCA.html"><a href="PCA.html#conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>8.9.5</b> Conduct an oblique extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="8.9.6" data-path="PCA.html"><a href="PCA.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest"><i class="fa fa-check"></i><b>8.9.6</b> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest</a></li>
<li class="chapter" data-level="8.9.7" data-path="PCA.html"><a href="PCA.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions"><i class="fa fa-check"></i><b>8.9.7</b> APA style results section with table and figure of one of the solutions</a></li>
<li class="chapter" data-level="8.9.8" data-path="PCA.html"><a href="PCA.html#explanation-to-grader-1"><i class="fa fa-check"></i><b>8.9.8</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="PAF.html"><a href="PAF.html"><i class="fa fa-check"></i><b>9</b> Principal Axis Factoring</a>
<ul>
<li class="chapter" data-level="9.1" data-path="PAF.html"><a href="PAF.html#navigating-this-lesson-7"><i class="fa fa-check"></i><b>9.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="PAF.html"><a href="PAF.html#learning-objectives-7"><i class="fa fa-check"></i><b>9.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="9.1.2" data-path="PAF.html"><a href="PAF.html#planning-for-practice-7"><i class="fa fa-check"></i><b>9.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="9.1.3" data-path="PAF.html"><a href="PAF.html#readings-resources-7"><i class="fa fa-check"></i><b>9.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="9.1.4" data-path="PAF.html"><a href="PAF.html#packages-7"><i class="fa fa-check"></i><b>9.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="PAF.html"><a href="PAF.html#exploratory-factor-analysis-with-a-quick-contrast-to-pca"><i class="fa fa-check"></i><b>9.2</b> Exploratory Factor Analysis (with a quick contrast to PCA)</a></li>
<li class="chapter" data-level="9.3" data-path="PAF.html"><a href="PAF.html#paf-workflow"><i class="fa fa-check"></i><b>9.3</b> PAF Workflow</a></li>
<li class="chapter" data-level="9.4" data-path="PAF.html"><a href="PAF.html#research-vignette-6"><i class="fa fa-check"></i><b>9.4</b> Research Vignette</a></li>
<li class="chapter" data-level="9.5" data-path="PAF.html"><a href="PAF.html#working-the-vignette-1"><i class="fa fa-check"></i><b>9.5</b> Working the Vignette</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="PAF.html"><a href="PAF.html#data-prep-1"><i class="fa fa-check"></i><b>9.5.1</b> Data Prep</a></li>
<li class="chapter" data-level="9.5.2" data-path="PAF.html"><a href="PAF.html#principal-axis-factoring-paf"><i class="fa fa-check"></i><b>9.5.2</b> Principal Axis Factoring (PAF)</a></li>
<li class="chapter" data-level="9.5.3" data-path="PAF.html"><a href="PAF.html#factor-rotation"><i class="fa fa-check"></i><b>9.5.3</b> Factor Rotation</a></li>
<li class="chapter" data-level="9.5.4" data-path="PAF.html"><a href="PAF.html#factor-scores"><i class="fa fa-check"></i><b>9.5.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="PAF.html"><a href="PAF.html#apa-style-results-1"><i class="fa fa-check"></i><b>9.6</b> APA Style Results</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="PAF.html"><a href="PAF.html#comparing-fa-and-pca"><i class="fa fa-check"></i><b>9.6.1</b> Comparing FA and PCA</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="PAF.html"><a href="PAF.html#going-back-to-the-future-what-then-is-omega"><i class="fa fa-check"></i><b>9.7</b> Going Back to the Future: What, then, is Omega?</a></li>
<li class="chapter" data-level="9.8" data-path="PAF.html"><a href="PAF.html#comparing-pfa-to-item-analysis-and-pca"><i class="fa fa-check"></i><b>9.8</b> Comparing PFA to Item Analysis and PCA</a></li>
<li class="chapter" data-level="9.9" data-path="PAF.html"><a href="PAF.html#practice-problems-7"><i class="fa fa-check"></i><b>9.9</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="PAF.html"><a href="PAF.html#problem-1-play-around-with-this-simulation.-4"><i class="fa fa-check"></i><b>9.9.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="9.9.2" data-path="PAF.html"><a href="PAF.html#problem-2-conduct-a-pca-with-the-szymanski-and-bissonette--szymanski_perceptions_2020-research-vignette-that-was-used-in-prior-lessons."><i class="fa fa-check"></i><b>9.9.2</b> Problem #2: Conduct a PCA with the Szymanski and Bissonette <span class="citation">(2020)</span> research vignette that was used in prior lessons.</a></li>
<li class="chapter" data-level="9.9.3" data-path="PAF.html"><a href="PAF.html#problem-3-try-something-entirely-new.-4"><i class="fa fa-check"></i><b>9.9.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="9.9.4" data-path="PAF.html"><a href="PAF.html#grading-rubric-4"><i class="fa fa-check"></i><b>9.9.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="PAF.html"><a href="PAF.html#homeworked-example-4"><i class="fa fa-check"></i><b>9.10</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="PAF.html"><a href="PAF.html#check-and-if-needed-format-data-2"><i class="fa fa-check"></i><b>9.10.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="9.10.2" data-path="PAF.html"><a href="PAF.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant-1"><i class="fa fa-check"></i><b>9.10.2</b> Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant)</a></li>
<li class="chapter" data-level="9.10.3" data-path="PAF.html"><a href="PAF.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory-1"><i class="fa fa-check"></i><b>9.10.3</b> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)</a></li>
<li class="chapter" data-level="9.10.4" data-path="PAF.html"><a href="PAF.html#conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1"><i class="fa fa-check"></i><b>9.10.4</b> Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="9.10.5" data-path="PAF.html"><a href="PAF.html#conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1"><i class="fa fa-check"></i><b>9.10.5</b> Conduct an oblique extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="9.10.6" data-path="PAF.html"><a href="PAF.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest-1"><i class="fa fa-check"></i><b>9.10.6</b> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest</a></li>
<li class="chapter" data-level="9.10.7" data-path="PAF.html"><a href="PAF.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions-1"><i class="fa fa-check"></i><b>9.10.7</b> APA style results section with table and figure of one of the solutions</a></li>
<li class="chapter" data-level="9.10.8" data-path="PAF.html"><a href="PAF.html#explanation-to-grader-2"><i class="fa fa-check"></i><b>9.10.8</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="confirmatory-factor-analysis-1.html"><a href="confirmatory-factor-analysis-1.html"><i class="fa fa-check"></i>Confirmatory Factor Analysis</a></li>
<li class="chapter" data-level="10" data-path="CFA1st.html"><a href="CFA1st.html"><i class="fa fa-check"></i><b>10</b> CFA: First Order Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="CFA1st.html"><a href="CFA1st.html#navigating-this-lesson-8"><i class="fa fa-check"></i><b>10.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="CFA1st.html"><a href="CFA1st.html#learning-objectives-8"><i class="fa fa-check"></i><b>10.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.1.2" data-path="CFA1st.html"><a href="CFA1st.html#planning-for-practice-8"><i class="fa fa-check"></i><b>10.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="10.1.3" data-path="CFA1st.html"><a href="CFA1st.html#readings-resources-8"><i class="fa fa-check"></i><b>10.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="10.1.4" data-path="CFA1st.html"><a href="CFA1st.html#packages-8"><i class="fa fa-check"></i><b>10.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="CFA1st.html"><a href="CFA1st.html#two-broad-categories-of-factor-analysis-exploratory-and-confirmatory"><i class="fa fa-check"></i><b>10.2</b> Two Broad Categories of Factor Analysis: Exploratory and Confirmatory</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="CFA1st.html"><a href="CFA1st.html#common-to-both-exploratory-and-confirmatory-approaches"><i class="fa fa-check"></i><b>10.2.1</b> Common to Both Exploratory and Confirmatory Approaches</a></li>
<li class="chapter" data-level="10.2.2" data-path="CFA1st.html"><a href="CFA1st.html#differences-between-efa-and-cfa"><i class="fa fa-check"></i><b>10.2.2</b> Differences between EFA and CFA</a></li>
<li class="chapter" data-level="10.2.3" data-path="CFA1st.html"><a href="CFA1st.html#on-the-relationship-between-efa-and-cfa"><i class="fa fa-check"></i><b>10.2.3</b> On the relationship between EFA and CFA</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="CFA1st.html"><a href="CFA1st.html#exploring-a-standard-cfa-model"><i class="fa fa-check"></i><b>10.3</b> Exploring a Standard CFA Model</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="CFA1st.html"><a href="CFA1st.html#model-identification-for-cfa"><i class="fa fa-check"></i><b>10.3.1</b> Model Identification for CFA</a></li>
<li class="chapter" data-level="10.3.2" data-path="CFA1st.html"><a href="CFA1st.html#selecting-indicatorsitems-for-a-reflective-measurement"><i class="fa fa-check"></i><b>10.3.2</b> Selecting Indicators/Items for a Reflective Measurement</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="CFA1st.html"><a href="CFA1st.html#cfa-workflow"><i class="fa fa-check"></i><b>10.4</b> CFA Workflow</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="CFA1st.html"><a href="CFA1st.html#cfa-in-lavaan-requires-fluency-with-the-syntax"><i class="fa fa-check"></i><b>10.4.1</b> CFA in <em>lavaan</em> Requires Fluency with the Syntax</a></li>
<li class="chapter" data-level="10.4.2" data-path="CFA1st.html"><a href="CFA1st.html#differing-factor-structures"><i class="fa fa-check"></i><b>10.4.2</b> Differing Factor Structures</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="CFA1st.html"><a href="CFA1st.html#research-vignette-7"><i class="fa fa-check"></i><b>10.5</b> Research Vignette</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="CFA1st.html"><a href="CFA1st.html#modeling-the-grmsaaw-as-unidimensional"><i class="fa fa-check"></i><b>10.5.1</b> Modeling the GRMSAAW as Unidimensional</a></li>
<li class="chapter" data-level="10.5.2" data-path="CFA1st.html"><a href="CFA1st.html#modeling-the-grmsaaw-as-a-first-order-4-factor-model"><i class="fa fa-check"></i><b>10.5.2</b> Modeling the GRMSAAW as a First-Order, 4-factor model</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="CFA1st.html"><a href="CFA1st.html#model-comparison"><i class="fa fa-check"></i><b>10.6</b> Model Comparison</a></li>
<li class="chapter" data-level="10.7" data-path="CFA1st.html"><a href="CFA1st.html#a-concluding-thought"><i class="fa fa-check"></i><b>10.7</b> A concluding thought</a></li>
<li class="chapter" data-level="10.8" data-path="CFA1st.html"><a href="CFA1st.html#practice-problems-8"><i class="fa fa-check"></i><b>10.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="CFA1st.html"><a href="CFA1st.html#problem-1-play-around-with-this-simulation.-5"><i class="fa fa-check"></i><b>10.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="10.8.2" data-path="CFA1st.html"><a href="CFA1st.html#problem-2-use-simulated-data-from-other-lessons."><i class="fa fa-check"></i><b>10.8.2</b> Problem #2: Use simulated data from other lessons.</a></li>
<li class="chapter" data-level="10.8.3" data-path="CFA1st.html"><a href="CFA1st.html#problem-3-try-something-entirely-new.-5"><i class="fa fa-check"></i><b>10.8.3</b> Problem #3: Try something entirely new.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="REFS.html"><a href="REFS.html"><i class="fa fa-check"></i>REFERENCES</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ReCentering Psych Stats: Psychometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="PAF" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Principal Axis Factoring<a href="PAF.html#PAF" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=04c108ff-257e-4893-b6c3-adad0038666b">Screencasted Lecture Link</a></p>
<p>This is the second week of <em>exploratory</em> principal components analysis (PCA) and factor analysis (EFA). This time the focus is on actual <em>factor analysis</em>. There are numerous approaches. I will be demonstrating principal axis factoring (PAF).</p>
<div id="navigating-this-lesson-7" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Navigating this Lesson<a href="PAF.html#navigating-this-lesson-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There is about an hour-and-a-half of lecture. If you work through the materials with me it would be plan for an additional two hours.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_Psychometrics">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="ReCintro.html#ReCintro">introduction</a></p>
<div id="learning-objectives-7" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Learning Objectives<a href="PAF.html#learning-objectives-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Focusing on this week’s materials, make sure you can:</p>
<ul>
<li>Distinguish between PCA and EFA on several levels:
<ul>
<li>recognize PCA and EFA from a path diagram</li>
<li>define keywords associated with each: factor loadings, linear components, describe v. explain.<br />
</li>
</ul></li>
<li>Recognize/define an identity matrix – what test would you use to diagnose it?</li>
<li>Recognize/define multicollinearity and singularity – what test would you use to diagnose it?</li>
<li>Describe the desired pattern of “loadings” (i.e., the relative weights of an item on its own scale compared to other scales)</li>
<li>Compare the results from item analysis, PCA, PAF, and omega.</li>
</ul>
</div>
<div id="planning-for-practice-7" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Planning for Practice<a href="PAF.html#planning-for-practice-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. Whichever you choose, it would be terrific if you used the same dataframe across as many psychometrics lessons as possible so you can compare the results.</p>
<p>The least complex is to change the random seed and rework the problem demonstrated in the lesson. The results <em>should</em> map onto the ones obtained in the lecture.</p>
<p>The second option involves utilizing one of the simulated datasets available in this OER. Szymanski and Bissonette’s <span class="citation">(<a href="#ref-szymanski_perceptions_2020">2020</a>)</span> Perceptions of the LGBTQ College Campus Climate Scale: Development and Psychometric Evaluation was used as the research vignette for the validity, reliability, and item analysis lessons. Although I switched vignettes, the Szymanski and Bissonette example is ready for PCA.</p>
<p>As a third option, you are welcome to use data to which you have access and is suitable for PCA. These could include other vignettes from this OER, other simualated data, or your own data (presuming you have permissoin to use it). In either case, please plan to:</p>
<ul>
<li>Properly format and prepare the data.</li>
<li>Conduct diagnostic tests to determine the suitability of the data for PCA.</li>
<li>Conducting tests to guide the decisions about number of components to extract.</li>
<li>Conducting orthogonal and oblique extractions (at least two each with different numbers of components).</li>
<li>Selecting one solution and preparing an APA style results section (with table and figure).</li>
<li>Compare your results in light of any other psychometrics lessons where you have used this data (especially the <a href="ItemAnalSurvey.html#ItemAnalSurvey">item analysis</a> and <a href="PCA.html#PCA">PCA</a> lessons).</li>
</ul>
</div>
<div id="readings-resources-7" class="section level3 hasAnchor" number="9.1.3">
<h3><span class="header-section-number">9.1.3</span> Readings &amp; Resources<a href="PAF.html#readings-resources-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li>Revelle, William. (n.d.). Chapter 6: Constructs, components, and factor models. In <em>An introduction to psychometric theory with applications in R</em>. Retrieved from <a href="https://personality-project.org/r/book/#chapter6" class="uri">https://personality-project.org/r/book/#chapter6</a>
<ul>
<li>pp. 150 to 167. Stop at “Non-Simple Structure Solutions: The Simplex and Circumplex.”</li>
<li>A simultaneously theoretical review of psychometric theory while working with R and data to understand the concepts.</li>
</ul></li>
<li>Revelle, W. (2019). <em>How To: Use the psych package for Factor Analysis and data reduction</em>.
<ul>
<li>Treat as reference. Pages 13 through 24 provide technical information about what we are doing.</li>
</ul></li>
</ul>
</div>
<div id="packages-7" class="section level3 hasAnchor" number="9.1.4">
<h3><span class="header-section-number">9.1.4</span> Packages<a href="PAF.html#packages-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The packages used in this lesson are embedded in this code. When the hashtags are removed, the script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="PAF.html#cb355-1" tabindex="-1"></a><span class="co"># will install the package if not already installed</span></span>
<span id="cb355-2"><a href="PAF.html#cb355-2" tabindex="-1"></a><span class="co"># if(!require(psych)){install.packages(&#39;psych&#39;)}</span></span>
<span id="cb355-3"><a href="PAF.html#cb355-3" tabindex="-1"></a><span class="co"># if(!require(tidyverse)){install.packages(&#39;tidyverse&#39;)}</span></span>
<span id="cb355-4"><a href="PAF.html#cb355-4" tabindex="-1"></a><span class="co"># if(!require(MASS)){install.packages(&#39;MASS&#39;)}</span></span>
<span id="cb355-5"><a href="PAF.html#cb355-5" tabindex="-1"></a><span class="co"># if(!require(sjstats)){install.packages(&#39;sjstats&#39;)}</span></span>
<span id="cb355-6"><a href="PAF.html#cb355-6" tabindex="-1"></a><span class="co"># if(!require(apaTables)){install.packages(&#39;apaTables&#39;)}</span></span>
<span id="cb355-7"><a href="PAF.html#cb355-7" tabindex="-1"></a><span class="co"># if(!require(qualtRics)){install.packages(&#39;qualtRics&#39;)}</span></span></code></pre></div>
</div>
</div>
<div id="exploratory-factor-analysis-with-a-quick-contrast-to-pca" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Exploratory Factor Analysis (with a quick contrast to PCA)<a href="PAF.html#exploratory-factor-analysis-with-a-quick-contrast-to-pca" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Whereas principal components analysis (PCA) is a regression analysis technique, principal factor analysis is “…a latent variable model” <span class="citation">(<a href="#ref-revelle_william_chapter_nodate"><strong>revelle_william_chapter_nodate?</strong></a>)</span>.</p>
<p>Exploratory factor analysis has a rich history. In 1904, Spearman used it for a single factor. In 1947, Thurstone generalized it to multiple factors. Factor analysis is frequently used and controversial.</p>
<p>Factor analysis and principal components are commonly confused:</p>
<p><strong>Principal components</strong></p>
<ul>
<li>linear sums of variables,</li>
<li>solved with an eigenvalue or singular decomposition</li>
<li>represents a <span class="math inline">\(n*n\)</span> matrix in terms of the first <em>k</em> components and attempts to reproduce all of the <span class="math inline">\(R\)</span> matrix.</li>
<li>paths point from the items to a total scale score – all represented as observed/manifest (square) variables</li>
</ul>
<p><strong>Factor analysis</strong></p>
<ul>
<li>linear sums of unknown factors</li>
<li>estimated as best fitting solutions, normally through iterative procedures.</li>
<li>Controversial because
<ul>
<li>at the <em>structural</em> level (i.e., covariance or correlation matrix), there are normally more observed variables than parameters to estimate them and the procedure seeks to find the best fitting solution using ordinary least squares, weighted least squares, or maximum likelihood</li>
<li>at the <em>data</em> level, the model is indeterminate, although scores can be extimated</li>
<li>this leads some to argue for using principal components; but fans of factor analysis suggest that it is useful for theory construction and evaluation</li>
</ul></li>
<li>attempts to model only the <em>common</em> part of the matrix, which means all of the off-diagonal elements and the common part of the diagonal (the <em>communalities</em>); the <em>uniquenesses</em> are the non-common (leftover) part</li>
<li>Stated another way, the factor model partitions the correlation or covariance matrix into
<ul>
<li><em>common factors</em>, <span class="math inline">\(FF&#39;\)</span>, and</li>
<li>that which is <em>unique</em>, <span class="math inline">\(U^2\)</span> (the diagonal matrix of <em>uniquenesses</em>)</li>
</ul></li>
<li>paths point from the latent variable (LV) representing the factor (oval) to the items (squares) illustrating that the factor/LV “causes” the item’s score</li>
</ul>
<div class="float">
<img src="images/PAF/PCAvPAF.png" alt="Comparison of path models for PCA and EFA" />
<div class="figcaption">Comparison of path models for PCA and EFA</div>
</div>
<p>Our focus today is on the PAF approach to scale construction. By utilizing the same research vignette as in the <a href="PCA.html#PCA">PCA lesson</a>, we can identify similarities in differences in the approach, results, and interpretation. Let’s first take a look at the workflow for PAF.</p>
</div>
<div id="paf-workflow" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> PAF Workflow<a href="PAF.html#paf-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below is a screenshot of the workflow. The original document is located in the <a href="https://github.com/lhbikos/ReC_Psychometrics">Github site</a> that hosts the ReCentering Psych Stats: Psychometrics OER. You may find it refreshing that, with the exception of the change from “components” to “factors,” the workflow for PCA and PAF are quite similar.</p>
<div class="float">
<img src="images/PAF/PAFworkflow.png" alt="Image of the workflow for PAF" />
<div class="figcaption">Image of the workflow for PAF</div>
</div>
<p>Steps in the process include:</p>
<ul>
<li>Creating an items only dataframe where all items are scaled in the same direction (i.e., negatively worded items are reverse-scored).</li>
<li>Conducting tests that assess the statistical assumptions of PAF to ensure that the data is appropriate for PAF.</li>
<li>Determining the number of factors (think “subscales”) to extract.</li>
<li>Conducting the factor extraction – this process will likely occur iteratively,
<ul>
<li>exploring orthogonal (uncorrelated/independent) and oblique (correlated) factors, and</li>
<li>changing the number of factors to extract</li>
</ul></li>
</ul>
<p>Because the intended audience for the ReCentering Psych Stats OER is the scientist-practitioner-advocate, this lesson focuses on the workflow and decisions. As you might guess, the details of PAF can be quite complex. Some important notions to consider that may not be obvious from lesson, are these:</p>
<ul>
<li>The values of factor loadings are directly related to the correlation matrix.
<ul>
<li>Although I do not explain this in detail, nearly every analytic step attempts to convey this notion by presenting equivalent analytic options using the raw data and correlation matrix.</li>
</ul></li>
<li>PAF (like PCA and related EFA procecures) is about <em>dimension reduction</em> – our goal is fewer factors (think subscales) than there are items.
<ul>
<li>In this lesson’s vignette there are 25 items on the scale and we will have 4 subscales.</li>
</ul></li>
<li>As a latent variable procedure, PAF is both <em>exploratory</em> and <em>factor analysis.</em> This is in contrast to our prior <a href="PCA.html#PCA">PCA lesson</a>. Recall that PCA is a regression-based model and therefore not “factor analysis.”</li>
<li>Matrix algebra (e.g., using the transpose of a matrix, multiplying matrices together) plays a critical role in the analytic solution.</li>
</ul>
</div>
<div id="research-vignette-6" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Research Vignette<a href="PAF.html#research-vignette-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This lesson’s research vignette emerges from Lewis and Neville’s Gendered Racial Microaggressions Scale for Black Women <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span>. The article reports on two separate studies that comprised the development, refinement, and psychometric evaluation of two parallel versions (stress appraisal, frequency) of the scale. Below, I simulate data from the final construction of the stress appraisal version as the basis of the lecture. Items were on a 6-point Likert scale ranging from 0 (<em>not at all stressful</em>) to 5 (<em>extremely stressful</em>).</p>
<p>Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> reported support for a total scale score (25 items) and four subscales. Below, I list the four subscales, their number of items, and a single example item. At the outset, let me provide a content advisory. For those who hold this particular identity (or related identities) the content in the items may be upsetting. In other lessons, I often provide a variable name that gives an indication of the primary content of the item. In the case of the GRMS, I will simply provide an abbreviation of the subscale name and its respective item number. This will allow us to easily inspect the alignment of the item with its intended factor, and hopefully minimize discomfort. If you are not a member of this particular identity, I encourage you to learn about these microaggressions by reading the article in its entirety. Please do not ask members of this group to explain why these microaggressions are harmful or ask if they have encountered them. The four factors, number of items, and sample item are as follows:</p>
<ul>
<li>Assumptions of Beauty and Sexual Objectification
<ul>
<li>10 items</li>
<li>“Objectified me based on physical features.”</li>
<li>Abbreviated in the simulated data as “Obj#”</li>
</ul></li>
<li>Silenced and Marginalized
<ul>
<li>7 items</li>
<li>“Someone has tried to ‘put me in my place.’”</li>
<li>Abbreviated in the simulated data as “Marg#”</li>
</ul></li>
<li>Strong Black Woman Stereotype
<ul>
<li>5 items</li>
<li>“I have been told that I am too assertive.”</li>
<li>Abbreviated in the simulated data as “Str#”</li>
</ul></li>
<li>Angry Black Woman Stereotype
<ul>
<li>3 items</li>
<li>“Someone accused me of being angry when speaking calm.”</li>
<li>Abbreviated in the simulated data as “Ang#”</li>
</ul></li>
</ul>
<p>Three additional scales were reported in the Lewis and Neville article <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span>.
Because (a) the focus of this lesson is on exploratory factor analytic approaches and, therefore, only requires item-level data for the scale, and (b) the article does not include correlations between the subscales/scales of all involved measures, I only simulated item-level data for the GRMS items.</p>
<p>Below, I walk through the data simulation. This is not an essential portion of the lesson, but I will lecture it in case you are interested. None of the items are negatively worded (relative to the other items), so there is no need to reverse-score any items.</p>
<p>Simulating the data involved using factor loadings, means, standard deviations, and correlations between the scales. Because the simulation will produce “out-of-bounds” values, the code below rescales the scores into the range of the Likert-type scaling and rounds them to whole values.</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="PAF.html#cb356-1" tabindex="-1"></a><span class="co"># Entering the intercorrelations, means, and standard deviations from</span></span>
<span id="cb356-2"><a href="PAF.html#cb356-2" tabindex="-1"></a><span class="co"># the journal article</span></span>
<span id="cb356-3"><a href="PAF.html#cb356-3" tabindex="-1"></a></span>
<span id="cb356-4"><a href="PAF.html#cb356-4" tabindex="-1"></a>LewisGRMS_generating_model <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb356-5"><a href="PAF.html#cb356-5" tabindex="-1"></a><span class="st">        #measurement model</span></span>
<span id="cb356-6"><a href="PAF.html#cb356-6" tabindex="-1"></a><span class="st">        Objectification =~ .69*Obj1 + .69*Obj2 + .60*Obj3 + .59*Obj4 + .55*Obj5 + .55*Obj6 + .54*Obj7 + .50*Obj8 + .41*Obj9 + .41*Obj10</span></span>
<span id="cb356-7"><a href="PAF.html#cb356-7" tabindex="-1"></a><span class="st">        Marginalized =~ .93*Marg1 + .81*Marg2 +.69*Marg3 + .67*Marg4 + .61*Marg5 + .58*Marg6 +.54*Marg7</span></span>
<span id="cb356-8"><a href="PAF.html#cb356-8" tabindex="-1"></a><span class="st">        Strong =~ .59*Str1 + .55*Str2 + .54*Str3 + .54*Str4 + .51*Str5</span></span>
<span id="cb356-9"><a href="PAF.html#cb356-9" tabindex="-1"></a><span class="st">        Angry =~ .70*Ang1 + .69*Ang2 + .68*Ang3</span></span>
<span id="cb356-10"><a href="PAF.html#cb356-10" tabindex="-1"></a><span class="st">        </span></span>
<span id="cb356-11"><a href="PAF.html#cb356-11" tabindex="-1"></a><span class="st">        #Means</span></span>
<span id="cb356-12"><a href="PAF.html#cb356-12" tabindex="-1"></a><span class="st">         Objectification ~ 1.85*1</span></span>
<span id="cb356-13"><a href="PAF.html#cb356-13" tabindex="-1"></a><span class="st">         Marginalized ~ 2.67*1</span></span>
<span id="cb356-14"><a href="PAF.html#cb356-14" tabindex="-1"></a><span class="st">         Strong ~ 1.61*1</span></span>
<span id="cb356-15"><a href="PAF.html#cb356-15" tabindex="-1"></a><span class="st">         Angry ~ 2.29*1</span></span>
<span id="cb356-16"><a href="PAF.html#cb356-16" tabindex="-1"></a><span class="st">         </span></span>
<span id="cb356-17"><a href="PAF.html#cb356-17" tabindex="-1"></a><span class="st">        #Correlations</span></span>
<span id="cb356-18"><a href="PAF.html#cb356-18" tabindex="-1"></a><span class="st">         Objectification ~~ .63*Marginalized</span></span>
<span id="cb356-19"><a href="PAF.html#cb356-19" tabindex="-1"></a><span class="st">         Objectification ~~ .66*Strong</span></span>
<span id="cb356-20"><a href="PAF.html#cb356-20" tabindex="-1"></a><span class="st">         Objectification ~~ .51*Angry</span></span>
<span id="cb356-21"><a href="PAF.html#cb356-21" tabindex="-1"></a><span class="st">         </span></span>
<span id="cb356-22"><a href="PAF.html#cb356-22" tabindex="-1"></a><span class="st">         Marginalized ~~ .59*Strong</span></span>
<span id="cb356-23"><a href="PAF.html#cb356-23" tabindex="-1"></a><span class="st">         Marginalized ~~ .62*Angry</span></span>
<span id="cb356-24"><a href="PAF.html#cb356-24" tabindex="-1"></a></span>
<span id="cb356-25"><a href="PAF.html#cb356-25" tabindex="-1"></a><span class="st">         Strong ~~ .61*Angry</span></span>
<span id="cb356-26"><a href="PAF.html#cb356-26" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb356-27"><a href="PAF.html#cb356-27" tabindex="-1"></a><span class="st">        &quot;</span></span>
<span id="cb356-28"><a href="PAF.html#cb356-28" tabindex="-1"></a></span>
<span id="cb356-29"><a href="PAF.html#cb356-29" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">240311</span>)</span>
<span id="cb356-30"><a href="PAF.html#cb356-30" tabindex="-1"></a>items <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">simulateData</span>(<span class="at">model =</span> LewisGRMS_generating_model, <span class="at">model.type =</span> <span class="st">&quot;sem&quot;</span>,</span>
<span id="cb356-31"><a href="PAF.html#cb356-31" tabindex="-1"></a>    <span class="at">meanstructure =</span> T, <span class="at">sample.nobs =</span> <span class="dv">259</span>, <span class="at">standardized =</span> <span class="cn">FALSE</span>)</span>
<span id="cb356-32"><a href="PAF.html#cb356-32" tabindex="-1"></a></span>
<span id="cb356-33"><a href="PAF.html#cb356-33" tabindex="-1"></a><span class="co"># used to retrieve column indices used in the rescaling script below</span></span>
<span id="cb356-34"><a href="PAF.html#cb356-34" tabindex="-1"></a>col_index <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">colnames</span>(items))</span>
<span id="cb356-35"><a href="PAF.html#cb356-35" tabindex="-1"></a></span>
<span id="cb356-36"><a href="PAF.html#cb356-36" tabindex="-1"></a><span class="co"># The code below loops through each column of the dataframe and</span></span>
<span id="cb356-37"><a href="PAF.html#cb356-37" tabindex="-1"></a><span class="co"># assigns the scaling accordingly Rows 1 thru 26 are the GRMS items</span></span>
<span id="cb356-38"><a href="PAF.html#cb356-38" tabindex="-1"></a></span>
<span id="cb356-39"><a href="PAF.html#cb356-39" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(items)) {</span>
<span id="cb356-40"><a href="PAF.html#cb356-40" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="sc">&gt;=</span> <span class="dv">1</span> <span class="sc">&amp;</span> i <span class="sc">&lt;=</span> <span class="dv">26</span>) {</span>
<span id="cb356-41"><a href="PAF.html#cb356-41" tabindex="-1"></a>        items[, i] <span class="ot">&lt;-</span> scales<span class="sc">::</span><span class="fu">rescale</span>(items[, i], <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>))</span>
<span id="cb356-42"><a href="PAF.html#cb356-42" tabindex="-1"></a>    }</span>
<span id="cb356-43"><a href="PAF.html#cb356-43" tabindex="-1"></a>}</span>
<span id="cb356-44"><a href="PAF.html#cb356-44" tabindex="-1"></a></span>
<span id="cb356-45"><a href="PAF.html#cb356-45" tabindex="-1"></a><span class="co"># rounding to integers so that the data resembles that which was</span></span>
<span id="cb356-46"><a href="PAF.html#cb356-46" tabindex="-1"></a><span class="co"># collected</span></span>
<span id="cb356-47"><a href="PAF.html#cb356-47" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb356-48"><a href="PAF.html#cb356-48" tabindex="-1"></a>items <span class="ot">&lt;-</span> items <span class="sc">%&gt;%</span></span>
<span id="cb356-49"><a href="PAF.html#cb356-49" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">0</span>)</span>
<span id="cb356-50"><a href="PAF.html#cb356-50" tabindex="-1"></a></span>
<span id="cb356-51"><a href="PAF.html#cb356-51" tabindex="-1"></a><span class="co"># quick check of my work psych::describe(items)</span></span></code></pre></div>
<p>The optional script below will let you save the simulated data to your computing environment as either a .csv file (think “Excel lite”) or .rds object (preserves any formatting you might do).</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="PAF.html#cb357-1" tabindex="-1"></a><span class="co">#write the simulated data  as a .csv</span></span>
<span id="cb357-2"><a href="PAF.html#cb357-2" tabindex="-1"></a><span class="co">#write.table(items, file=&quot;items.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE)</span></span>
<span id="cb357-3"><a href="PAF.html#cb357-3" tabindex="-1"></a><span class="co">#bring back the simulated dat from a .csv file</span></span>
<span id="cb357-4"><a href="PAF.html#cb357-4" tabindex="-1"></a><span class="co">#items &lt;- read.csv (&quot;items.csv&quot;, header = TRUE)</span></span></code></pre></div>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="PAF.html#cb358-1" tabindex="-1"></a><span class="co">#to save the df as an .rds (think &quot;R object&quot;) file on your computer; it should save in the same file as the .rmd file you are working with</span></span>
<span id="cb358-2"><a href="PAF.html#cb358-2" tabindex="-1"></a><span class="co">#saveRDS(items, &quot;items.rds&quot;)</span></span>
<span id="cb358-3"><a href="PAF.html#cb358-3" tabindex="-1"></a><span class="co">#bring back the simulated dat from an .rds file</span></span>
<span id="cb358-4"><a href="PAF.html#cb358-4" tabindex="-1"></a><span class="co">#items &lt;- readRDS(&quot;items.rds&quot;)</span></span></code></pre></div>
</div>
<div id="working-the-vignette-1" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Working the Vignette<a href="PAF.html#working-the-vignette-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It may be useful to recall how we might understand factors in the psychometric sense:</p>
<ul>
<li>clusters of correlated items in an <span class="math inline">\(R\)</span>-matrix</li>
<li>statistical entities that can be plotted as classification axes where coordinates of variables along each axis represen the strength of the relationship between that variable to each factor.</li>
<li>mathematical equations, resembling regression equations, where each variable is represented according to its relative weight</li>
</ul>
<div id="data-prep-1" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> Data Prep<a href="PAF.html#data-prep-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Since the first step is data preparation, let’s start by:</p>
<ul>
<li>reverse coding any items that are phrased in the opposite direction</li>
<li>creating a <em>df</em> (as an object) that only contains the items in their properly scored direction (i.e., you might need to replace the original item with the reverse-coded item); there shoud be no other variables (e.g., ID, demographic variables, other scales) in this df
<ul>
<li>because the GRMS has no items like this we can skip these two steps</li>
</ul></li>
</ul>
<p>Our example today requires no reverse coding and the dataset I simulated only has item-level data (with no ID and no other variables). This means we are ready to start the PAF process.</p>
<p>Let’s take a look at (and make an object of) the correlation matrix.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="PAF.html#cb359-1" tabindex="-1"></a>GRMSr <span class="ot">&lt;-</span> <span class="fu">cor</span>(items)  <span class="co">#correlation matrix (with the negatively scored item already reversed) created and saved as object</span></span>
<span id="cb359-2"><a href="PAF.html#cb359-2" tabindex="-1"></a><span class="fu">round</span>(GRMSr, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>      Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7 Obj8  Obj9 Obj10 Marg1 Marg2 Marg3
Obj1  1.00 0.30 0.24 0.20 0.27 0.18 0.25 0.32  0.12  0.26  0.17  0.21  0.19
Obj2  0.30 1.00 0.32 0.24 0.27 0.21 0.24 0.29  0.26  0.19  0.08  0.19  0.14
Obj3  0.24 0.32 1.00 0.21 0.22 0.19 0.25 0.21  0.17  0.23  0.25  0.19  0.15
Obj4  0.20 0.24 0.21 1.00 0.36 0.19 0.27 0.27  0.23  0.26  0.16  0.13  0.17
Obj5  0.27 0.27 0.22 0.36 1.00 0.16 0.16 0.25  0.14  0.19  0.26  0.23  0.22
Obj6  0.18 0.21 0.19 0.19 0.16 1.00 0.16 0.19  0.14  0.10  0.16  0.06  0.05
Obj7  0.25 0.24 0.25 0.27 0.16 0.16 1.00 0.33  0.21  0.25  0.31  0.18  0.20
Obj8  0.32 0.29 0.21 0.27 0.25 0.19 0.33 1.00  0.16  0.26  0.12  0.10  0.12
Obj9  0.12 0.26 0.17 0.23 0.14 0.14 0.21 0.16  1.00  0.14  0.03  0.08  0.18
Obj10 0.26 0.19 0.23 0.26 0.19 0.10 0.25 0.26  0.14  1.00  0.10  0.10  0.20
Marg1 0.17 0.08 0.25 0.16 0.26 0.16 0.31 0.12  0.03  0.10  1.00  0.33  0.36
Marg2 0.21 0.19 0.19 0.13 0.23 0.06 0.18 0.10  0.08  0.10  0.33  1.00  0.35
Marg3 0.19 0.14 0.15 0.17 0.22 0.05 0.20 0.12  0.18  0.20  0.36  0.35  1.00
Marg4 0.21 0.15 0.20 0.24 0.21 0.13 0.21 0.17  0.07  0.17  0.41  0.20  0.37
Marg5 0.09 0.17 0.13 0.20 0.25 0.12 0.18 0.18  0.20  0.06  0.35  0.31  0.24
Marg6 0.22 0.21 0.11 0.22 0.24 0.22 0.31 0.20  0.12  0.14  0.34  0.28  0.31
Marg7 0.08 0.18 0.11 0.19 0.18 0.12 0.13 0.13  0.09  0.07  0.28  0.29  0.23
Str1  0.19 0.19 0.19 0.13 0.23 0.06 0.26 0.14  0.13  0.21  0.17  0.18  0.15
Str2  0.23 0.15 0.18 0.14 0.11 0.14 0.18 0.10  0.07  0.16  0.11  0.15  0.21
Str3  0.18 0.06 0.15 0.10 0.13 0.06 0.15 0.05  0.05  0.17  0.14  0.18  0.15
Str4  0.03 0.14 0.17 0.13 0.07 0.08 0.12 0.03  0.00  0.06  0.10  0.07  0.06
Str5  0.13 0.11 0.17 0.01 0.09 0.05 0.15 0.06  0.02  0.03  0.07  0.15  0.05
Ang1  0.06 0.01 0.15 0.14 0.11 0.04 0.25 0.08  0.12  0.06  0.21  0.19  0.13
Ang2  0.05 0.05 0.09 0.07 0.09 0.14 0.09 0.03 -0.01  0.13  0.13  0.21  0.14
Ang3  0.21 0.10 0.18 0.19 0.11 0.11 0.23 0.08  0.08  0.14  0.25  0.20  0.14
      Marg4 Marg5 Marg6 Marg7 Str1  Str2 Str3 Str4  Str5 Ang1  Ang2 Ang3
Obj1   0.21  0.09  0.22  0.08 0.19  0.23 0.18 0.03  0.13 0.06  0.05 0.21
Obj2   0.15  0.17  0.21  0.18 0.19  0.15 0.06 0.14  0.11 0.01  0.05 0.10
Obj3   0.20  0.13  0.11  0.11 0.19  0.18 0.15 0.17  0.17 0.15  0.09 0.18
Obj4   0.24  0.20  0.22  0.19 0.13  0.14 0.10 0.13  0.01 0.14  0.07 0.19
Obj5   0.21  0.25  0.24  0.18 0.23  0.11 0.13 0.07  0.09 0.11  0.09 0.11
Obj6   0.13  0.12  0.22  0.12 0.06  0.14 0.06 0.08  0.05 0.04  0.14 0.11
Obj7   0.21  0.18  0.31  0.13 0.26  0.18 0.15 0.12  0.15 0.25  0.09 0.23
Obj8   0.17  0.18  0.20  0.13 0.14  0.10 0.05 0.03  0.06 0.08  0.03 0.08
Obj9   0.07  0.20  0.12  0.09 0.13  0.07 0.05 0.00  0.02 0.12 -0.01 0.08
Obj10  0.17  0.06  0.14  0.07 0.21  0.16 0.17 0.06  0.03 0.06  0.13 0.14
Marg1  0.41  0.35  0.34  0.28 0.17  0.11 0.14 0.10  0.07 0.21  0.13 0.25
Marg2  0.20  0.31  0.28  0.29 0.18  0.15 0.18 0.07  0.15 0.19  0.21 0.20
Marg3  0.37  0.24  0.31  0.23 0.15  0.21 0.15 0.06  0.05 0.13  0.14 0.14
Marg4  1.00  0.27  0.28  0.24 0.13  0.17 0.13 0.16 -0.01 0.11  0.17 0.20
Marg5  0.27  1.00  0.27  0.23 0.13  0.06 0.20 0.11  0.08 0.04  0.10 0.22
Marg6  0.28  0.27  1.00  0.26 0.12  0.28 0.17 0.14  0.09 0.13  0.21 0.16
Marg7  0.24  0.23  0.26  1.00 0.12 -0.01 0.05 0.05  0.03 0.18  0.12 0.08
Str1   0.13  0.13  0.12  0.12 1.00  0.16 0.22 0.14  0.18 0.18  0.05 0.06
Str2   0.17  0.06  0.28 -0.01 0.16  1.00 0.19 0.17  0.18 0.11  0.16 0.12
Str3   0.13  0.20  0.17  0.05 0.22  0.19 1.00 0.27  0.19 0.27  0.13 0.22
Str4   0.16  0.11  0.14  0.05 0.14  0.17 0.27 1.00  0.11 0.12  0.04 0.04
Str5  -0.01  0.08  0.09  0.03 0.18  0.18 0.19 0.11  1.00 0.15  0.11 0.12
Ang1   0.11  0.04  0.13  0.18 0.18  0.11 0.27 0.12  0.15 1.00  0.23 0.26
Ang2   0.17  0.10  0.21  0.12 0.05  0.16 0.13 0.04  0.11 0.23  1.00 0.27
Ang3   0.20  0.22  0.16  0.08 0.06  0.12 0.22 0.04  0.12 0.26  0.27 1.00</code></pre>
<p>In case you want to examine it in sections (easier to view):</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="PAF.html#cb361-1" tabindex="-1"></a><span class="co"># round(GRMSr[,1:8], 2) round(GRMSr[,9:16], 2) round(GRMSr[,17:25],</span></span>
<span id="cb361-2"><a href="PAF.html#cb361-2" tabindex="-1"></a><span class="co"># 2)</span></span></code></pre></div>
<p>As with PCA, we can analyze the data with either raw data or correlation matrix. I will do both to demonstrate (a) that it’s possible and to (b) continue emphasizing that this is a <em>structural</em> analysis. That is, we are trying to see if our more parsimonious extraction <em>reproduces</em> this original correlation matrix.</p>
<div id="three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factoranalysis" class="section level4 hasAnchor" number="9.5.1.1">
<h4><span class="header-section-number">9.5.1.1</span> Three Diagnostic Tests to Evaluate the Appropriateness of the Data for Component (or Factor)Analysis<a href="PAF.html#three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factoranalysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="is-my-sample-adequate-for-paf" class="section level4 hasAnchor" number="9.5.1.2">
<h4><span class="header-section-number">9.5.1.2</span> Is my sample adequate for PAF?<a href="PAF.html#is-my-sample-adequate-for-paf" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We return to the <strong>KMO</strong> (Kaiser-Meyer-Olkin), an index of <em>sampling adequacy</em> that can be used with the actual sample to let us know if the sample size is sufficient (or if we should collect more data).</p>
<p>Kaiser’s 1974 recommendations were:</p>
<ul>
<li>bare minimum of .5</li>
<li>values between .5 and .7 are mediocre</li>
<li>values between .7 and .8 are good</li>
<li>values above .9 are superb</li>
</ul>
<p>We use the <em>KMO()</em> function from the <em>psych</em> package with either raw or matrix dat.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="PAF.html#cb362-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">KMO</span>(items)</span></code></pre></div>
<pre><code>Kaiser-Meyer-Olkin factor adequacy
Call: psych::KMO(r = items)
Overall MSA =  0.84
MSA for each item = 
 Obj1  Obj2  Obj3  Obj4  Obj5  Obj6  Obj7  Obj8  Obj9 Obj10 Marg1 Marg2 Marg3 
 0.85  0.85  0.88  0.86  0.87  0.86  0.87  0.85  0.76  0.85  0.83  0.87  0.87 
Marg4 Marg5 Marg6 Marg7  Str1  Str2  Str3  Str4  Str5  Ang1  Ang2  Ang3 
 0.87  0.82  0.88  0.84  0.87  0.84  0.79  0.74  0.81  0.74  0.75  0.82 </code></pre>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="PAF.html#cb364-1" tabindex="-1"></a><span class="co"># psych::KMO(GRMSr) #for the KMO function, do not specify sample size</span></span>
<span id="cb364-2"><a href="PAF.html#cb364-2" tabindex="-1"></a><span class="co"># if using the matrix form of the data</span></span></code></pre></div>
<p>We examine the KMO values for both the overall matrix and the individual items.</p>
<p>At the matrix level, our <span class="math inline">\(KMO = .84\)</span>, which falls in between Kaiser’s definitions of <em>good</em> and <em>superb</em>.</p>
<p>At the item level, the KMO should be &gt; .50. Variables with values below .5 should be evaluated for exclusion from the analysis (or run the analysis with and without the variable and compare the difference). Because removing/adding variables impacts the KMO, be sure to re-evaluate.</p>
<p>At the item level, our KMO values range between .71 (Ang1, Ang2) and .88 (Obj3, Marg6).</p>
<p>Considering both item- and matrix- levels, we conclude that the sample size and the data are adequate for component (or factor) analysis.</p>
</div>
<div id="are-there-correlations-among-the-variables-that-are-big-enough-to-be-analyzed" class="section level4 hasAnchor" number="9.5.1.3">
<h4><span class="header-section-number">9.5.1.3</span> Are there correlations among the variables that are big enough to be analyzed?<a href="PAF.html#are-there-correlations-among-the-variables-that-are-big-enough-to-be-analyzed" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Bartlett’s</strong> lets us know if a matrix is an <em>identity matrix.</em> In an identity matrix all correlation coefficients (everything on the off-diagonal) would be 0.0 (and everything on the diagonal would be 1.0).</p>
<p>A significant Barlett’s (i.e., <span class="math inline">\(p &lt; .05\)</span>) tells that the <span class="math inline">\(R\)</span>-matrix is not an identity matrix. That is, there are some relationships between variables that can be analyzed.</p>
<p>The <em>cortest.bartlett()</em> function in the <em>psych</em> package and can be run either from the raw data or R matrix formats.</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="PAF.html#cb365-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">cortest.bartlett</span>(items)  <span class="co">#from the raw data</span></span></code></pre></div>
<pre><code>R was not square, finding R from data</code></pre>
<pre><code>$chisq
[1] 1113.299

$p.value
[1] 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000007869186

$df
[1] 300</code></pre>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="PAF.html#cb368-1" tabindex="-1"></a><span class="co"># raw data produces the warning &#39;R was not square, finding R from</span></span>
<span id="cb368-2"><a href="PAF.html#cb368-2" tabindex="-1"></a><span class="co"># data.&#39; This means nothing other than we fed it raw data and the</span></span>
<span id="cb368-3"><a href="PAF.html#cb368-3" tabindex="-1"></a><span class="co"># function is creating a matrix from which to do the analysis.</span></span>
<span id="cb368-4"><a href="PAF.html#cb368-4" tabindex="-1"></a></span>
<span id="cb368-5"><a href="PAF.html#cb368-5" tabindex="-1"></a><span class="co"># psych::cortest.bartlett(GRMSr, n = 259) #if using the matrix, must</span></span>
<span id="cb368-6"><a href="PAF.html#cb368-6" tabindex="-1"></a><span class="co"># specify sample size</span></span></code></pre></div>
<p>Our Bartlett’s test is significant: <span class="math inline">\(\chi ^{1}(300)=1113.30, p &lt; .001\)</span>. This supports a component (or factor) analytic approach for investigating the data.</p>
</div>
<div id="is-there-multicollinearity-or-singularity-in-my-data-1" class="section level4 hasAnchor" number="9.5.1.4">
<h4><span class="header-section-number">9.5.1.4</span> Is there multicollinearity or singularity in my data?<a href="PAF.html#is-there-multicollinearity-or-singularity-in-my-data-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <strong>determinant of the correlation matrix</strong> should be greater than 0.00001 (that would be 4 zeros before the 1). If it is smaller than 0.00001 then we may have an issue with <em>multicollinearity</em> (i.e., variables that are too highly correlated) or <em>singularity</em> (variables that are perfectly correlated).</p>
<p>The determinant function comes from base R. It is easiest to compute when the correlation matrix is the object. However, it is also possible to specify the command to work with the raw data.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="PAF.html#cb369-1" tabindex="-1"></a><span class="co"># det(GRMSr)</span></span>
<span id="cb369-2"><a href="PAF.html#cb369-2" tabindex="-1"></a><span class="fu">det</span>(<span class="fu">cor</span>(items))  <span class="co">#if using the raw data</span></span></code></pre></div>
<pre><code>[1] 0.01140074</code></pre>
<p>With a value of 0.00115, our determinant is greater than the 0.00001 requirement. If it were not, then we could identify problematic variables (i.e., those correlating too highly with others and those not correlating sufficiently with others) and re-run the diagnostic statistics.</p>
</div>
<div id="apa-style-summary-so-far" class="section level4 hasAnchor" number="9.5.1.5">
<h4><span class="header-section-number">9.5.1.5</span> APA Style Summary So Far<a href="PAF.html#apa-style-summary-so-far" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00 – values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was .84, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi ^{1}(300)=1113.30, p &lt; .001\)</span>, indicating the correlations between items are sufficiently large enough for principal axis factoring. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.01140 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
<p><em>Note</em>: If this looks familiar, it is! The same diagnostics are used in PAF and <a href="PCA.html#PCA">PCA</a>.</p>
</div>
</div>
<div id="principal-axis-factoring-paf" class="section level3 hasAnchor" number="9.5.2">
<h3><span class="header-section-number">9.5.2</span> Principal Axis Factoring (PAF)<a href="PAF.html#principal-axis-factoring-paf" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can use the <em>fa()</em> function, specifying <em>fm = “pa”</em> from the <em>psych</em> package with raw or matrix data.</p>
<p>One difference from PCA is that factor analysis will not (cannot) calculate as many factors as there are items. This means that we should select a reasonable number, like 20 (since there are 25 items). However, I received a number of errors/warnings and 13 is the first number that would run. I also received the warning, “maximum iteration exceeded.” Therefore I increased “max.iter” to 100.</p>
<p>Our goal is to begin to get an idea of the cumulative variance explained and number of factors to extract. If we think there are four factors, we simply need to specify more than four factors on the <em>nfactors = ##</em> command. As long as that number is less than the total number of items, it does not matter what that number is.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="PAF.html#cb371-1" tabindex="-1"></a><span class="co"># grmsPAF1 &lt;- psych::fa(GRMSr, nfactors=10, fm = &#39;pa&#39;, max.iter =</span></span>
<span id="cb371-2"><a href="PAF.html#cb371-2" tabindex="-1"></a><span class="co"># 100, rotate=&#39;none&#39;)# using the matrix data and specifying the # of</span></span>
<span id="cb371-3"><a href="PAF.html#cb371-3" tabindex="-1"></a><span class="co"># factors.</span></span>
<span id="cb371-4"><a href="PAF.html#cb371-4" tabindex="-1"></a></span>
<span id="cb371-5"><a href="PAF.html#cb371-5" tabindex="-1"></a>grmsPAF1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">13</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">max.iter =</span> <span class="dv">100</span>,</span>
<span id="cb371-6"><a href="PAF.html#cb371-6" tabindex="-1"></a>    <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co"># using raw data and specifying the max number of factors</span></span></code></pre></div>
<pre><code>maximum iteration exceeded</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="PAF.html#cb373-1" tabindex="-1"></a><span class="co"># I received the warning &#39;maximum iteration exceeded&#39;. It gave</span></span>
<span id="cb373-2"><a href="PAF.html#cb373-2" tabindex="-1"></a><span class="co"># output, but it&#39;s best if we don&#39;t get that warning, so I increased</span></span>
<span id="cb373-3"><a href="PAF.html#cb373-3" tabindex="-1"></a><span class="co"># it to 100.</span></span>
<span id="cb373-4"><a href="PAF.html#cb373-4" tabindex="-1"></a></span>
<span id="cb373-5"><a href="PAF.html#cb373-5" tabindex="-1"></a>grmsPAF1  <span class="co">#this object holds a great deal of information </span></span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 13, rotate = &quot;none&quot;, max.iter = 100, 
    fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PA1   PA2   PA3   PA4   PA5   PA6   PA7   PA8   PA9  PA10  PA11  PA12
Obj1  0.50  0.37  0.08 -0.33 -0.27 -0.03 -0.29 -0.10  0.01  0.06 -0.02  0.18
Obj2  0.45  0.34 -0.08  0.04  0.10  0.12 -0.06  0.11  0.13  0.14  0.14 -0.05
Obj3  0.46  0.17  0.12  0.04  0.06  0.07  0.00 -0.09 -0.07  0.12  0.29 -0.19
Obj4  0.46  0.19 -0.10  0.10  0.12 -0.10  0.15  0.08 -0.11 -0.08  0.00  0.11
Obj5  0.54  0.21 -0.32  0.41 -0.44 -0.21  0.09  0.02 -0.06 -0.01 -0.07 -0.08
Obj6  0.31  0.12 -0.03 -0.05  0.09  0.00  0.02  0.21 -0.10  0.14  0.02 -0.05
Obj7  0.54  0.11  0.13 -0.07  0.26 -0.04  0.02 -0.15 -0.10  0.06 -0.25 -0.07
Obj8  0.41  0.31 -0.09 -0.06  0.12 -0.06 -0.02 -0.01 -0.07  0.04 -0.07  0.08
Obj9  0.30  0.22 -0.09  0.13  0.34  0.00 -0.07  0.01  0.18 -0.19 -0.03 -0.12
Obj10 0.39  0.27  0.10 -0.14  0.02 -0.10  0.18 -0.05  0.01 -0.26  0.12  0.08
Marg1 0.56 -0.38 -0.16 -0.11 -0.02  0.00  0.01 -0.26 -0.23  0.14  0.00 -0.14
Marg2 0.48 -0.24 -0.04  0.00 -0.10  0.00 -0.17 -0.01  0.23  0.03  0.06 -0.03
Marg3 0.50 -0.22 -0.15 -0.19 -0.07  0.05  0.13 -0.13  0.26 -0.22  0.02 -0.10
Marg4 0.50 -0.18 -0.14 -0.17 -0.02  0.05  0.19 -0.05 -0.13 -0.04  0.12  0.06
Marg5 0.48 -0.24 -0.28  0.17  0.11  0.27 -0.30  0.11 -0.15 -0.20 -0.02  0.05
Marg6 0.54 -0.14 -0.08 -0.16 -0.01  0.07  0.10  0.24  0.06  0.10 -0.28  0.01
Marg7 0.39 -0.22 -0.25  0.05  0.14 -0.10  0.02  0.01  0.23  0.24  0.11  0.26
Str1  0.37  0.09  0.15  0.15 -0.04  0.06  0.02 -0.18  0.12 -0.01 -0.04 -0.01
Str2  0.35  0.05  0.25 -0.13 -0.13  0.15  0.12  0.15  0.07 -0.02 -0.09 -0.13
Str3  0.36 -0.11  0.36  0.16 -0.11  0.16 -0.03 -0.03 -0.01 -0.15 -0.02  0.17
Str4  0.25 -0.04  0.24  0.18 -0.01  0.36  0.23  0.03 -0.08  0.10  0.06  0.14
Str5  0.23 -0.01  0.27  0.12 -0.09  0.09 -0.15  0.01  0.09  0.12 -0.03 -0.12
Ang1  0.35 -0.23  0.37  0.22  0.15 -0.32  0.01 -0.12  0.06  0.05 -0.07  0.07
Ang2  0.29 -0.24  0.20 -0.08 -0.05 -0.24  0.02  0.35  0.01 -0.03  0.12 -0.06
Ang3  0.39 -0.15  0.20 -0.05  0.04 -0.19 -0.20  0.09 -0.21 -0.11  0.09 -0.01
       PA13   h2   u2 com
Obj1   0.15 0.74 0.26 5.0
Obj2   0.01 0.42 0.58 3.3
Obj3   0.01 0.42 0.58 3.2
Obj4   0.07 0.36 0.64 2.6
Obj5   0.02 0.87 0.13 4.6
Obj6   0.05 0.20 0.80 3.4
Obj7  -0.13 0.51 0.49 2.8
Obj8  -0.10 0.32 0.68 2.7
Obj9   0.21 0.40 0.60 5.9
Obj10 -0.25 0.45 0.55 5.2
Marg1  0.00 0.65 0.35 3.4
Marg2 -0.09 0.40 0.60 2.6
Marg3  0.09 0.54 0.46 3.8
Marg4  0.10 0.41 0.59 2.6
Marg5 -0.08 0.66 0.34 5.4
Marg6 -0.01 0.51 0.49 2.7
Marg7 -0.06 0.49 0.51 5.9
Str1  -0.13 0.26 0.74 3.1
Str2   0.05 0.31 0.69 4.5
Str3   0.01 0.39 0.61 4.2
Str4   0.08 0.38 0.62 5.2
Str5  -0.10 0.22 0.78 5.2
Ang1   0.15 0.54 0.46 5.7
Ang2  -0.09 0.40 0.60 5.2
Ang3   0.07 0.37 0.63 4.5

                       PA1  PA2  PA3  PA4  PA5  PA6  PA7  PA8  PA9 PA10 PA11
SS loadings           4.54 1.17 0.97 0.64 0.60 0.56 0.47 0.47 0.44 0.42 0.35
Proportion Var        0.18 0.05 0.04 0.03 0.02 0.02 0.02 0.02 0.02 0.02 0.01
Cumulative Var        0.18 0.23 0.27 0.29 0.32 0.34 0.36 0.38 0.39 0.41 0.43
Proportion Explained  0.40 0.10 0.09 0.06 0.05 0.05 0.04 0.04 0.04 0.04 0.03
Cumulative Proportion 0.40 0.51 0.60 0.65 0.71 0.76 0.80 0.84 0.88 0.92 0.95
                      PA12 PA13
SS loadings           0.31 0.27
Proportion Var        0.01 0.01
Cumulative Var        0.44 0.45
Proportion Explained  0.03 0.02
Cumulative Proportion 0.98 1.00

Mean item complexity =  4.1
Test of the hypothesis that 13 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 53  and the objective function was  0.09 

The root mean square of the residuals (RMSR) is  0.01 
The df corrected root mean square of the residuals is  0.02 

The harmonic n.obs is  259 with the empirical chi square  16.54  with prob &lt;  1 
The total n.obs was  259  with Likelihood Chi Square =  22.09  with prob &lt;  1 

Tucker Lewis Index of factoring reliability =  1.226
RMSEA index =  0  and the 90 % confidence intervals are  0 0
BIC =  -272.42
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   PA1  PA2  PA3  PA4  PA5  PA6
Correlation of (regression) scores with factors   0.95 0.85 0.82 0.81 0.79 0.73
Multiple R square of scores with factors          0.91 0.72 0.67 0.66 0.63 0.54
Minimum correlation of possible factor scores     0.81 0.44 0.34 0.32 0.26 0.07
                                                   PA7   PA8   PA9  PA10  PA11
Correlation of (regression) scores with factors   0.72  0.68  0.68  0.67  0.63
Multiple R square of scores with factors          0.51  0.47  0.46  0.45  0.39
Minimum correlation of possible factor scores     0.03 -0.06 -0.09 -0.10 -0.21
                                                   PA12  PA13
Correlation of (regression) scores with factors    0.62  0.58
Multiple R square of scores with factors           0.38  0.34
Minimum correlation of possible factor scores     -0.24 -0.33</code></pre>
<p><em>The total variance for a particular variable will have two factors:some variance will be shared with other variables (common variance) and some variance will be specific to that measure (unique variance). Random variance is also specific to one item, but not reliably so.</em></p>
<p>We can examine this most easily by examining the matrix (second screen).</p>
<p>The columns PA1 thru PA10 are the (uninteresting at this point) unrotated loadings. These are the loading from each factor to each variable. PA stands for “principal axis.”</p>
<p>Scrolling to the far right we are interested in:</p>
<p><strong>Communalities</strong> are represented as <span class="math inline">\(h^2\)</span>. These are the proportions of common variance present in the variables. A variable that has no specific (or random) variance would have a communality of 1.0. If a variable shares none of its variance with any other variable, its communality would be 0.0. As a point of comparison, in PCA these started as 1.0 because we extracted the same number of components as items. In PAF, because we must extract fewer factors than items, these will have unique values.</p>
<p>**Uniquenesses* are represented as <span class="math inline">\(u2\)</span>. These are the amount of unique variance for each variable. They are calculated as <span class="math inline">\(1 - h^2\)</span> (or 1 minus the communality).</p>
<p>The final column, <em>com</em> represents <em>item complexity.</em> This is an indication of how well an item reflects a single construct. If it is 1.0 then the item loads only on one component, if it is 2.0, it loads evenly on two components, and so forth. For now, we can ignore this. <em>I mostly wanted to reassure you that “com” is not “communality” – h2 is communality</em>.</p>
<p>Let’s switch to the first screen of output.</p>
<p><strong>Eigenvalues</strong> are displayed in the row called, <em>SS loadings</em> (i.e., the sum of squared loadings). They represent the variance explained by the particular linear component. PA1 explains 4.54 units of variance (out of a possible 25; the # of potential factors). As a proportion, this is 4.54/25 = 0.1816 (reported in the <em>Proportion Var</em> row).</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="PAF.html#cb375-1" tabindex="-1"></a><span class="fl">4.54</span><span class="sc">/</span><span class="dv">25</span></span></code></pre></div>
<pre><code>[1] 0.1816</code></pre>
<p>We inspect the eigenvalues to see how many are &gt; 1.0 (Kaiser’s eigenvalue &gt; 1 criteria criteria). We see there are two that meet Kaiser’s critera and three that meet Joliffe’s criteria (eigenvalues &gt; .77).</p>
<p><strong>Cumulative Var</strong> is helpful to determine how many factors we’d like to retain to balance parsimony (few as possible) with the amount of variance we want to explain. The eigenvalues are in descending order. Using both Kaiser’s criteria (eigenvalue &gt; 1.0), Joiliffe’s criteria (eigenvalue &gt; 0.7) criteria, and the a priori theory related to the Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> article, we landed on a four-factor solution. Extracting four factors (like we did with PCA will) will explain 29% of the variance. Eigenvalues are only one criteria, let’s look at the scree plot.</p>
<p><strong>Scree plot</strong>:<br />
Eigenvalues are stored in the <em>grmsPAF1</em> object’s variable, “values”. We can see all the values captured by this object with the <em>names()</em> function:</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="PAF.html#cb377-1" tabindex="-1"></a><span class="fu">names</span>(grmsPAF1)</span></code></pre></div>
<pre><code> [1] &quot;residual&quot;               &quot;dof&quot;                    &quot;chi&quot;                   
 [4] &quot;nh&quot;                     &quot;rms&quot;                    &quot;EPVAL&quot;                 
 [7] &quot;crms&quot;                   &quot;EBIC&quot;                   &quot;ESABIC&quot;                
[10] &quot;fit&quot;                    &quot;fit.off&quot;                &quot;sd&quot;                    
[13] &quot;factors&quot;                &quot;complexity&quot;             &quot;n.obs&quot;                 
[16] &quot;objective&quot;              &quot;criteria&quot;               &quot;STATISTIC&quot;             
[19] &quot;PVAL&quot;                   &quot;Call&quot;                   &quot;null.model&quot;            
[22] &quot;null.dof&quot;               &quot;null.chisq&quot;             &quot;TLI&quot;                   
[25] &quot;F0&quot;                     &quot;RMSEA&quot;                  &quot;BIC&quot;                   
[28] &quot;SABIC&quot;                  &quot;r.scores&quot;               &quot;R2&quot;                    
[31] &quot;valid&quot;                  &quot;score.cor&quot;              &quot;weights&quot;               
[34] &quot;rotation&quot;               &quot;hyperplane&quot;             &quot;communality&quot;           
[37] &quot;communalities&quot;          &quot;uniquenesses&quot;           &quot;values&quot;                
[40] &quot;e.values&quot;               &quot;loadings&quot;               &quot;model&quot;                 
[43] &quot;fm&quot;                     &quot;Structure&quot;              &quot;communality.iterations&quot;
[46] &quot;method&quot;                 &quot;scores&quot;                 &quot;R2.scores&quot;             
[49] &quot;r&quot;                      &quot;np.obs&quot;                 &quot;fn&quot;                    
[52] &quot;Vaccounted&quot;            </code></pre>
<p>Plotting the eigen<em>values</em> produces a scree plot. We can use this to further guage the number of factors we should extract.</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="PAF.html#cb379-1" tabindex="-1"></a><span class="fu">plot</span>(grmsPAF1<span class="sc">$</span>values, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>) <span class="co">#type = &quot;b&quot; gives us &quot;both&quot; lines and points;  type = &quot;l&quot; gives lines and is relatively worthless</span></span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We look for the point of <em>inflexion</em>. That is, where the baseline levels out into a plateau. I can see inflections after 1, 2, 3, and 4.</p>
<div id="specifying-the-number-of-factors" class="section level4 hasAnchor" number="9.5.2.1">
<h4><span class="header-section-number">9.5.2.1</span> Specifying the number of factors<a href="PAF.html#specifying-the-number-of-factors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Having determined the number of components, we must rerun the analysis with this specification. Especially when researchers may not have a clear theoretical structure that guides the process, researchers may do this iteratively with varying numbers of factors. Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">J. A. Lewis &amp; Neville, 2015</a>)</span> examined solutions with 2, 3, 4, and 5 factors (they conducted a parallel <em>factor</em> analysis; in contrast this lesson demonstrates principal axis factoring).</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="PAF.html#cb380-1" tabindex="-1"></a><span class="co"># grmsPAF2 &lt;- psych::fa(GRMSr, nfactors=4, fm = &#39;pa&#39;, rotate=&#39;none&#39;)</span></span>
<span id="cb380-2"><a href="PAF.html#cb380-2" tabindex="-1"></a>grmsPAF2 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co">#can copy prior script, but change nfactors and object name</span></span>
<span id="cb380-3"><a href="PAF.html#cb380-3" tabindex="-1"></a>grmsPAF2</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;none&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PA1   PA2   PA3   PA4   h2   u2 com
Obj1  0.46  0.24  0.05 -0.06 0.28 0.72 1.6
Obj2  0.45  0.36 -0.06  0.12 0.35 0.65 2.1
Obj3  0.45  0.16  0.11  0.04 0.24 0.76 1.4
Obj4  0.47  0.21 -0.11 -0.09 0.28 0.72 1.6
Obj5  0.48  0.12 -0.13  0.10 0.27 0.73 1.4
Obj6  0.31  0.14 -0.05 -0.13 0.13 0.87 1.8
Obj7  0.53  0.12  0.07 -0.08 0.30 0.70 1.2
Obj8  0.42  0.35 -0.11 -0.09 0.32 0.68 2.2
Obj9  0.29  0.21 -0.07  0.06 0.14 0.86 2.1
Obj10 0.38  0.23  0.07 -0.13 0.22 0.78 2.0
Marg1 0.54 -0.34 -0.19  0.01 0.44 0.56 2.0
Marg2 0.48 -0.25 -0.05  0.14 0.32 0.68 1.7
Marg3 0.49 -0.20 -0.16  0.04 0.30 0.70 1.6
Marg4 0.50 -0.17 -0.19 -0.09 0.32 0.68 1.6
Marg5 0.45 -0.16 -0.19  0.15 0.29 0.71 1.9
Marg6 0.53 -0.12 -0.10 -0.07 0.31 0.69 1.2
Marg7 0.38 -0.17 -0.24  0.08 0.23 0.77 2.3
Str1  0.38  0.08  0.19  0.23 0.24 0.76 2.3
Str2  0.35  0.03  0.23 -0.06 0.18 0.82 1.8
Str3  0.36 -0.14  0.39  0.12 0.32 0.68 2.5
Str4  0.24 -0.03  0.21  0.15 0.13 0.87 2.7
Str5  0.23 -0.02  0.31  0.14 0.17 0.83 2.3
Ang1  0.33 -0.19  0.27 -0.07 0.23 0.77 2.7
Ang2  0.29 -0.23  0.15 -0.27 0.23 0.77 3.5
Ang3  0.39 -0.16  0.16 -0.25 0.26 0.74 2.5

                       PA1  PA2  PA3  PA4
SS loadings           4.34 0.98 0.78 0.40
Proportion Var        0.17 0.04 0.03 0.02
Cumulative Var        0.17 0.21 0.24 0.26
Proportion Explained  0.67 0.15 0.12 0.06
Cumulative Proportion 0.67 0.82 0.94 1.00

Mean item complexity =  2
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA1  PA2  PA3   PA4
Correlation of (regression) scores with factors   0.93 0.77 0.72  0.59
Multiple R square of scores with factors          0.86 0.59 0.51  0.35
Minimum correlation of possible factor scores     0.72 0.17 0.03 -0.30</code></pre>
<p>Our eigenvalues/SS loadings wiggle around a bit from the initial run. With four factors, we now, cumulatively, explain 26% of the variance.</p>
<p><em>Communality</em> is the proportion of common variance within a variable. Changing from 13 to 4 factors changed these values (<span class="math inline">\(h2\)</span>) as well as their associated <em>uniquenesses</em> (<span class="math inline">\(u2\)</span>), which are calculated as “1.0 minus the communality.”</p>
<p>Now we see that 28% of the variance associated with Obj1 is common/shared (the <span class="math inline">\(h2\)</span> value).</p>
<p>As a reminder of what we are doing, recall that we are looking for a more <em>parsimonious</em> explanation than 25 items on the GRMS. By respecifying a smaller number of factors, we lose some information. That is, the retained factors (now 4) cannot explain all of the variance present in the data (as we saw, it explains about 28%, cumulatively). The amount of variance explained in each variable is represented by the communalities after extraction.</p>
<p>We can also inspect the communalities through the lens of Kaiser’s criterion (the eigenvalue &gt; 1 criteria) to see if we think that four was a good number of factors to extract.</p>
<p>Kaiser’s criterion is believed to be accurate if:</p>
<ul>
<li>when there are fewer than 30 variables (we had 25) and, after extraction, the communalities are greater than .70
<ul>
<li>looking at our data, none of the communalities is &gt; .70, so, this does not support extracting four components</li>
</ul></li>
<li>when the sample size is greater than 250 (ours was 259) and the average communality is &gt; .60
<ul>
<li>again, our communalities were lower than this</li>
</ul></li>
</ul>
<p>Using the <em>names()</em> function again, we see that “communality” is available for manipulation.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="PAF.html#cb382-1" tabindex="-1"></a><span class="fu">names</span>(grmsPAF2)</span></code></pre></div>
<pre><code> [1] &quot;residual&quot;               &quot;dof&quot;                    &quot;chi&quot;                   
 [4] &quot;nh&quot;                     &quot;rms&quot;                    &quot;EPVAL&quot;                 
 [7] &quot;crms&quot;                   &quot;EBIC&quot;                   &quot;ESABIC&quot;                
[10] &quot;fit&quot;                    &quot;fit.off&quot;                &quot;sd&quot;                    
[13] &quot;factors&quot;                &quot;complexity&quot;             &quot;n.obs&quot;                 
[16] &quot;objective&quot;              &quot;criteria&quot;               &quot;STATISTIC&quot;             
[19] &quot;PVAL&quot;                   &quot;Call&quot;                   &quot;null.model&quot;            
[22] &quot;null.dof&quot;               &quot;null.chisq&quot;             &quot;TLI&quot;                   
[25] &quot;F0&quot;                     &quot;RMSEA&quot;                  &quot;BIC&quot;                   
[28] &quot;SABIC&quot;                  &quot;r.scores&quot;               &quot;R2&quot;                    
[31] &quot;valid&quot;                  &quot;score.cor&quot;              &quot;weights&quot;               
[34] &quot;rotation&quot;               &quot;hyperplane&quot;             &quot;communality&quot;           
[37] &quot;communalities&quot;          &quot;uniquenesses&quot;           &quot;values&quot;                
[40] &quot;e.values&quot;               &quot;loadings&quot;               &quot;model&quot;                 
[43] &quot;fm&quot;                     &quot;Structure&quot;              &quot;communality.iterations&quot;
[46] &quot;method&quot;                 &quot;scores&quot;                 &quot;R2.scores&quot;             
[49] &quot;r&quot;                      &quot;np.obs&quot;                 &quot;fn&quot;                    
[52] &quot;Vaccounted&quot;            </code></pre>
<p>We can use this value to calculate their mean.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="PAF.html#cb384-1" tabindex="-1"></a><span class="fu">mean</span>(grmsPAF2<span class="sc">$</span>communality)</span></code></pre></div>
<pre><code>[1] 0.2599292</code></pre>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="PAF.html#cb386-1" tabindex="-1"></a><span class="co"># sum(grmsPAF2$communality) #</span></span></code></pre></div>
<p>We see that our average communality is 0.26. These two criteria suggest that we may not have the best solution. That said (in our defense):</p>
<ul>
<li>We used the scree plot as a guide and it was very clear.</li>
<li>We have an adequate sample size and that was supported with the KMO.</li>
<li>Are the number of factors consistent with theory? We have not yet inspected the factor loadings. This will provide us with more information.</li>
</ul>
<p>We could do several things:</p>
<ul>
<li>rerun with a different number of factors (recall Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> ran models with 2, 3, 4, and 5 factors)</li>
<li>conduct more diagnostics tests
<ul>
<li>reproduced correlation matrix</li>
<li>the difference between the reproduced correlation matrix and the correlation matrix in the data</li>
</ul></li>
</ul>
<p>The <em>factor.model()</em> function in <em>psych</em> produces the <em>reproduced correlation matrix</em> by using the <em>loadings</em> in our extracted object. Conceptually, this matrix is the correlations that should be produced if we did not have the raw data but we only had the factor loadings. We could do fancy matrix algebra and produce these.</p>
<p>The questions, though, is: How close did we get? How different is the <em>reproduced correlation matrix</em> from <em>GRMSmatrix</em> – the <span class="math inline">\(R\)</span>-matrix produced from our raw data.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="PAF.html#cb387-1" tabindex="-1"></a><span class="fu">round</span>(psych<span class="sc">::</span><span class="fu">factor.model</span>(grmsPAF2<span class="sc">$</span>loadings), <span class="dv">3</span>)  <span class="co">#produces the reproduced correlation matrix</span></span></code></pre></div>
<pre><code>       Obj1  Obj2  Obj3  Obj4  Obj5  Obj6  Obj7  Obj8  Obj9 Obj10 Marg1 Marg2
Obj1  0.275 0.282 0.250 0.263 0.238 0.181 0.279 0.275 0.177 0.241 0.157 0.149
Obj2  0.282 0.350 0.260 0.278 0.282 0.176 0.265 0.308 0.217 0.232 0.135 0.146
Obj3  0.250 0.260 0.245 0.229 0.228 0.153 0.262 0.230 0.160 0.212 0.170 0.177
Obj4  0.263 0.278 0.229 0.278 0.255 0.189 0.268 0.286 0.181 0.227 0.202 0.165
Obj5  0.238 0.282 0.228 0.255 0.275 0.160 0.250 0.250 0.181 0.189 0.244 0.221
Obj6  0.181 0.176 0.153 0.189 0.160 0.133 0.186 0.194 0.115 0.162 0.130 0.100
Obj7  0.279 0.265 0.262 0.268 0.250 0.186 0.302 0.261 0.168 0.243 0.230 0.208
Obj8  0.275 0.308 0.230 0.286 0.250 0.194 0.261 0.316 0.197 0.242 0.129 0.107
Obj9  0.177 0.217 0.160 0.181 0.181 0.115 0.168 0.197 0.136 0.146 0.100 0.098
Obj10 0.241 0.232 0.212 0.227 0.189 0.162 0.243 0.242 0.146 0.219 0.115 0.105
Marg1 0.157 0.135 0.170 0.202 0.244 0.130 0.230 0.129 0.100 0.115 0.444 0.357
Marg2 0.149 0.146 0.177 0.165 0.221 0.100 0.208 0.107 0.098 0.105 0.357 0.318
Marg3 0.166 0.163 0.173 0.200 0.235 0.127 0.218 0.149 0.113 0.125 0.362 0.298
Marg4 0.183 0.163 0.173 0.224 0.234 0.151 0.234 0.177 0.116 0.148 0.361 0.279
Marg5 0.149 0.175 0.163 0.184 0.238 0.108 0.192 0.140 0.119 0.102 0.338 0.290
Marg6 0.214 0.194 0.207 0.239 0.246 0.162 0.262 0.198 0.132 0.177 0.345 0.280
Marg7 0.114 0.134 0.120 0.159 0.200 0.095 0.153 0.119 0.095 0.077 0.306 0.246
Str1  0.190 0.217 0.215 0.154 0.192 0.092 0.205 0.146 0.127 0.147 0.146 0.187
Str2  0.185 0.148 0.187 0.151 0.138 0.110 0.210 0.138 0.090 0.165 0.139 0.144
Str3  0.146 0.104 0.188 0.087 0.118 0.060 0.192 0.049 0.055 0.118 0.172 0.209
Str4  0.107 0.106 0.134 0.073 0.102 0.044 0.128 0.056 0.059 0.082 0.104 0.135
Str5  0.108 0.092 0.139 0.056 0.080 0.036 0.130 0.041 0.047 0.087 0.074 0.120
Ang1  0.125 0.055 0.146 0.093 0.094 0.074 0.177 0.049 0.033 0.111 0.197 0.188
Ang2  0.100 0.002 0.097 0.093 0.061 0.085 0.154 0.047 0.008 0.102 0.202 0.150
Ang3  0.164 0.077 0.157 0.152 0.121 0.123 0.216 0.112 0.054 0.155 0.233 0.185
      Marg3 Marg4 Marg5 Marg6 Marg7  Str1  Str2  Str3  Str4  Str5  Ang1  Ang2
Obj1  0.166 0.183 0.149 0.214 0.114 0.190 0.185 0.146 0.107 0.108 0.125 0.100
Obj2  0.163 0.163 0.175 0.194 0.134 0.217 0.148 0.104 0.106 0.092 0.055 0.002
Obj3  0.173 0.173 0.163 0.207 0.120 0.215 0.187 0.188 0.134 0.139 0.146 0.097
Obj4  0.200 0.224 0.184 0.239 0.159 0.154 0.151 0.087 0.073 0.056 0.093 0.093
Obj5  0.235 0.234 0.238 0.246 0.200 0.192 0.138 0.118 0.102 0.080 0.094 0.061
Obj6  0.127 0.151 0.108 0.162 0.095 0.092 0.110 0.060 0.044 0.036 0.074 0.085
Obj7  0.218 0.234 0.192 0.262 0.153 0.205 0.210 0.192 0.128 0.130 0.177 0.154
Obj8  0.149 0.177 0.140 0.198 0.119 0.146 0.138 0.049 0.056 0.041 0.049 0.047
Obj9  0.113 0.116 0.119 0.132 0.095 0.127 0.090 0.055 0.059 0.047 0.033 0.008
Obj10 0.125 0.148 0.102 0.177 0.077 0.147 0.165 0.118 0.082 0.087 0.111 0.102
Marg1 0.362 0.361 0.338 0.345 0.306 0.146 0.139 0.172 0.104 0.074 0.197 0.202
Marg2 0.298 0.279 0.290 0.280 0.246 0.187 0.144 0.209 0.135 0.120 0.188 0.150
Marg3 0.304 0.303 0.290 0.295 0.258 0.149 0.129 0.148 0.097 0.072 0.157 0.151
Marg4 0.303 0.318 0.276 0.307 0.253 0.121 0.133 0.120 0.074 0.047 0.155 0.176
Marg5 0.290 0.276 0.291 0.268 0.256 0.158 0.103 0.131 0.098 0.068 0.122 0.097
Marg6 0.295 0.307 0.268 0.308 0.237 0.158 0.165 0.161 0.102 0.084 0.178 0.182
Marg7 0.258 0.253 0.256 0.237 0.234 0.103 0.068 0.075 0.058 0.025 0.088 0.087
Str1  0.149 0.121 0.158 0.158 0.103 0.239 0.166 0.228 0.164 0.175 0.146 0.055
Str2  0.129 0.133 0.103 0.165 0.068 0.166 0.180 0.205 0.123 0.143 0.177 0.143
Str3  0.148 0.120 0.131 0.161 0.075 0.228 0.205 0.318 0.191 0.225 0.244 0.160
Str4  0.097 0.074 0.098 0.102 0.058 0.164 0.123 0.191 0.125 0.141 0.131 0.065
Str5  0.072 0.047 0.068 0.084 0.025 0.175 0.143 0.225 0.141 0.169 0.155 0.080
Ang1  0.157 0.155 0.122 0.178 0.088 0.146 0.177 0.244 0.131 0.155 0.226 0.199
Ang2  0.151 0.176 0.097 0.182 0.087 0.055 0.143 0.160 0.065 0.080 0.199 0.230
Ang3  0.187 0.211 0.134 0.225 0.113 0.108 0.183 0.195 0.095 0.109 0.220 0.238
       Ang3
Obj1  0.164
Obj2  0.077
Obj3  0.157
Obj4  0.152
Obj5  0.121
Obj6  0.123
Obj7  0.216
Obj8  0.112
Obj9  0.054
Obj10 0.155
Marg1 0.233
Marg2 0.185
Marg3 0.187
Marg4 0.211
Marg5 0.134
Marg6 0.225
Marg7 0.113
Str1  0.108
Str2  0.183
Str3  0.195
Str4  0.095
Str5  0.109
Ang1  0.220
Ang2  0.238
Ang3  0.263</code></pre>
<p>We’re not really interested in this matrix. We just need it to compare it to the <em>GRMSmatrix</em> to produce the residuals. We do that next.</p>
<p><strong>Residuals</strong> are the difference between the reproduced (i.e., those created from our factor loadings) and <span class="math inline">\(R\)</span>-matrix produced by the raw data.</p>
<p>If we look at the <span class="math inline">\(r_{_{Obj1Obj2}}\)</span> in our original correlation matrix (theoretically from the raw data [although we simulated data]), the value is 0.30. The reproduced correlation for this pair is 0.282. The difference is 0.018. The residuals table below shows 0.020 (rounding error).</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="PAF.html#cb389-1" tabindex="-1"></a>.<span class="dv">30</span> <span class="sc">-</span> .<span class="dv">282</span></span></code></pre></div>
<pre><code>[1] 0.018</code></pre>
<p>By using the <em>factor.residuals()</em> function we can calculate the residuals. Here we will see this difference calculated for us, for all the elements in the matrix.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="PAF.html#cb391-1" tabindex="-1"></a><span class="fu">round</span>(psych<span class="sc">::</span><span class="fu">factor.residuals</span>(GRMSr, grmsPAF2<span class="sc">$</span>loadings), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>        Obj1   Obj2   Obj3   Obj4   Obj5   Obj6   Obj7   Obj8   Obj9  Obj10
Obj1   0.725  0.020 -0.009 -0.066  0.031 -0.005 -0.026  0.041 -0.061  0.017
Obj2   0.020  0.650  0.056 -0.034 -0.010  0.033 -0.023 -0.023  0.046 -0.041
Obj3  -0.009  0.056  0.755 -0.023 -0.008  0.036 -0.010 -0.019  0.010  0.018
Obj4  -0.066 -0.034 -0.023  0.722  0.103 -0.002  0.005 -0.012  0.045  0.032
Obj5   0.031 -0.010 -0.008  0.103  0.725 -0.005 -0.085 -0.001 -0.039 -0.003
Obj6  -0.005  0.033  0.036 -0.002 -0.005  0.867 -0.029 -0.004  0.024 -0.060
Obj7  -0.026 -0.023 -0.010  0.005 -0.085 -0.029  0.698  0.067  0.039  0.007
Obj8   0.041 -0.023 -0.019 -0.012 -0.001 -0.004  0.067  0.684 -0.039  0.014
Obj9  -0.061  0.046  0.010  0.045 -0.039  0.024  0.039 -0.039  0.864 -0.010
Obj10  0.017 -0.041  0.018  0.032 -0.003 -0.060  0.007  0.014 -0.010  0.781
Marg1  0.011 -0.056  0.081 -0.046  0.012  0.029  0.077 -0.005 -0.070 -0.019
Marg2  0.057  0.046  0.011 -0.037  0.010 -0.044 -0.029 -0.007 -0.021 -0.003
Marg3  0.027 -0.023 -0.020 -0.030 -0.012 -0.073 -0.016 -0.031  0.063  0.077
Marg4  0.023 -0.011  0.030  0.015 -0.020 -0.019 -0.023 -0.006 -0.046  0.021
Marg5 -0.057 -0.001 -0.031  0.019  0.012  0.017 -0.010  0.044  0.077 -0.045
Marg6  0.009  0.016 -0.093 -0.016 -0.002  0.057  0.052 -0.001 -0.013 -0.036
Marg7 -0.034  0.047 -0.011  0.029 -0.019  0.028 -0.021  0.014 -0.003 -0.004
Str1   0.000 -0.027 -0.028 -0.020  0.042 -0.030  0.057 -0.010  0.005  0.060
Str2   0.043  0.002 -0.004 -0.012 -0.026  0.029 -0.028 -0.034 -0.022 -0.001
Str3   0.031 -0.042 -0.033  0.015  0.008 -0.004 -0.042 -0.001 -0.004  0.050
Str4  -0.072  0.037  0.039  0.062 -0.036  0.038 -0.006 -0.024 -0.057 -0.026
Str5   0.019  0.021  0.027 -0.048  0.014  0.015  0.018  0.019 -0.025 -0.061
Ang1  -0.065 -0.040  0.002  0.050  0.013 -0.034  0.068  0.034  0.091 -0.051
Ang2  -0.054  0.045 -0.007 -0.018  0.025  0.060 -0.065 -0.014 -0.022  0.031
Ang3   0.047  0.027  0.023  0.037 -0.010 -0.016  0.014 -0.032  0.022 -0.018
       Marg1  Marg2  Marg3  Marg4  Marg5  Marg6  Marg7   Str1   Str2   Str3
Obj1   0.011  0.057  0.027  0.023 -0.057  0.009 -0.034  0.000  0.043  0.031
Obj2  -0.056  0.046 -0.023 -0.011 -0.001  0.016  0.047 -0.027  0.002 -0.042
Obj3   0.081  0.011 -0.020  0.030 -0.031 -0.093 -0.011 -0.028 -0.004 -0.033
Obj4  -0.046 -0.037 -0.030  0.015  0.019 -0.016  0.029 -0.020 -0.012  0.015
Obj5   0.012  0.010 -0.012 -0.020  0.012 -0.002 -0.019  0.042 -0.026  0.008
Obj6   0.029 -0.044 -0.073 -0.019  0.017  0.057  0.028 -0.030  0.029 -0.004
Obj7   0.077 -0.029 -0.016 -0.023 -0.010  0.052 -0.021  0.057 -0.028 -0.042
Obj8  -0.005 -0.007 -0.031 -0.006  0.044 -0.001  0.014 -0.010 -0.034 -0.001
Obj9  -0.070 -0.021  0.063 -0.046  0.077 -0.013 -0.003  0.005 -0.022 -0.004
Obj10 -0.019 -0.003  0.077  0.021 -0.045 -0.036 -0.004  0.060 -0.001  0.050
Marg1  0.556 -0.028 -0.002  0.052  0.012 -0.006 -0.025  0.024 -0.030 -0.034
Marg2 -0.028  0.682  0.051 -0.083  0.019  0.002  0.047 -0.003  0.008 -0.029
Marg3 -0.002  0.051  0.696  0.071 -0.045  0.016 -0.025  0.002  0.077  0.006
Marg4  0.052 -0.083  0.071  0.682 -0.007 -0.028 -0.008  0.006  0.038  0.009
Marg5  0.012  0.019 -0.045 -0.007  0.709  0.005 -0.022 -0.024 -0.041  0.074
Marg6 -0.006  0.002  0.016 -0.028  0.005  0.692  0.028 -0.042  0.115  0.011
Marg7 -0.025  0.047 -0.025 -0.008 -0.022  0.028  0.766  0.014 -0.081 -0.024
Str1   0.024 -0.003  0.002  0.006 -0.024 -0.042  0.014  0.761 -0.008 -0.005
Str2  -0.030  0.008  0.077  0.038 -0.041  0.115 -0.081 -0.008  0.820 -0.012
Str3  -0.034 -0.029  0.006  0.009  0.074  0.011 -0.024 -0.005 -0.012  0.682
Str4  -0.005 -0.067 -0.033  0.088  0.012  0.036 -0.004 -0.020  0.049  0.076
Str5   0.000  0.031 -0.021 -0.054  0.015  0.007  0.009  0.000  0.032 -0.035
Ang1   0.017 -0.002 -0.027 -0.041 -0.079 -0.051  0.097  0.039 -0.063  0.022
Ang2  -0.077  0.059 -0.012 -0.004  0.000  0.032  0.030 -0.003  0.019 -0.035
Ang3   0.016  0.015 -0.049 -0.015  0.087 -0.063 -0.034 -0.045 -0.066  0.023
        Str4   Str5   Ang1   Ang2   Ang3
Obj1  -0.072  0.019 -0.065 -0.054  0.047
Obj2   0.037  0.021 -0.040  0.045  0.027
Obj3   0.039  0.027  0.002 -0.007  0.023
Obj4   0.062 -0.048  0.050 -0.018  0.037
Obj5  -0.036  0.014  0.013  0.025 -0.010
Obj6   0.038  0.015 -0.034  0.060 -0.016
Obj7  -0.006  0.018  0.068 -0.065  0.014
Obj8  -0.024  0.019  0.034 -0.014 -0.032
Obj9  -0.057 -0.025  0.091 -0.022  0.022
Obj10 -0.026 -0.061 -0.051  0.031 -0.018
Marg1 -0.005  0.000  0.017 -0.077  0.016
Marg2 -0.067  0.031 -0.002  0.059  0.015
Marg3 -0.033 -0.021 -0.027 -0.012 -0.049
Marg4  0.088 -0.054 -0.041 -0.004 -0.015
Marg5  0.012  0.015 -0.079  0.000  0.087
Marg6  0.036  0.007 -0.051  0.032 -0.063
Marg7 -0.004  0.009  0.097  0.030 -0.034
Str1  -0.020  0.000  0.039 -0.003 -0.045
Str2   0.049  0.032 -0.063  0.019 -0.066
Str3   0.076 -0.035  0.022 -0.035  0.023
Str4   0.875 -0.029 -0.007 -0.028 -0.055
Str5  -0.029  0.831 -0.006  0.032  0.008
Ang1  -0.007 -0.006  0.774  0.029  0.044
Ang2  -0.028  0.032  0.029  0.770  0.027
Ang3  -0.055  0.008  0.044  0.027  0.737</code></pre>
<p>There are several strategies to evaluate this matrix:</p>
<ul>
<li>see how large the residuals are, compared to the original correlations
<ul>
<li>the worst possible model would occur if we extracted no factors and would be the size of the original correlations</li>
<li>if the correlations were small to start with, we expect small residuals</li>
<li>if the correlations were large to start with, the residuals will be relatively larger (this is not terribly problematic)</li>
</ul></li>
<li>comparing residuals requires squaring them first (because residuals can be both positive and negative)
<ul>
<li>the sum of the squared residuals divided by the sum of the squared correlations is an estimate of model fit. Subtracting this from 1.0 means that it ranges from 0 to 1. Values &gt; .95 are an indication of good fit.</li>
</ul></li>
</ul>
<p>Analyzing the residuals means we need to extract only the upper right of the triangle them into an object. We can do this in steps.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="PAF.html#cb393-1" tabindex="-1"></a>grmsPAF2_resids <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">factor.residuals</span>(GRMSr, grmsPAF2<span class="sc">$</span>loadings)  <span class="co">#first extract the resids</span></span>
<span id="cb393-2"><a href="PAF.html#cb393-2" tabindex="-1"></a>grmsPAF2_resids <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(grmsPAF2_resids[<span class="fu">upper.tri</span>(grmsPAF2_resids)])  <span class="co">#the object has the residuals in a single column</span></span>
<span id="cb393-3"><a href="PAF.html#cb393-3" tabindex="-1"></a><span class="fu">head</span>(grmsPAF2_resids)</span></code></pre></div>
<pre><code>             [,1]
[1,]  0.019934198
[2,] -0.008859929
[3,]  0.055526063
[4,] -0.066056926
[5,] -0.034252440
[6,] -0.023167960</code></pre>
<p>One criteria of residual analysis is to see how many residuals there are that are greater than an absolute value of 0.05. The result will be a single column with TRUE if it is &gt; |0.05| and false if it is smaller. The sum function will tell us how many TRUE responses are in the matrix. Further, we can write script to obtain the proportion of total number of residuals.</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="PAF.html#cb395-1" tabindex="-1"></a>large.resid <span class="ot">&lt;-</span> <span class="fu">abs</span>(grmsPAF2_resids) <span class="sc">&gt;</span> <span class="fl">0.05</span></span>
<span id="cb395-2"><a href="PAF.html#cb395-2" tabindex="-1"></a><span class="co"># large.resid</span></span>
<span id="cb395-3"><a href="PAF.html#cb395-3" tabindex="-1"></a><span class="fu">sum</span>(large.resid)</span></code></pre></div>
<pre><code>[1] 55</code></pre>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="PAF.html#cb397-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sum</span>(large.resid)<span class="sc">/</span><span class="fu">nrow</span>(grmsPAF2_resids), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>[1] 0.183</code></pre>
<p>We learn that there are 55 residuals greater than the absolute value of 0.05. This represents 18% of the total number of residuals.</p>
<p>There are no hard rules about what proportion of residuals can be greater than 0.05. Field recommends that it stay below 50% <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span>.</p>
<p>Another approach to analyzing residuals is to look at their mean. Because of the +/- valences, we need to square them (to eliminate the negative), take the average, then take the square root.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="PAF.html#cb399-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="fu">mean</span>(grmsPAF2_resids<span class="sc">^</span><span class="dv">2</span>)), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>[1] 0.038</code></pre>
<p>While there are no clear guidelines to interpret these, one recommendation is to consider extracting more components if the value is higher than 0.08 <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span>.</p>
<p>Finally, we expect our residuals to be normally distributed. A histogram can help us inspect the distribution.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="PAF.html#cb401-1" tabindex="-1"></a><span class="fu">hist</span>(grmsPAF2_resids)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Not bad! It looks reasonably normal. No outliers.</p>
</div>
<div id="quick-recap-of-how-to-evaluate-the-of-factors-we-extracted" class="section level4 hasAnchor" number="9.5.2.2">
<h4><span class="header-section-number">9.5.2.2</span> Quick recap of how to evaluate the # of factors we extracted<a href="PAF.html#quick-recap-of-how-to-evaluate-the-of-factors-we-extracted" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>If fewer than 30 variables, the eigenvalue &gt; 1 (Kaiser’s) critera is fine, so long as communalities are all &gt; .70.</li>
<li>If sample size &gt; 250 and the average communalitie are .6 or greater, this is fine.</li>
<li>When <em>N</em> &gt; 200, the scree plot can be used.</li>
<li>Regarding residuals
<ul>
<li>fewer than 50% should have absolute values &gt; 0.05</li>
<li>model fit should be &gt; 0.90</li>
</ul></li>
</ul>
</div>
</div>
<div id="factor-rotation" class="section level3 hasAnchor" number="9.5.3">
<h3><span class="header-section-number">9.5.3</span> Factor Rotation<a href="PAF.html#factor-rotation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The original solution of a principal components or principal axis factor analysis is a set of vectors that best account for the observed covariance or correlation matrix. Each additional component or factor accounts for progressively less and less variance. The solution is efficient (yay) but difficult to interpret (boo).</p>
<p>Thanks to Thurstone’s five rules toward a simple structure (circa 1947), interpretation of a matrix is facilitaed by <em>rotation</em> (multiplying a matrix by a matrix of orthogonal vectors that preserve the communalities of each variable). Both the original matrix and the solution will be orthogonal.</p>
<p><em>Parsimony</em> becomes a statistical consideration (an equation, in fact) and goal and is maximized when each variable has a 1.0 loading on one factor and the rest are zero.</p>
<p>Different rotation strategies emphasize different goals related to parsimony:</p>
<p><em>Quartimax</em> seeks to maximize the notion of variable parsimony (each variable is associated with one factor) and permits the rotation toward a general factor (ignoring smaller factors).
<em>Varimax</em> maximizes the variance of squared loadings taken over items instead of over factors and <em>avoids</em> a general factor.</p>
<p>Rotation improves the interpretation of the factor by maximizing the loading on each variable on one of the extracted factors while minimizing the loading on all other factors Rotation works by changing the absolute values of the variables while keeping their differential values constant.</p>
<p>There are two big choices (to be made on theoretical grounds):</p>
<ul>
<li>Orthogonal rotation if you think that the factors are independent/unrelated.
<ul>
<li>varimax is the most common orthogonal rotation</li>
</ul></li>
<li>Oblique rotation if you think that the factors are related/correlated.
<ul>
<li>oblimin and promax are common oblique rotations</li>
</ul></li>
</ul>
<div id="orthogonal-rotation-1" class="section level4 hasAnchor" number="9.5.3.1">
<h4><span class="header-section-number">9.5.3.1</span> Orthogonal rotation<a href="PAF.html#orthogonal-rotation-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="PAF.html#cb402-1" tabindex="-1"></a><span class="co"># grmsPAF2ORTH &lt;- psych::fa(GRMSr, nfactors = 4, fm = &#39;pa&#39;, rotate =</span></span>
<span id="cb402-2"><a href="PAF.html#cb402-2" tabindex="-1"></a><span class="co"># &#39;varimax&#39;)</span></span>
<span id="cb402-3"><a href="PAF.html#cb402-3" tabindex="-1"></a>grmsPAF2ORTH <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb402-4"><a href="PAF.html#cb402-4" tabindex="-1"></a>grmsPAF2ORTH</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;varimax&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PA2  PA1  PA3   PA4   h2   u2 com
Obj1  0.47 0.10 0.17  0.13 0.28 0.72 1.5
Obj2  0.54 0.14 0.16 -0.11 0.35 0.65 1.4
Obj3  0.38 0.14 0.27  0.09 0.24 0.76 2.2
Obj4  0.47 0.21 0.04  0.10 0.28 0.72 1.5
Obj5  0.40 0.32 0.13 -0.02 0.27 0.73 2.2
Obj6  0.32 0.11 0.01  0.13 0.13 0.87 1.6
Obj7  0.42 0.19 0.21  0.21 0.30 0.70 2.5
Obj8  0.55 0.10 0.00  0.04 0.32 0.68 1.1
Obj9  0.34 0.11 0.07 -0.06 0.14 0.86 1.4
Obj10 0.42 0.04 0.12  0.17 0.22 0.78 1.5
Marg1 0.10 0.61 0.10  0.22 0.44 0.56 1.4
Marg2 0.09 0.49 0.25  0.11 0.32 0.68 1.7
Marg3 0.17 0.50 0.11  0.14 0.30 0.70 1.5
Marg4 0.22 0.47 0.02  0.22 0.32 0.68 1.9
Marg5 0.16 0.50 0.12  0.01 0.29 0.71 1.3
Marg6 0.26 0.42 0.11  0.23 0.31 0.69 2.5
Marg7 0.13 0.47 0.02  0.03 0.23 0.77 1.2
Str1  0.24 0.14 0.40 -0.03 0.24 0.76 1.9
Str2  0.22 0.06 0.28  0.23 0.18 0.82 3.0
Str3  0.05 0.11 0.51  0.20 0.32 0.68 1.4
Str4  0.08 0.09 0.33  0.04 0.13 0.87 1.3
Str5  0.06 0.01 0.40  0.08 0.17 0.83 1.1
Ang1  0.04 0.15 0.31  0.32 0.23 0.77 2.4
Ang2  0.03 0.15 0.10  0.44 0.23 0.77 1.3
Ang3  0.14 0.17 0.16  0.43 0.26 0.74 1.8

                       PA2  PA1  PA3  PA4
SS loadings           2.27 2.11 1.22 0.91
Proportion Var        0.09 0.08 0.05 0.04
Cumulative Var        0.09 0.17 0.22 0.26
Proportion Explained  0.35 0.32 0.19 0.14
Cumulative Proportion 0.35 0.67 0.86 1.00

Mean item complexity =  1.7
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA2  PA1  PA3   PA4
Correlation of (regression) scores with factors   0.82 0.81 0.72  0.67
Multiple R square of scores with factors          0.68 0.66 0.52  0.45
Minimum correlation of possible factor scores     0.36 0.33 0.03 -0.10</code></pre>
<p>Essentially, we have the same information as before, except that loadings are calculated after rotation (which adjusts the absolute values of the factor loadings while keeping their differential vales constant). Our communality and uniqueness values remain the same. The eigenvalues (SS loadings) should even out, but the proportion of variance explained and cumulative variance (39%) will remain the same.</p>
<p>The <em>print.psych()</em> function facilitates interpretation and prioritizes the information about which we care most:</p>
<ul>
<li>“cut” will display loadings above .3, this allows us to see
<ul>
<li>if some items load on no factors</li>
<li>if some items have cross-loadings (and their relative weights)</li>
</ul></li>
<li>“sort” will reorder the loadings to make it clearer (to the best of its ability…in the case of ties) to which factor/scale it belongs</li>
</ul>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="PAF.html#cb404-1" tabindex="-1"></a>grmsPAF2_table <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(grmsPAF2ORTH, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;varimax&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
      item  PA2  PA1  PA3   PA4   h2   u2 com
Obj8     8 0.55                 0.32 0.68 1.1
Obj2     2 0.54                 0.35 0.65 1.4
Obj4     4 0.47                 0.28 0.72 1.5
Obj1     1 0.47                 0.28 0.72 1.5
Obj7     7 0.42                 0.30 0.70 2.5
Obj10   10 0.42                 0.22 0.78 1.5
Obj5     5 0.40 0.32            0.27 0.73 2.2
Obj3     3 0.38                 0.24 0.76 2.2
Obj9     9 0.34                 0.14 0.86 1.4
Obj6     6 0.32                 0.13 0.87 1.6
Marg1   11      0.61            0.44 0.56 1.4
Marg5   15      0.50            0.29 0.71 1.3
Marg3   13      0.50            0.30 0.70 1.5
Marg2   12      0.49            0.32 0.68 1.7
Marg4   14      0.47            0.32 0.68 1.9
Marg7   17      0.47            0.23 0.77 1.2
Marg6   16      0.42            0.31 0.69 2.5
Str3    20           0.51       0.32 0.68 1.4
Str1    18           0.40       0.24 0.76 1.9
Str5    22           0.40       0.17 0.83 1.1
Str4    21           0.33       0.13 0.87 1.3
Str2    19                      0.18 0.82 3.0
Ang2    24                 0.44 0.23 0.77 1.3
Ang3    25                 0.43 0.26 0.74 1.8
Ang1    23           0.31  0.32 0.23 0.77 2.4

                       PA2  PA1  PA3  PA4
SS loadings           2.27 2.11 1.22 0.91
Proportion Var        0.09 0.08 0.05 0.04
Cumulative Var        0.09 0.17 0.22 0.26
Proportion Explained  0.35 0.32 0.19 0.14
Cumulative Proportion 0.35 0.67 0.86 1.00

Mean item complexity =  1.7
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA2  PA1  PA3   PA4
Correlation of (regression) scores with factors   0.82 0.81 0.72  0.67
Multiple R square of scores with factors          0.68 0.66 0.52  0.45
Minimum correlation of possible factor scores     0.36 0.33 0.03 -0.10</code></pre>
<p>In the unrotated solution, most variables loaded on the first component. After rotation, there are four clear components/scales. Further, there is clear (or at least reasonable) component/scale membership for each item and few cross-loadings. Something curious has happened to Str2 – it has no loadings at all! Looking back at the PCA with an orthogonal rotation, Str2 had cross-loadings with two factors.</p>
<p>If this were a new scale and we had not yet established ideas for subscales, the next step is to look back at the items, themselves, and try to name the scales/components. If our scale construction included a priori/planned subscales, here’s where we hope the items fall where they were hypothesized to do so. Our simulated data worked perfectly and replicated the four scales that Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">J. A. Lewis &amp; Neville, 2015</a>)</span> reported in the article.</p>
<ul>
<li>Assumptions of Beauty and Sexual Objectification</li>
<li>Silenced and Marginalized</li>
<li>Strong Woman Stereotype</li>
<li>Angry Woman Stereotype</li>
</ul>
<p>We can also create a figure of the result. Note the direction of the arrows from the factor (latent variable) to the items in PAF – in PCA the arrows went from item to component.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="PAF.html#cb406-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(grmsPAF2ORTH)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>We can extract the factor loadings and write them to a table. This can be useful in preparing an APA style table for a manuscript or presentation.</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="PAF.html#cb407-1" tabindex="-1"></a><span class="co"># names(grmsPAF2ORTH)</span></span>
<span id="cb407-2"><a href="PAF.html#cb407-2" tabindex="-1"></a>pafORTH_table <span class="ot">&lt;-</span> <span class="fu">round</span>(grmsPAF2ORTH<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb407-3"><a href="PAF.html#cb407-3" tabindex="-1"></a><span class="fu">write.table</span>(pafORTH_table, <span class="at">file =</span> <span class="st">&quot;pafORTH_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb407-4"><a href="PAF.html#cb407-4" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb407-5"><a href="PAF.html#cb407-5" tabindex="-1"></a>pafORTH_table</span></code></pre></div>
<pre><code>
Loadings:
      PA2    PA1    PA3    PA4   
Obj1   0.471  0.103  0.166  0.126
Obj2   0.540  0.140  0.162 -0.111
Obj3   0.385  0.136  0.265       
Obj4   0.472  0.206         0.104
Obj5   0.396  0.318  0.130       
Obj6   0.322  0.109         0.133
Obj7   0.421  0.193  0.209  0.210
Obj8   0.551  0.103              
Obj9   0.340  0.112              
Obj10  0.420         0.116  0.167
Marg1  0.105  0.612  0.104  0.218
Marg2         0.486  0.247  0.112
Marg3  0.169  0.495  0.108  0.138
Marg4  0.218  0.471         0.220
Marg5  0.159  0.500  0.124       
Marg6  0.265  0.419  0.107  0.228
Marg7  0.126  0.466              
Str1   0.239  0.140  0.402       
Str2   0.222         0.276  0.225
Str3          0.114  0.512  0.202
Str4                 0.331       
Str5                 0.398       
Ang1          0.147  0.313  0.324
Ang2          0.150  0.102  0.443
Ang3   0.139  0.175  0.157  0.434

                 PA2   PA1   PA3   PA4
SS loadings    2.266 2.105 1.217 0.911
Proportion Var 0.091 0.084 0.049 0.036
Cumulative Var 0.091 0.175 0.224 0.260</code></pre>
</div>
<div id="oblique-rotation-1" class="section level4 hasAnchor" number="9.5.3.2">
<h4><span class="header-section-number">9.5.3.2</span> Oblique rotation<a href="PAF.html#oblique-rotation-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Whereas the orthogonal rotation sought to maximize the independence/unrelatedness of the coponents, an oblique rotation will allow them to be correlated. Researchers often explore both solutions but only report one.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="PAF.html#cb409-1" tabindex="-1"></a><span class="co"># grmsPAF2obl &lt;- psych::fa(GRMSr, nfactors = 4, fm = &#39;pa&#39;, rotate =</span></span>
<span id="cb409-2"><a href="PAF.html#cb409-2" tabindex="-1"></a><span class="co"># &#39;oblimin&#39;)</span></span>
<span id="cb409-3"><a href="PAF.html#cb409-3" tabindex="-1"></a>grmsPAF2obl <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span></code></pre></div>
<pre><code>Loading required namespace: GPArotation</code></pre>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="PAF.html#cb411-1" tabindex="-1"></a>grmsPAF2obl</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
        PA2   PA1   PA3   PA4   h2   u2 com
Obj1   0.48 -0.02  0.09  0.07 0.28 0.72 1.1
Obj2   0.55  0.03  0.07 -0.18 0.35 0.65 1.3
Obj3   0.37  0.03  0.21  0.01 0.24 0.76 1.6
Obj4   0.47  0.12 -0.06  0.05 0.28 0.72 1.2
Obj5   0.34  0.27  0.03 -0.12 0.27 0.73 2.2
Obj6   0.33  0.04 -0.06  0.11 0.13 0.87 1.3
Obj7   0.40  0.09  0.13  0.13 0.30 0.70 1.5
Obj8   0.59 -0.01 -0.10  0.01 0.32 0.68 1.1
Obj9   0.34  0.05  0.01 -0.10 0.14 0.86 1.2
Obj10  0.45 -0.08  0.05  0.14 0.22 0.78 1.3
Marg1 -0.05  0.66  0.00  0.08 0.44 0.56 1.0
Marg2 -0.05  0.51  0.18 -0.03 0.32 0.68 1.3
Marg3  0.05  0.52  0.02  0.02 0.30 0.70 1.0
Marg4  0.12  0.48 -0.08  0.12 0.32 0.68 1.3
Marg5  0.03  0.53  0.03 -0.11 0.29 0.71 1.1
Marg6  0.18  0.40  0.01  0.12 0.31 0.69 1.6
Marg7  0.01  0.51 -0.07 -0.07 0.23 0.77 1.1
Str1   0.18  0.06  0.38 -0.14 0.24 0.76 1.8
Str2   0.21 -0.03  0.25  0.16 0.18 0.82 2.7
Str3  -0.03  0.04  0.53  0.09 0.32 0.68 1.1
Str4   0.03  0.04  0.33 -0.04 0.13 0.87 1.1
Str5   0.02 -0.05  0.42  0.00 0.17 0.83 1.0
Ang1  -0.03  0.10  0.31  0.24 0.23 0.77 2.2
Ang2  -0.01  0.13  0.08  0.40 0.23 0.77 1.3
Ang3   0.10  0.12  0.12  0.37 0.26 0.74 1.6

                       PA2  PA1  PA3  PA4
SS loadings           2.33 2.30 1.20 0.66
Proportion Var        0.09 0.09 0.05 0.03
Cumulative Var        0.09 0.19 0.23 0.26
Proportion Explained  0.36 0.35 0.19 0.10
Cumulative Proportion 0.36 0.71 0.90 1.00

 With factor correlations of 
     PA2  PA1  PA3  PA4
PA2 1.00 0.47 0.33 0.09
PA1 0.47 1.00 0.36 0.27
PA3 0.33 0.36 1.00 0.23
PA4 0.09 0.27 0.23 1.00

Mean item complexity =  1.4
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA2  PA1  PA3   PA4
Correlation of (regression) scores with factors   0.87 0.88 0.78  0.68
Multiple R square of scores with factors          0.76 0.78 0.61  0.47
Minimum correlation of possible factor scores     0.52 0.56 0.23 -0.07</code></pre>
<p>We can make it a little easier to interpret by removing all factor loadings below .30.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="PAF.html#cb413-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">print.psych</span>(grmsPAF2obl, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
      item   PA2   PA1   PA3   PA4   h2   u2 com
Obj8     8  0.59                   0.32 0.68 1.1
Obj2     2  0.55                   0.35 0.65 1.3
Obj1     1  0.48                   0.28 0.72 1.1
Obj4     4  0.47                   0.28 0.72 1.2
Obj10   10  0.45                   0.22 0.78 1.3
Obj7     7  0.40                   0.30 0.70 1.5
Obj3     3  0.37                   0.24 0.76 1.6
Obj5     5  0.34                   0.27 0.73 2.2
Obj9     9  0.34                   0.14 0.86 1.2
Obj6     6  0.33                   0.13 0.87 1.3
Marg1   11        0.66             0.44 0.56 1.0
Marg5   15        0.53             0.29 0.71 1.1
Marg3   13        0.52             0.30 0.70 1.0
Marg7   17        0.51             0.23 0.77 1.1
Marg2   12        0.51             0.32 0.68 1.3
Marg4   14        0.48             0.32 0.68 1.3
Marg6   16        0.40             0.31 0.69 1.6
Str3    20              0.53       0.32 0.68 1.1
Str5    22              0.42       0.17 0.83 1.0
Str1    18              0.38       0.24 0.76 1.8
Str4    21              0.33       0.13 0.87 1.1
Ang1    23              0.31       0.23 0.77 2.2
Str2    19                         0.18 0.82 2.7
Ang2    24                    0.40 0.23 0.77 1.3
Ang3    25                    0.37 0.26 0.74 1.6

                       PA2  PA1  PA3  PA4
SS loadings           2.33 2.30 1.20 0.66
Proportion Var        0.09 0.09 0.05 0.03
Cumulative Var        0.09 0.19 0.23 0.26
Proportion Explained  0.36 0.35 0.19 0.10
Cumulative Proportion 0.36 0.71 0.90 1.00

 With factor correlations of 
     PA2  PA1  PA3  PA4
PA2 1.00 0.47 0.33 0.09
PA1 0.47 1.00 0.36 0.27
PA3 0.33 0.36 1.00 0.23
PA4 0.09 0.27 0.23 1.00

Mean item complexity =  1.4
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA2  PA1  PA3   PA4
Correlation of (regression) scores with factors   0.87 0.88 0.78  0.68
Multiple R square of scores with factors          0.76 0.78 0.61  0.47
Minimum correlation of possible factor scores     0.52 0.56 0.23 -0.07</code></pre>
<p>The factor structure differs a bit. The Ang items are split between two factors. Again, Str2 has no factor loadings. Additionally, because our specification included “sort=TRUE”, the relative weights wiggled around and so the items are listed in a different order than in the orthogonal rotation.</p>
<p>The oblique rotation allows us to see the correlation between the factors/scales. This was not available in the orthogonal rotation because the assumption of the orthogonal/varimax rotation is that the scales/factors are uncorrelated; hence in the analysis they were fixed to 0.0.</p>
<p>We can see that all the scales have almost no relation with each other. That is, the the correlations range between 0.09 to 0.47.</p>
<p>Of course there is always a little complexity. In oblique rotations, there is a distinction between the <em>pattern</em> matrix (which reports factor loadings and is comparable to the matrix we interpreted for the orthogonal rotation) and the <em>structure</em> matrix (takes into account the relationship between the factors/scales – it is a product of the pattern matrix and the matrix containing the correlation coefficients between the factors/scales). Most interpret the pattern matrix because it is simpler; however it could be that values in the pattern matrix are suppressed because of relations between the factors. Therefore, the structure matrix can be a useful check and some editors will request it.</p>
<p>Obtaining the structure matrix requires two steps. First, multiply the factor loadings with the phi matrix.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="PAF.html#cb415-1" tabindex="-1"></a>grmsPAF2obl<span class="sc">$</span>loadings <span class="sc">%*%</span> grmsPAF2obl<span class="sc">$</span>Phi</span></code></pre></div>
<pre><code>            PA2       PA1        PA3          PA4
Obj1  0.5117768 0.2623780 0.25894758  0.131327445
Obj2  0.5652440 0.2614637 0.22061708 -0.103410346
Obj3  0.4496925 0.2807825 0.34047371  0.098382643
Obj4  0.5118597 0.3325313 0.14601126  0.113266310
Obj5  0.4668753 0.4065387 0.21448069 -0.004545714
Obj6  0.3444817 0.2078771 0.09157767  0.137305996
Obj7  0.4977523 0.3599345 0.32409226  0.222044585
Obj8  0.5538851 0.2351906 0.09469550  0.041663770
Obj9  0.3571910 0.1849101 0.11600401 -0.049653291
Obj10 0.4437917 0.1891586 0.20387746  0.168147070
Marg1 0.2667675 0.6599847 0.24370246  0.254854162
Marg2 0.2443037 0.5404013 0.33965745  0.143501312
Marg3 0.2971065 0.5493661 0.22274243  0.167137489
Marg4 0.3318382 0.5421759 0.16003431  0.245973715
Marg5 0.2812631 0.5274537 0.21175354  0.041944192
Marg6 0.3802024 0.5199470 0.24118171  0.251867664
Marg7 0.2261903 0.4737589 0.10625875  0.052607361
Str1  0.3235913 0.2477221 0.43009276 -0.015627556
Str2  0.2914882 0.2047585 0.34849429  0.231678214
Str3  0.1755369 0.2463368 0.55516637  0.216374544
Str4  0.1555775 0.1626701 0.34786493  0.047592268
Str5  0.1378062 0.1115899 0.40915323  0.087193633
Ang1  0.1466244 0.2675128 0.39209800  0.337320941
Ang2  0.1116268 0.2590113 0.21376799  0.452992854
Ang3  0.2335740 0.3157820 0.28220912  0.444879719</code></pre>
<p>Next, use Field’s <span class="citation">(<a href="#ref-field_discovering_2012">2012</a>)</span> function to produce the matrix.</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="PAF.html#cb417-1" tabindex="-1"></a><span class="co"># Field&#39;s function to produce the structure matrix</span></span>
<span id="cb417-2"><a href="PAF.html#cb417-2" tabindex="-1"></a>factor.structure <span class="ot">&lt;-</span> <span class="cf">function</span>(fa, <span class="at">cut =</span> <span class="fl">0.2</span>, <span class="at">decimals =</span> <span class="dv">2</span>) {</span>
<span id="cb417-3"><a href="PAF.html#cb417-3" tabindex="-1"></a>    structure.matrix <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa.sort</span>(fa<span class="sc">$</span>loadings <span class="sc">%*%</span> fa<span class="sc">$</span>Phi)</span>
<span id="cb417-4"><a href="PAF.html#cb417-4" tabindex="-1"></a>    structure.matrix <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(structure.matrix) <span class="sc">&lt;</span> cut,</span>
<span id="cb417-5"><a href="PAF.html#cb417-5" tabindex="-1"></a>        <span class="st">&quot;&quot;</span>, <span class="fu">round</span>(structure.matrix, decimals)))</span>
<span id="cb417-6"><a href="PAF.html#cb417-6" tabindex="-1"></a>    <span class="fu">return</span>(structure.matrix)</span>
<span id="cb417-7"><a href="PAF.html#cb417-7" tabindex="-1"></a>}</span>
<span id="cb417-8"><a href="PAF.html#cb417-8" tabindex="-1"></a></span>
<span id="cb417-9"><a href="PAF.html#cb417-9" tabindex="-1"></a><span class="fu">factor.structure</span>(grmsPAF2obl, <span class="at">cut =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<pre><code>       PA2  PA1  PA3  PA4
Obj2  0.57               
Obj8  0.55               
Obj4  0.51 0.33          
Obj1  0.51               
Obj7   0.5 0.36 0.32     
Obj5  0.47 0.41          
Obj3  0.45      0.34     
Obj10 0.44               
Obj9  0.36               
Obj6  0.34               
Marg1      0.66          
Marg3      0.55          
Marg4 0.33 0.54          
Marg2      0.54 0.34     
Marg5      0.53          
Marg6 0.38 0.52          
Marg7      0.47          
Str3            0.56     
Str1  0.32      0.43     
Str5            0.41     
Ang1            0.39 0.34
Str2            0.35     
Str4            0.35     
Ang2                 0.45
Ang3       0.32      0.44</code></pre>
<p>Although some of the relative values changed, our items were stable regarding their component membership.</p>
</div>
</div>
<div id="factor-scores" class="section level3 hasAnchor" number="9.5.4">
<h3><span class="header-section-number">9.5.4</span> Factor Scores<a href="PAF.html#factor-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Factor <em>scores</em> (PA scores) can be created for each case (row) on each component (column). These can be used to assess the relative standing of one person on the construct/variable to another. We can also use them in regression (in place of means or sums) when groups of predictors correlate so highly that there is multicolliearity.</p>
<p>Computation involves multiplying an individual’s item-level response by the component loadings we obtained through the PAF process. The results will be one score per component for each row/case.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="PAF.html#cb419-1" tabindex="-1"></a><span class="co"># in all of this, don&#39;t forget to be specifiying the datset that has</span></span>
<span id="cb419-2"><a href="PAF.html#cb419-2" tabindex="-1"></a><span class="co"># the reverse-coded item replaced</span></span>
<span id="cb419-3"><a href="PAF.html#cb419-3" tabindex="-1"></a>grmsPAF2obl <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>,</span>
<span id="cb419-4"><a href="PAF.html#cb419-4" tabindex="-1"></a>    <span class="at">scores =</span> <span class="cn">TRUE</span>)</span>
<span id="cb419-5"><a href="PAF.html#cb419-5" tabindex="-1"></a><span class="fu">head</span>(grmsPAF2obl<span class="sc">$</span>scores, <span class="dv">10</span>)  <span class="co">#shows us only the first 10 (of N = 2571)</span></span></code></pre></div>
<pre><code>             PA2        PA1         PA3        PA4
 [1,] -0.6699528 -0.5575643 -0.55243623 -0.3342807
 [2,]  0.2744146 -0.9566521  0.58955654 -0.1364487
 [3,]  0.4226985  0.6280590  0.51242085  0.2482677
 [4,] -0.6921922 -1.0455498 -0.01224736 -0.8670751
 [5,] -0.4401667  0.9678210 -1.21941588 -0.1755326
 [6,] -0.1246221  0.8492276  0.11362900  0.5588851
 [7,]  0.3611167  0.1384934 -0.67560774 -0.7922718
 [8,] -1.2134910 -0.8242205  0.46592064  1.4000547
 [9,] -0.7439952 -1.1541284 -0.78862308  0.4794409
[10,] -0.2601972 -0.1055672 -0.61634040  0.6119441</code></pre>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="PAF.html#cb421-1" tabindex="-1"></a>items <span class="ot">&lt;-</span> <span class="fu">cbind</span>(items, grmsPAF2obl<span class="sc">$</span>scores)  <span class="co">#adds them to our raw dataset</span></span></code></pre></div>
<p>To bring this full circle, we can see the correlation of the component scores; the pattern maps onto what we saw previously in the correlations between factors in the oblique rotation.</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="PAF.html#cb422-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">corr.test</span>(items[<span class="fu">c</span>(<span class="st">&quot;PA1&quot;</span>, <span class="st">&quot;PA2&quot;</span>, <span class="st">&quot;PA3&quot;</span>, <span class="st">&quot;PA4&quot;</span>)])</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = items[c(&quot;PA1&quot;, &quot;PA2&quot;, &quot;PA3&quot;, &quot;PA4&quot;)])
Correlation matrix 
     PA1  PA2  PA3  PA4
PA1 1.00 0.60 0.52 0.44
PA2 0.60 1.00 0.49 0.20
PA3 0.52 0.49 1.00 0.44
PA4 0.44 0.20 0.44 1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
    PA1 PA2 PA3 PA4
PA1   0   0   0   0
PA2   0   0   0   0
PA3   0   0   0   0
PA4   0   0   0   0

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<p>We can extract the factor loadings and write them to a table. This can be useful in preparing an APA style table for a manuscript or presentation.</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="PAF.html#cb424-1" tabindex="-1"></a><span class="co"># names(grmsPAF2obl)</span></span>
<span id="cb424-2"><a href="PAF.html#cb424-2" tabindex="-1"></a>pafOBL_table <span class="ot">&lt;-</span> <span class="fu">round</span>(grmsPAF2obl<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb424-3"><a href="PAF.html#cb424-3" tabindex="-1"></a><span class="fu">write.table</span>(pafOBL_table, <span class="at">file =</span> <span class="st">&quot;pafOBL_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb424-4"><a href="PAF.html#cb424-4" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb424-5"><a href="PAF.html#cb424-5" tabindex="-1"></a>pafOBL_table</span></code></pre></div>
<pre><code>
Loadings:
      PA2    PA1    PA3    PA4   
Obj1   0.484                     
Obj2   0.546               -0.179
Obj3   0.366         0.207       
Obj4   0.472  0.119              
Obj5   0.342  0.265        -0.116
Obj6   0.334                0.108
Obj7   0.401         0.130  0.130
Obj8   0.590                     
Obj9   0.341                     
Obj10  0.451                0.135
Marg1         0.663              
Marg2         0.508  0.179       
Marg3         0.517              
Marg4  0.120  0.482         0.123
Marg5         0.532        -0.113
Marg6  0.177  0.399         0.124
Marg7         0.511              
Str1   0.183         0.379 -0.136
Str2   0.206         0.254  0.162
Str3                 0.529       
Str4                 0.333       
Str5                 0.420       
Ang1          0.102  0.308  0.241
Ang2          0.127         0.401
Ang3   0.101  0.123  0.118  0.375

                 PA2   PA1   PA3   PA4
SS loadings    2.090 2.058 1.030 0.579
Proportion Var 0.084 0.082 0.041 0.023
Cumulative Var 0.084 0.166 0.207 0.230</code></pre>
<p>We can also obtain a figure of this PAF with oblique rotation.</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="PAF.html#cb426-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(grmsPAF2obl)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
</div>
</div>
<div id="apa-style-results-1" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> APA Style Results<a href="PAF.html#apa-style-results-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Results</strong></p>
<blockquote>
<p>The dimensionality of the 25 items from the Gendered Racial Microagressions Scale for Black Women was analyzed using principal axis factoring. First, data screening evaluated the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00 – values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was .84, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi ^{1}(300)=1113.30, p &lt; .001\)</span>, indicating the correlations between items are sufficiently large enough for principal axis factoring. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.01140 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
<blockquote>
<p>Four criteria were used to determine the number of factors to rotate: a priori theory, the scree test, the Eigenvalue-greater-than-one criteria, and the interpretability of the solution. Kaiser’s eigenvalue-greater-than-one criteria suggested two components, and, in combination explained 23% of the variance. The scree plot was showed an inflexion that would justified retaining between one and four components. A priori theory based on Lewis and Neville’s <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> psychometric evaluation, suggested four components. Based on the convergence of these decisions, four components were extracted. We investigated each with orthogonal (varimax) and oblique (oblimin) procedures. Given the correspondence of the orthogonal solution with the original research, we selected this as our final model.</p>
</blockquote>
<blockquote>
<p>The rotated solution, as shown in Table 1 and Figure 1, yielded four interpretable components, each listed with the proportion of variance accounted for: assumptions of beauty and sexual objectification (9%), silenced and marginalized (8%), strong woman stereotype (5%), and angry woman stereotype (4%).</p>
</blockquote>
<p>Regarding the Table 1, I would include a table with ALL the values, bolding those with component membership. This will be easy because we exported all those values to a .csv file.</p>
<div id="comparing-fa-and-pca" class="section level3 hasAnchor" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Comparing FA and PCA<a href="PAF.html#comparing-fa-and-pca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>FA drives a mathematical solution from which factors are estimated
<ul>
<li>Only FA can estimate underlying factors, but it relies on the various assumptions to be met</li>
</ul></li>
<li>PCA decomposes the original data into a set of linear variates
<ul>
<li>This limits its concern to establishing which linear components exist within the data and how a particular variable might contribute to that component</li>
</ul></li>
<li>Generally, FA and PCA result in similar solutions
<ul>
<li>When there are 30 or more variables and communalities are &gt; .7 for all variables, different solutions are unlikely (Stevens, 2002)</li>
<li>When there are &lt; 20 variables and low communalities (&lt; .4) different solutions are likely to emerge</li>
<li>Both are inferential statistics</li>
</ul></li>
<li>Critics of PCA suggest
<ul>
<li>“at best it is a common factor analysis with some error added and at worst an unrecognizable hodgepodge of things from which nothing can be determined” (Cliff, 1987, p. 349)</li>
<li>PCA should never be described as FA and the resulting components should not be treated as reverently as true, latent variable, <em>factors</em></li>
<li>To most of us (i.e., scientist-practitioners), the difference is largely from the algorithm used to drive the solutions. This is true for Field <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span> also, who uses the terms interchangeably. My take: use whichever you like, just be precise in the language describing what you did.</li>
</ul></li>
</ul>
</div>
</div>
<div id="going-back-to-the-future-what-then-is-omega" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Going Back to the Future: What, then, is Omega?<a href="PAF.html#going-back-to-the-future-what-then-is-omega" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we’ve had an introduction to factor analysis, let’s revisit the <span class="math inline">\(\omega\)</span> grouping of reliability estimates. In the context of <em>psychometrics</em>, it may be useful to think of factors as scales/subscales where <em>g</em> refers to the amount of variance in the <em>general</em> factor (or total scale score) and subcales to be items that have something in common that is separate from what is <em>g</em>.</p>
<p>Model-based estimates examine the correlations or covariances of the items and decompose the test variance into that which is:</p>
<ul>
<li>common to all items (<strong>g</strong>, a general factor),</li>
<li>specific to some items (<strong>f</strong>, orthogonal group factors), and</li>
<li>unique to each item (confounding <strong>s</strong> specific, and <strong>e</strong> error variance)</li>
</ul>
<p>In the <em>psych</em> package</p>
<ul>
<li><span class="math inline">\(\omega_{t}\)</span> represents the total reliability of the test (<span class="math inline">\(\omega_{t}\)</span>)
<ul>
<li>In the <em>psych</em> package, this is calculated from a bifactor model where there is one general <em>g</em> factor (i.e., each item loads on the single general factor), one or more group factors (<em>f</em>), and an item-specific factor (<em>s</em>).</li>
</ul></li>
<li><span class="math inline">\(\omega_{h}\)</span> extracts a higher order factor from the correlation matrix of lower level factors, then applies the Schmid and Leiman (1957) transformation to find the general loadings on the original items. Stated another way, it is a measure o f the general factor saturation (<em>g</em>; the amount of variance attributable to one comon factor). The subscript “h” acknowledges the hierarchical nature of the approach.
<ul>
<li>the <span class="math inline">\(\omega_{h}\)</span> approach is exploratory and defined if there are three or more group factors (with only two group factors, the default is to assume they are equally important, hence the factor loadings of those subscales will be equal)</li>
<li>Najera Catalan <span class="citation">(<a href="#ref-najera_catalan_reliability_2019">Najera Catalan, 2019</a>)</span> suggests that <span class="math inline">\(\omega_{h}\)</span> is the best measure of reliability when dealing with multiple dimensions.</li>
</ul></li>
<li><span class="math inline">\(\omega_{g}\)</span> is an estimate that uses a bifactor solution via the SEM package <em>lavaan</em> and tends to be a larger (because it forces all the cross loadings of lower level factors to be 0)
<ul>
<li>the <span class="math inline">\(\omega_{g}\)</span> is confirmatory, requiring the specification of which variables load on each group factor</li>
</ul></li>
<li><em>psych::omegaSem()</em> reports both EFA and CFA solutions
<ul>
<li>We will use the <em>psych::omegaSem()</em> function</li>
</ul></li>
</ul>
<p>Note that in our specification, we indicate there are two factors. We do not tell it (anywhere!) what items belong to what factors (think, <em>subscales</em>). One test will be to see if the items align with their respective factors.</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="PAF.html#cb427-1" tabindex="-1"></a><span class="co"># Because we added the component scores to our df (and now it has</span></span>
<span id="cb427-2"><a href="PAF.html#cb427-2" tabindex="-1"></a><span class="co"># more variables than just our items), I will estimate omegaSem with</span></span>
<span id="cb427-3"><a href="PAF.html#cb427-3" tabindex="-1"></a><span class="co"># the correlation matrix; I will need to tell it the n.obs</span></span>
<span id="cb427-4"><a href="PAF.html#cb427-4" tabindex="-1"></a></span>
<span id="cb427-5"><a href="PAF.html#cb427-5" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">omegaSem</span>(GRMSr, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">n.obs =</span> <span class="dv">259</span>)</span></code></pre></div>
<pre><code>Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING:
    Could not compute standard errors! The information matrix could
    not be inverted. This may be a symptom that the model is not
    identified.</code></pre>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-37-1.png" width="672" /><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-37-2.png" width="672" /></p>
<pre><code> 
Call: psych::omegaSem(m = GRMSr, nfactors = 4, n.obs = 259)
Omega 
Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, 
    digits = digits, title = title, sl = sl, labels = labels, 
    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, 
    covar = covar)
Alpha:                 0.83 
G.6:                   0.85 
Omega Hierarchical:    0.58 
Omega H asymptotic:    0.68 
Omega Total            0.85 

Schmid Leiman Factor loadings greater than  0.2 
         g   F1*   F2*   F3*   F4*   h2   u2   p2
Obj1  0.34  0.39                   0.27 0.73 0.41
Obj2  0.32  0.45                   0.35 0.65 0.29
Obj3  0.35  0.30                   0.24 0.76 0.50
Obj4  0.35  0.39                   0.28 0.72 0.43
Obj5  0.38  0.28                   0.27 0.73 0.53
Obj6  0.23  0.27                   0.13 0.87 0.40
Obj7  0.41  0.33                   0.30 0.70 0.56
Obj8  0.29  0.48                   0.32 0.68 0.26
Obj9  0.21  0.28                   0.14 0.86 0.32
Obj10 0.27  0.37                   0.22 0.78 0.34
Marg1 0.51        0.42             0.44 0.56 0.58
Marg2 0.45        0.32             0.32 0.68 0.63
Marg3 0.44        0.33             0.31 0.69 0.63
Marg4 0.44        0.31             0.32 0.68 0.61
Marg5 0.41        0.34             0.29 0.71 0.58
Marg6 0.46        0.25             0.31 0.69 0.68
Marg7 0.34        0.32             0.23 0.77 0.51
Str1  0.31              0.33       0.24 0.76 0.40
Str2  0.28              0.22       0.18 0.82 0.46
Str3  0.33              0.45       0.32 0.68 0.33
Str4  0.21              0.29       0.13 0.87 0.35
Str5  0.20              0.35       0.17 0.83 0.23
Ang1  0.31              0.25  0.24 0.23 0.77 0.41
Ang2  0.26                    0.39 0.23 0.77 0.29
Ang3  0.34                    0.37 0.27 0.73 0.42

With Sums of squares  of:
   g  F1*  F2*  F3*  F4* 
3.00 1.39 0.83 0.73 0.53 

general/max  2.17   max/min =   2.6
mean percent general =  0.45    with sd =  0.13 and cv of  0.29 
Explained Common Variance of the general factor =  0.46 

The degrees of freedom are 206  and the fit is  0.82 
The number of observations was  259  with Chi Square =  201.42  with prob &lt;  0.58
The root mean square of the residuals is  0.04 
The df corrected root mean square of the residuals is  0.05
RMSEA index =  0  and the 10 % confidence intervals are  0 0.025
BIC =  -943.28

Compare this with the adequacy of just a general factor and no group factors
The degrees of freedom for just the general factor are 275  and the fit is  1.69 
The number of observations was  259  with Chi Square =  418.67  with prob &lt;  0.00000005
The root mean square of the residuals is  0.08 
The df corrected root mean square of the residuals is  0.09 

RMSEA index =  0.045  and the 10 % confidence intervals are  0.036 0.053
BIC =  -1109.45 

Measures of factor score adequacy             
                                                 g  F1*   F2*   F3*   F4*
Correlation of scores with factors            0.78 0.74  0.59  0.65  0.62
Multiple R square of scores with factors      0.61 0.55  0.35  0.42  0.39
Minimum correlation of factor score estimates 0.22 0.10 -0.30 -0.15 -0.23

 Total, General and Subset omega for each subset
                                                 g  F1*  F2*  F3*  F4*
Omega total for total scores and subscales    0.85 0.74 0.75 0.55 0.37
Omega general for total scores and subscales  0.58 0.33 0.47 0.24 0.14
Omega group for total scores and subscales    0.18 0.41 0.27 0.31 0.23

 The following analyses were done using the  lavaan  package 

 Omega Hierarchical from a confirmatory model using sem =  0.69
 Omega Total  from a confirmatory model using sem =  0.85 
With loadings of 
         g  F1*  F2*  F3*  F4*   h2   u2   p2
Obj1  0.41 0.31                0.27 0.73 0.62
Obj2  0.33 0.46                0.32 0.68 0.34
Obj3  0.40 0.26                0.23 0.77 0.70
Obj4  0.40 0.33                0.26 0.74 0.62
Obj5  0.42 0.27                0.24 0.76 0.73
Obj6  0.27 0.22                0.12 0.88 0.61
Obj7  0.51 0.20                0.31 0.69 0.84
Obj8  0.31 0.46                0.31 0.69 0.31
Obj9  0.22 0.29                0.13 0.87 0.37
Obj10 0.34 0.28                0.19 0.81 0.61
Marg1 0.49      0.44           0.43 0.57 0.56
Marg2 0.44      0.30           0.28 0.72 0.69
Marg3 0.43      0.38           0.33 0.67 0.56
Marg4 0.43      0.36           0.32 0.68 0.58
Marg5 0.38      0.34           0.26 0.74 0.56
Marg6 0.51      0.22           0.31 0.69 0.84
Marg7 0.29      0.36           0.21 0.79 0.40
Str1  0.37                     0.17 0.83 0.81
Str2  0.38                     0.16 0.84 0.90
Str3  0.35           0.53      0.40 0.60 0.31
Str4  0.22           0.34      0.16 0.84 0.30
Str5  0.24           0.23      0.11 0.89 0.52
Ang1  0.36           0.22      0.18 0.82 0.72
Ang2  0.31                0.71 0.59 0.41 0.16
Ang3  0.42                     0.21 0.79 0.84

With sum of squared loadings of:
   g  F1*  F2*  F3*  F4* 
3.55 1.02 0.85 0.55 0.53 

The degrees of freedom of the confirmatory model are  250  and the fit is  256.6602  with p =  0.3725889
general/max  3.47   max/min =   1.92
mean percent general =  0.58    with sd =  0.2 and cv of  0.35 
Explained Common Variance of the general factor =  0.55 

Measures of factor score adequacy             
                                                 g  F1*   F2*   F3*  F4*
Correlation of scores with factors            0.85 0.72  0.67  0.64 0.77
Multiple R square of scores with factors      0.73 0.51  0.46  0.41 0.59
Minimum correlation of factor score estimates 0.45 0.03 -0.09 -0.18 0.19

 Total, General and Subset omega for each subset
                                                 g  F1*  F2*  F3*  F4*
Omega total for total scores and subscales    0.85 0.75 0.75 0.57 0.53
Omega general for total scores and subscales  0.69 0.43 0.45 0.33 0.21
Omega group for total scores and subscales    0.15 0.32 0.30 0.24 0.32

To get the standard sem fit statistics, ask for summary on the fitted object</code></pre>
<p>There’s a ton of output! How do we make sense of it?</p>
<p>First, our items aligned perfectly with their respective factors (subscales). That is, it would be problematic if the items switched factors.</p>
<p>Second, we can interpret our results. Like alpha, the omegas range from 0 to 1, where values closer to 1 represent good reliability <span class="citation">(<a href="#ref-najera_catalan_reliability_2019">Najera Catalan, 2019</a>)</span>. For unidimensional measures, <span class="math inline">\(\omega_{t}\)</span> values above 0.80 seem to be an indicator of good reliability. For multidimensional measures with well-defined dimensions we strive for <span class="math inline">\(\omega_{h}\)</span> values above 0.65 (and <span class="math inline">\(\omega_{t}\)</span> &gt; 0.8). These recommendations are based on a Monte Carlo study that examined a host of reliability indicators and how their values corresponded with accurate predictions of poverty status. With this in mind, let’s examine the output related to our simulated research vignette.</p>
<p>Let’s examine the output in the lower portion where the values are “from a confirmatory model using sem.”</p>
<p>Omega is a reliability estimate for factor analysis that represents the proportion of variance in the GRMS scale attributable to common variance (rather than error). The omega for the total reliability of the test (<span class="math inline">\(\omega_{t}\)</span>; which included the general factors and the subscale factors) was .85, meaning that 85% of the variance in the total scale is due to the factors and 15% (100% - 85%) is attributable to error.</p>
<p>Omega hierarchical (<span class="math inline">\(\omega_{h}\)</span>) estimates are the proportion of variance in the GRMS score attributable to the general factor, which in effect treats the subscales as error. <span class="math inline">\(\omega_{h}\)</span> for the the GRMS total scale was .69 A quick calculation with <span class="math inline">\(\omega_{h}\)</span> (.69) and <span class="math inline">\(\omega_{t}\)</span> (.85; .69/.85 = .81) lets us know that that 81% of the reliable variance in the GRMS total scale is attributable to the general factor.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="PAF.html#cb430-1" tabindex="-1"></a>.<span class="dv">69</span><span class="sc">/</span>.<span class="dv">85</span></span></code></pre></div>
<pre><code>[1] 0.8117647</code></pre>
<p>Amongst the output is the Cronbach’s alpha coefficient (.83). Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> did not report omega results. They reported an alpha of .92 for the version of the GRMS that assessed stress appraisal.</p>
</div>
<div id="comparing-pfa-to-item-analysis-and-pca" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Comparing PFA to Item Analysis and PCA<a href="PAF.html#comparing-pfa-to-item-analysis-and-pca" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the lesson on PCA, we began a table that compared our item analysis (item corrected-total correlations with item-other scale correlations) and PCA results (both orthogonal and oblique). Let’s now add our PAF results (both orthogonal and oblique).</p>
<p>In the prior lecture, I saved the file as both .rds and .csv objects. I will bring back in the .rds object and add to it.</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="PAF.html#cb432-1" tabindex="-1"></a>GRMScomps <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;GRMS_Comparisons.rds&quot;</span>)</span>
<span id="cb432-2"><a href="PAF.html#cb432-2" tabindex="-1"></a>grmsPAF2ORTH</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 4, rotate = &quot;varimax&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PA2  PA1  PA3   PA4   h2   u2 com
Obj1  0.47 0.10 0.17  0.13 0.28 0.72 1.5
Obj2  0.54 0.14 0.16 -0.11 0.35 0.65 1.4
Obj3  0.38 0.14 0.27  0.09 0.24 0.76 2.2
Obj4  0.47 0.21 0.04  0.10 0.28 0.72 1.5
Obj5  0.40 0.32 0.13 -0.02 0.27 0.73 2.2
Obj6  0.32 0.11 0.01  0.13 0.13 0.87 1.6
Obj7  0.42 0.19 0.21  0.21 0.30 0.70 2.5
Obj8  0.55 0.10 0.00  0.04 0.32 0.68 1.1
Obj9  0.34 0.11 0.07 -0.06 0.14 0.86 1.4
Obj10 0.42 0.04 0.12  0.17 0.22 0.78 1.5
Marg1 0.10 0.61 0.10  0.22 0.44 0.56 1.4
Marg2 0.09 0.49 0.25  0.11 0.32 0.68 1.7
Marg3 0.17 0.50 0.11  0.14 0.30 0.70 1.5
Marg4 0.22 0.47 0.02  0.22 0.32 0.68 1.9
Marg5 0.16 0.50 0.12  0.01 0.29 0.71 1.3
Marg6 0.26 0.42 0.11  0.23 0.31 0.69 2.5
Marg7 0.13 0.47 0.02  0.03 0.23 0.77 1.2
Str1  0.24 0.14 0.40 -0.03 0.24 0.76 1.9
Str2  0.22 0.06 0.28  0.23 0.18 0.82 3.0
Str3  0.05 0.11 0.51  0.20 0.32 0.68 1.4
Str4  0.08 0.09 0.33  0.04 0.13 0.87 1.3
Str5  0.06 0.01 0.40  0.08 0.17 0.83 1.1
Ang1  0.04 0.15 0.31  0.32 0.23 0.77 2.4
Ang2  0.03 0.15 0.10  0.44 0.23 0.77 1.3
Ang3  0.14 0.17 0.16  0.43 0.26 0.74 1.8

                       PA2  PA1  PA3  PA4
SS loadings           2.27 2.11 1.22 0.91
Proportion Var        0.09 0.08 0.05 0.04
Cumulative Var        0.09 0.17 0.22 0.26
Proportion Explained  0.35 0.32 0.19 0.14
Cumulative Proportion 0.35 0.67 0.86 1.00

Mean item complexity =  1.7
Test of the hypothesis that 4 factors are sufficient.

df null model =  300  with the objective function =  4.47 with Chi Square =  1113.3
df of  the model are 206  and the objective function was  0.82 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic n.obs is  259 with the empirical chi square  223.39  with prob &lt;  0.19 
The total n.obs was  259  with Likelihood Chi Square =  201.39  with prob &lt;  0.58 

Tucker Lewis Index of factoring reliability =  1.008
RMSEA index =  0  and the 90 % confidence intervals are  0 0.025
BIC =  -943.32
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   PA2  PA1  PA3   PA4
Correlation of (regression) scores with factors   0.82 0.81 0.72  0.67
Multiple R square of scores with factors          0.68 0.66 0.52  0.45
Minimum correlation of possible factor scores     0.36 0.33 0.03 -0.10</code></pre>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="PAF.html#cb434-1" tabindex="-1"></a><span class="co"># names(grmsPAF2ORTH) I had to add &#39;unclass&#39; to the loadings to</span></span>
<span id="cb434-2"><a href="PAF.html#cb434-2" tabindex="-1"></a><span class="co"># render them into a df</span></span>
<span id="cb434-3"><a href="PAF.html#cb434-3" tabindex="-1"></a>pafORTH_loadings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">unclass</span>(grmsPAF2ORTH<span class="sc">$</span>loadings))</span>
<span id="cb434-4"><a href="PAF.html#cb434-4" tabindex="-1"></a>pafORTH_loadings<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>,</span>
<span id="cb434-5"><a href="PAF.html#cb434-5" tabindex="-1"></a>    <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>,</span>
<span id="cb434-6"><a href="PAF.html#cb434-6" tabindex="-1"></a>    <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>,</span>
<span id="cb434-7"><a href="PAF.html#cb434-7" tabindex="-1"></a>    <span class="st">&quot;Strong5&quot;</span>, <span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)  <span class="co">#Item names for joining (and to make sure we know which variable is which)</span></span>
<span id="cb434-8"><a href="PAF.html#cb434-8" tabindex="-1"></a>pafORTH_loadings <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">rename</span>(pafORTH_loadings, <span class="at">PAF_OR_Mar =</span> PA1, <span class="at">PAF_OR_Obj =</span> PA2,</span>
<span id="cb434-9"><a href="PAF.html#cb434-9" tabindex="-1"></a>    <span class="at">PAF_OR_Ang =</span> PA3, <span class="at">PAF_OR_Str =</span> PA4)</span>
<span id="cb434-10"><a href="PAF.html#cb434-10" tabindex="-1"></a><span class="co"># I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb434-11"><a href="PAF.html#cb434-11" tabindex="-1"></a>GRMScomps <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">full_join</span>(GRMScomps, pafORTH_loadings, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb434-12"><a href="PAF.html#cb434-12" tabindex="-1"></a></span>
<span id="cb434-13"><a href="PAF.html#cb434-13" tabindex="-1"></a><span class="co"># Now adding the PAF oblique loadings</span></span>
<span id="cb434-14"><a href="PAF.html#cb434-14" tabindex="-1"></a>pafOBLQ_loadings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">unclass</span>(grmsPAF2obl<span class="sc">$</span>loadings))  <span class="co">#I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb434-15"><a href="PAF.html#cb434-15" tabindex="-1"></a>pafOBLQ_loadings<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>,</span>
<span id="cb434-16"><a href="PAF.html#cb434-16" tabindex="-1"></a>    <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>,</span>
<span id="cb434-17"><a href="PAF.html#cb434-17" tabindex="-1"></a>    <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>,</span>
<span id="cb434-18"><a href="PAF.html#cb434-18" tabindex="-1"></a>    <span class="st">&quot;Strong5&quot;</span>, <span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)</span>
<span id="cb434-19"><a href="PAF.html#cb434-19" tabindex="-1"></a></span>
<span id="cb434-20"><a href="PAF.html#cb434-20" tabindex="-1"></a><span class="co"># Item names for joining (and to make sure we know which variable is</span></span>
<span id="cb434-21"><a href="PAF.html#cb434-21" tabindex="-1"></a><span class="co"># which)</span></span>
<span id="cb434-22"><a href="PAF.html#cb434-22" tabindex="-1"></a>pafOBLQ_loadings <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">rename</span>(pafOBLQ_loadings, <span class="at">PAF_OB_Mar =</span> PA1, <span class="at">PAF_OB_Obj =</span> PA2,</span>
<span id="cb434-23"><a href="PAF.html#cb434-23" tabindex="-1"></a>    <span class="at">PAF_OB_Ang =</span> PA3, <span class="at">PAF_OB_Str =</span> PA4)</span>
<span id="cb434-24"><a href="PAF.html#cb434-24" tabindex="-1"></a></span>
<span id="cb434-25"><a href="PAF.html#cb434-25" tabindex="-1"></a><span class="co"># I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb434-26"><a href="PAF.html#cb434-26" tabindex="-1"></a>GRMScomps <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">full_join</span>(GRMScomps, pafOBLQ_loadings, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb434-27"><a href="PAF.html#cb434-27" tabindex="-1"></a></span>
<span id="cb434-28"><a href="PAF.html#cb434-28" tabindex="-1"></a><span class="co"># Writes the table to a .csv file where you can open it with Excel</span></span>
<span id="cb434-29"><a href="PAF.html#cb434-29" tabindex="-1"></a><span class="co"># and format )</span></span>
<span id="cb434-30"><a href="PAF.html#cb434-30" tabindex="-1"></a><span class="fu">write.csv</span>(GRMScomps, <span class="at">file =</span> <span class="st">&quot;GRMS_Comps.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">row.names =</span> <span class="cn">FALSE</span>,</span>
<span id="cb434-31"><a href="PAF.html#cb434-31" tabindex="-1"></a>    <span class="at">col.names =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Warning in write.csv(GRMScomps, file = &quot;GRMS_Comps.csv&quot;, sep = &quot;,&quot;, row.names =
FALSE, : attempt to set &#39;col.names&#39; ignored</code></pre>
<pre><code>Warning in write.csv(GRMScomps, file = &quot;GRMS_Comps.csv&quot;, sep = &quot;,&quot;, row.names =
FALSE, : attempt to set &#39;sep&#39; ignored</code></pre>
<p>As a research vignette, this has worked extremely well, modeling consistency across the item analysis, principal components analysis (PCA), and principal axis factoring (PAF). That is, items load highest on their own scale (whether it is a component or factor), have no cross-loadings, and do not switch scale memberships from analysis to analysis.</p>
<div class="float">
<img src="images/PAF/GRMScomps.png" alt="Comparison of path models for PCA and EFA" />
<div class="figcaption">Comparison of path models for PCA and EFA</div>
</div>
</div>
<div id="practice-problems-7" class="section level2 hasAnchor" number="9.9">
<h2><span class="header-section-number">9.9</span> Practice Problems<a href="PAF.html#practice-problems-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. In the <em>ReCentering Psych Stats: Psychometrics</em> OER, it would be ideal if you have selected a dataset you can utilize across the lessons. The least complex is to change the random seed in the research and rework the problem demonstrated in the lesson. The most complex is to use data of your own. In either case, please plan to:</p>
<ul>
<li>Properly format and prepare the data.</li>
<li>Conduct diagnostic tests to determine the suitability of the data for PCA.</li>
<li>Conducting tests to guide the decisions about number of components to extract.</li>
<li>Conducting orthogonal and oblique extractions (at least two each with different numbers of components).</li>
<li>Selecting one solution and preparing an APA style results section (with table and figure).</li>
<li>Compare your results in light of any other psychometrics lessons where you have used this data (especially the <a href="ItemAnalSurvey.html#ItemAnalSurvey">item analysis</a> and <a href="PCA.html#PCA">PCA</a> lessons).</li>
</ul>
<div id="problem-1-play-around-with-this-simulation.-4" class="section level3 hasAnchor" number="9.9.1">
<h3><span class="header-section-number">9.9.1</span> Problem #1: Play around with this simulation.<a href="PAF.html#problem-1-play-around-with-this-simulation.-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Copy the script for the simulation and then change (at least) one thing in the simulation to see how it impacts the results. If PAF is new to you, perhaps you just change the number in “set.seed(240311)” from 240311 to something else. Your results should parallel those obtained in the lecture, making it easier for you to check your work as you go.</p>
</div>
<div id="problem-2-conduct-a-pca-with-the-szymanski-and-bissonette--szymanski_perceptions_2020-research-vignette-that-was-used-in-prior-lessons." class="section level3 hasAnchor" number="9.9.2">
<h3><span class="header-section-number">9.9.2</span> Problem #2: Conduct a PCA with the Szymanski and Bissonette <span class="citation">(<a href="#ref-szymanski_perceptions_2020">2020</a>)</span> research vignette that was used in prior lessons.<a href="PAF.html#problem-2-conduct-a-pca-with-the-szymanski-and-bissonette--szymanski_perceptions_2020-research-vignette-that-was-used-in-prior-lessons." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The second option involves utilizing one of the simulated datasets available in this OER. Szymanski and Bissonette’s <span class="citation">(<a href="#ref-szymanski_perceptions_2020">2020</a>)</span>Perceptions of the LGBTQ College Campus Climate Scale: Development and psychometric evaluation and Keum et al.’s Gendered Racial Microaggressions Scale for Asian American Women <span class="citation">(<a href="#ref-keum_gendered_2018">Keum et al., 2018</a>)</span> are ready for PAF analysis. The simulations are available in the chapters in which they are the featured vignette as well as in a simulations appendix at the end of the OER.</p>
</div>
<div id="problem-3-try-something-entirely-new.-4" class="section level3 hasAnchor" number="9.9.3">
<h3><span class="header-section-number">9.9.3</span> Problem #3: Try something entirely new.<a href="PAF.html#problem-3-try-something-entirely-new.-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete PAF. The data should allow for at least two (ideally three) components/subscales.</p>
</div>
<div id="grading-rubric-4" class="section level3 hasAnchor" number="9.9.4">
<h3><span class="header-section-number">9.9.4</span> Grading Rubric<a href="PAF.html#grading-rubric-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using the lecture and workflow (chart) as a guide, please work through all the steps listed in the proposed assignment/grading rubric.</p>
<table>
<colgroup>
<col width="54%" />
<col width="25%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Check and, if needed, format data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Conduct and interpret the three diagnostic tests to determine if PAF is appropriate as an analysis (KMO, Bartlett’s, determinant).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Determine how many components to extract (e.g., scree plot, eigenvalues, theory).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Conduct an oblique extraction and rotation with a minimum of two different factor extractions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. APA style results section with table and figure of one of the solutions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">40</td>
<td align="center">_____</td>
<td align="center"></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="homeworked-example-4" class="section level2 hasAnchor" number="9.10">
<h2><span class="header-section-number">9.10</span> Homeworked Example<a href="PAF.html#homeworked-example-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="link">Screencast Link</a></p>
<p>For more information about the data used in this homeworked example, please refer to the description and codebook located at the end of the <a href="https://lhbikos.github.io/ReCenterPsychStats/ReCintro.html#introduction-to-the-data-set-used-for-homeworked-examples">introduction</a> in first volume of ReCentering Psych Stats.</p>
<p>As a brief review, this data is part of an IRB-approved study, with consent to use in teaching demonstrations and to be made available to the general public via the open science framework. Hence, it is appropriate to share in class. You will notice there are student- and teacher- IDs. These numbers are not connected to the SPU student ID. Rather, the subcontractor who does the course evals for SPU creates a third, not-SPU-related identifier.</p>
<p>This is the same dataset I have been using for many in-class demos. It’s great for psychometrics because I actually created a three-factor solution from the institution’s course evaluations. We’ll get to walk through that process in this class.</p>
<p>Because this is an actual dataset, if you wish to work the problem along with me, you will need to download the data from <strong>LINK TO DATASET</strong>.</p>
<p>In this homewoRked example I will conduct a principal components analysis. My hope is that the results will support my solution of three dimensions: valued-by-the-student, traditional pedagogy, socially responsive pedagogy.</p>
<div id="check-and-if-needed-format-data-2" class="section level3 hasAnchor" number="9.10.1">
<h3><span class="header-section-number">9.10.1</span> Check and, if needed, format data<a href="PAF.html#check-and-if-needed-format-data-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="PAF.html#cb437-1" tabindex="-1"></a>big <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;ReC.rds&quot;</span>)</span></code></pre></div>
<p>With the next code I will create an item-level df with only the items used in the three scales.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="PAF.html#cb438-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb438-2"><a href="PAF.html#cb438-2" tabindex="-1"></a>items <span class="ot">&lt;-</span> big <span class="sc">%&gt;%</span></span>
<span id="cb438-3"><a href="PAF.html#cb438-3" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(ValObjectives, IncrUnderstanding, IncrInterest, ClearResponsibilities,</span>
<span id="cb438-4"><a href="PAF.html#cb438-4" tabindex="-1"></a>        EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation,</span>
<span id="cb438-5"><a href="PAF.html#cb438-5" tabindex="-1"></a>        MultPerspectives, InclusvClassrm, DEIintegration, EquitableEval)</span></code></pre></div>
<p>Some of the analyses require non-missing data in the df.</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="PAF.html#cb439-1" tabindex="-1"></a>items <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(items)</span></code></pre></div>
<p>Let’s check the structure of the data.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="PAF.html#cb440-1" tabindex="-1"></a><span class="fu">str</span>(items)</span></code></pre></div>
<pre><code>Classes &#39;data.table&#39; and &#39;data.frame&#39;:  267 obs. of  12 variables:
 $ ValObjectives        : int  5 5 4 4 5 5 5 4 5 3 ...
 $ IncrUnderstanding    : int  2 3 4 3 4 5 2 4 5 4 ...
 $ IncrInterest         : int  5 3 4 2 4 5 3 2 5 1 ...
 $ ClearResponsibilities: int  5 5 4 4 5 5 4 4 5 3 ...
 $ EffectiveAnswers     : int  5 3 5 3 5 4 3 2 3 3 ...
 $ Feedback             : int  5 3 4 2 5 5 4 4 5 2 ...
 $ ClearOrganization    : int  3 4 3 4 4 5 4 4 5 2 ...
 $ ClearPresentation    : int  4 4 4 2 5 4 4 4 5 2 ...
 $ MultPerspectives     : int  5 5 4 5 5 5 5 5 5 1 ...
 $ InclusvClassrm       : int  5 5 5 5 5 5 5 4 5 3 ...
 $ DEIintegration       : int  5 5 5 5 5 5 5 5 5 2 ...
 $ EquitableEval        : int  5 5 3 5 5 5 5 3 5 3 ...
 - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; 
 - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:43] 6 20 106 109 112 113 114 117 122 128 ...
  ..- attr(*, &quot;names&quot;)= chr [1:43] &quot;6&quot; &quot;20&quot; &quot;106&quot; &quot;109&quot; ...</code></pre>
</div>
<div id="conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant-1" class="section level3 hasAnchor" number="9.10.2">
<h3><span class="header-section-number">9.10.2</span> Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant)<a href="PAF.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="kmo-1" class="section level4 hasAnchor" number="9.10.2.1">
<h4><span class="header-section-number">9.10.2.1</span> KMO<a href="PAF.html#kmo-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Kaiser-Meyer-Olkin (KMO) index is an index of <em>sampling adequacy</em> to let us know if the sample size is sufficient relative to the statistical characteristics of the data.</p>
<p>General crieria (1974, Kaiser):</p>
<ul>
<li>bare minimum of .5</li>
<li>values between .5 and .7 as mediocre</li>
<li>values above .9 are superb</li>
</ul>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="PAF.html#cb442-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">KMO</span>(items)</span></code></pre></div>
<pre><code>Kaiser-Meyer-Olkin factor adequacy
Call: psych::KMO(r = items)
Overall MSA =  0.91
MSA for each item = 
        ValObjectives     IncrUnderstanding          IncrInterest 
                 0.94                  0.89                  0.89 
ClearResponsibilities      EffectiveAnswers              Feedback 
                 0.91                  0.93                  0.94 
    ClearOrganization     ClearPresentation      MultPerspectives 
                 0.94                  0.91                  0.93 
       InclusvClassrm        DEIintegration         EquitableEval 
                 0.86                  0.78                  0.95 </code></pre>
<p>With a KMO of 0.91, the data seems appropriate to continue with the PCA.</p>
</div>
<div id="bartletts-1" class="section level4 hasAnchor" number="9.10.2.2">
<h4><span class="header-section-number">9.10.2.2</span> Bartlett’s<a href="PAF.html#bartletts-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Barlett’s test let’s us know if the matrix is an <em>identity matrix</em> (i.e., where elements on the off-diagonal would be 0.0 and elements on the diagonal would be 1.0). Stated another way – items only correlate with “themselves” and not other variables.</p>
<p>When <span class="math inline">\(p &lt; 0.05\)</span> the matrix is not an identity matrix. That is, there are some relationships between variables that can be analyzed.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="PAF.html#cb444-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">cortest.bartlett</span>(items)</span></code></pre></div>
<pre><code>R was not square, finding R from data</code></pre>
<pre><code>$chisq
[1] 1897.769

$p.value
[1] 0

$df
[1] 66</code></pre>
<p>The Barlett’s test, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span>, indicating that the correlation matrix is not an identity matrix and, on that dimension, is suitable for analysis.</p>
</div>
<div id="determinant-1" class="section level4 hasAnchor" number="9.10.2.3">
<h4><span class="header-section-number">9.10.2.3</span> Determinant<a href="PAF.html#determinant-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Multicollinearity or singularity is diagnosed by the determinant. The determinant should be greater than 0.00001. If smaller, then there may be an issue with multicollinearity (variables that are too highly correlated) or singularity (variables that are perfectly correlated).</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="PAF.html#cb447-1" tabindex="-1"></a>items <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(items)</span>
<span id="cb447-2"><a href="PAF.html#cb447-2" tabindex="-1"></a><span class="fu">det</span>(<span class="fu">cor</span>(items))</span></code></pre></div>
<pre><code>[1] 0.0006985496</code></pre>
<p>The value of the determinant is 0.0007; greater than 0.00001. We are not concerned with multicollinearity or singularity.</p>
<p>Summary from data screening:</p>
<blockquote>
<p>Data screening were conducted to determine the suitability of the data for principal axis factoring. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was 0.91, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span> indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0007 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
</div>
</div>
<div id="determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory-1" class="section level3 hasAnchor" number="9.10.3">
<h3><span class="header-section-number">9.10.3</span> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)<a href="PAF.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Specify fewer factors than # of items (12). For me it wouldn’t run unless it was 6 or fewer.</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="PAF.html#cb449-1" tabindex="-1"></a>paf1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">6</span>, <span class="at">fm =</span> <span class="st">&quot;pa&quot;</span>, <span class="at">max.iter =</span> <span class="dv">100</span>, <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co"># using raw data and letting the length function automatically calculate the # factors as a function of how many columns in the raw data</span></span></code></pre></div>
<pre><code>maximum iteration exceeded</code></pre>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="PAF.html#cb451-1" tabindex="-1"></a>paf1</span></code></pre></div>
<pre><code>Factor Analysis using method =  pa
Call: psych::fa(r = items, nfactors = 6, rotate = &quot;none&quot;, max.iter = 100, 
    fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       PA1   PA2   PA3   PA4   PA5   PA6   h2    u2 com
ValObjectives         0.52 -0.07  0.16  0.05  0.05  0.10 0.31 0.688 1.3
IncrUnderstanding     0.65 -0.28  0.31  0.03 -0.04 -0.01 0.60 0.400 1.9
IncrInterest          0.74 -0.18  0.50 -0.18  0.13 -0.02 0.87 0.127 2.1
ClearResponsibilities 0.80 -0.09 -0.34  0.10  0.03 -0.06 0.77 0.226 1.4
EffectiveAnswers      0.78 -0.14 -0.13  0.05  0.09 -0.17 0.68 0.315 1.3
Feedback              0.74  0.05 -0.20 -0.12  0.22  0.05 0.65 0.347 1.4
ClearOrganization     0.78 -0.28 -0.13  0.12 -0.07  0.32 0.83 0.175 1.8
ClearPresentation     0.84 -0.21  0.01  0.12 -0.20 -0.11 0.82 0.182 1.3
MultPerspectives      0.81  0.30 -0.12 -0.40 -0.23  0.03 0.97 0.029 2.0
InclusvClassrm        0.64  0.41  0.18  0.21 -0.14 -0.08 0.67 0.327 2.3
DEIintegration        0.49  0.66  0.13  0.14  0.11  0.10 0.74 0.265 2.2
EquitableEval         0.69  0.09 -0.17 -0.02  0.13 -0.09 0.54 0.462 1.3

                       PA1  PA2  PA3  PA4  PA5  PA6
SS loadings           6.11 0.97 0.65 0.31 0.22 0.19
Proportion Var        0.51 0.08 0.05 0.03 0.02 0.02
Cumulative Var        0.51 0.59 0.64 0.67 0.69 0.70
Proportion Explained  0.72 0.11 0.08 0.04 0.03 0.02
Cumulative Proportion 0.72 0.84 0.91 0.95 0.98 1.00

Mean item complexity =  1.7
Test of the hypothesis that 6 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 9  and the objective function was  0.06 

The root mean square of the residuals (RMSR) is  0.01 
The df corrected root mean square of the residuals is  0.02 

The harmonic n.obs is  267 with the empirical chi square  2.97  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  14.81  with prob &lt;  0.096 

Tucker Lewis Index of factoring reliability =  0.976
RMSEA index =  0.049  and the 90 % confidence intervals are  0 0.093
BIC =  -35.47
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   PA1  PA2  PA3  PA4  PA5
Correlation of (regression) scores with factors   0.98 0.90 0.88 0.86 0.73
Multiple R square of scores with factors          0.97 0.81 0.77 0.74 0.54
Minimum correlation of possible factor scores     0.93 0.63 0.54 0.48 0.07
                                                    PA6
Correlation of (regression) scores with factors    0.68
Multiple R square of scores with factors           0.46
Minimum correlation of possible factor scores     -0.08</code></pre>
<p>The eigenvalue-greater-than-one criteria suggests 1 factor (but the second factor has an SSloading of .97).</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="PAF.html#cb453-1" tabindex="-1"></a><span class="fu">plot</span>(paf1<span class="sc">$</span>values, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-91-1.png" width="672" />
The scree plot looks like one factor.</p>
<p>Ugh.</p>
<ul>
<li>I want 3 factors (we could think of this as a priori theory); would account for 64% of variance.</li>
<li>Two could account for 59% of variance.</li>
<li>Eigenvalues-greater-than-one criteria and scree plot suggests 1 (would account for 51% of variance)</li>
</ul>
<p><em>Note</em>: The lecture has more on evaluating communalities and uniquenesses and how this information can also inform the number of components we want to extract. Because it is easy to get lost (very lost) I will skip over this for now. If you were to create a measure and use PCA as an exploratory approach to understanding the dimensionality of an instrument, you would likely want to investigate further and report on these.</p>
</div>
<div id="conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1" class="section level3 hasAnchor" number="9.10.4">
<h3><span class="header-section-number">9.10.4</span> Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions<a href="PAF.html#conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>An orthogonal two factor solution</strong></p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="PAF.html#cb454-1" tabindex="-1"></a>pafORTH2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">2</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb454-2"><a href="PAF.html#cb454-2" tabindex="-1"></a>pafORTH2f</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 2, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       MR1  MR2   h2   u2 com
ValObjectives         0.48 0.21 0.27 0.73 1.4
IncrUnderstanding     0.67 0.12 0.46 0.54 1.1
IncrInterest          0.66 0.25 0.50 0.50 1.3
ClearResponsibilities 0.74 0.29 0.63 0.37 1.3
EffectiveAnswers      0.76 0.26 0.64 0.36 1.2
Feedback              0.63 0.38 0.54 0.46 1.7
ClearOrganization     0.79 0.17 0.65 0.35 1.1
ClearPresentation     0.83 0.23 0.75 0.25 1.2
MultPerspectives      0.58 0.55 0.64 0.36 2.0
InclusvClassrm        0.36 0.64 0.54 0.46 1.6
DEIintegration        0.08 0.86 0.75 0.25 1.0
EquitableEval         0.57 0.40 0.49 0.51 1.8

                       MR1  MR2
SS loadings           4.74 2.12
Proportion Var        0.39 0.18
Cumulative Var        0.39 0.57
Proportion Explained  0.69 0.31
Cumulative Proportion 0.69 1.00

Mean item complexity =  1.4
Test of the hypothesis that 2 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 43  and the objective function was  0.75 

The root mean square of the residuals (RMSR) is  0.05 
The df corrected root mean square of the residuals is  0.06 

The harmonic n.obs is  267 with the empirical chi square  90.7  with prob &lt;  0.000029 
The total n.obs was  267  with Likelihood Chi Square =  194.26  with prob &lt;  0.0000000000000000000041 

Tucker Lewis Index of factoring reliability =  0.873
RMSEA index =  0.115  and the 90 % confidence intervals are  0.099 0.132
BIC =  -46
Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   MR1 MR2
Correlation of (regression) scores with factors   0.94 0.9
Multiple R square of scores with factors          0.89 0.8
Minimum correlation of possible factor scores     0.78 0.6</code></pre>
<p>Sorting the scores into a table can help see the results more clearly. The “cut = #” command will not show the factor scores for factor loading &lt; .30. I would do this “to see”, but I would include all the values in an APA style table.</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="PAF.html#cb456-1" tabindex="-1"></a>paf_tableOR2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pafORTH2f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 2, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item  MR1  MR2   h2   u2 com
ClearPresentation        8 0.83      0.75 0.25 1.2
ClearOrganization        7 0.79      0.65 0.35 1.1
EffectiveAnswers         5 0.76      0.64 0.36 1.2
ClearResponsibilities    4 0.74      0.63 0.37 1.3
IncrUnderstanding        2 0.67      0.46 0.54 1.1
IncrInterest             3 0.66      0.50 0.50 1.3
Feedback                 6 0.63 0.38 0.54 0.46 1.7
MultPerspectives         9 0.58 0.55 0.64 0.36 2.0
EquitableEval           12 0.57 0.40 0.49 0.51 1.8
ValObjectives            1 0.48      0.27 0.73 1.4
DEIintegration          11      0.86 0.75 0.25 1.0
InclusvClassrm          10 0.36 0.64 0.54 0.46 1.6

                       MR1  MR2
SS loadings           4.74 2.12
Proportion Var        0.39 0.18
Cumulative Var        0.39 0.57
Proportion Explained  0.69 0.31
Cumulative Proportion 0.69 1.00

Mean item complexity =  1.4
Test of the hypothesis that 2 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 43  and the objective function was  0.75 

The root mean square of the residuals (RMSR) is  0.05 
The df corrected root mean square of the residuals is  0.06 

The harmonic n.obs is  267 with the empirical chi square  90.7  with prob &lt;  0.000029 
The total n.obs was  267  with Likelihood Chi Square =  194.26  with prob &lt;  0.0000000000000000000041 

Tucker Lewis Index of factoring reliability =  0.873
RMSEA index =  0.115  and the 90 % confidence intervals are  0.099 0.132
BIC =  -46
Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   MR1 MR2
Correlation of (regression) scores with factors   0.94 0.9
Multiple R square of scores with factors          0.89 0.8
Minimum correlation of possible factor scores     0.78 0.6</code></pre>
<p>F1: Includes everything else.
F2: Includes 2 SCR items – DEIintegration, InclsvClssrm
Also: EquitableEval MultPerspectives have high cross-loadings, but end up on the first factor</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="PAF.html#cb458-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pafORTH2f)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-94-1.png" width="672" />
Plotting these figures from the program can facilitate conceptual understanding of what is going on – and can be a “check” to your work.</p>
<p>In the lecture I made a “biggish deal” about PCA being <em>components</em> analysis and PAF being <em>factor</em> analysis. Although the two approaches can lead to similar results/conclusions, there are some significant differences “under the hood.” PCA can be thought of more as regression where the items predict the component. Consequently, the arrows went <em>from</em> the item, <em>to</em> the component.</p>
<p>In PAF, the arrows will go from the factor to the item – because the factors (or latent variables) are assumed to predict the scores on the items (i.e., “depression” would predict how someone rates items that assess hopelessness, sleep, anhedonia, and so forth).</p>
<p><strong>An orthogonal three factor solution</strong></p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="PAF.html#cb459-1" tabindex="-1"></a>pafORTH3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb459-2"><a href="PAF.html#cb459-2" tabindex="-1"></a>pafORTH3f</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 3, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       MR1  MR3  MR2   h2   u2 com
ValObjectives         0.27 0.43 0.20 0.30 0.70 2.1
IncrUnderstanding     0.27 0.76 0.09 0.66 0.34 1.3
IncrInterest          0.27 0.75 0.25 0.69 0.31 1.5
ClearResponsibilities 0.84 0.24 0.17 0.79 0.21 1.2
EffectiveAnswers      0.67 0.41 0.18 0.64 0.36 1.8
Feedback              0.65 0.26 0.30 0.58 0.42 1.8
ClearOrganization     0.65 0.47 0.10 0.64 0.36 1.9
ClearPresentation     0.62 0.57 0.18 0.74 0.26 2.2
MultPerspectives      0.57 0.29 0.49 0.65 0.35 2.5
InclusvClassrm        0.28 0.30 0.63 0.56 0.44 1.9
DEIintegration        0.14 0.07 0.85 0.75 0.25 1.1
EquitableEval         0.60 0.23 0.33 0.52 0.48 1.9

                       MR1  MR3  MR2
SS loadings           3.37 2.39 1.77
Proportion Var        0.28 0.20 0.15
Cumulative Var        0.28 0.48 0.63
Proportion Explained  0.45 0.32 0.23
Cumulative Proportion 0.45 0.77 1.00

Mean item complexity =  1.8
Test of the hypothesis that 3 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 33  and the objective function was  0.29 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic n.obs is  267 with the empirical chi square  19.55  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  75.2  with prob &lt;  0.000039 

Tucker Lewis Index of factoring reliability =  0.954
RMSEA index =  0.069  and the 90 % confidence intervals are  0.049 0.09
BIC =  -109.18
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   MR1  MR3  MR2
Correlation of (regression) scores with factors   0.90 0.87 0.89
Multiple R square of scores with factors          0.82 0.76 0.79
Minimum correlation of possible factor scores     0.64 0.52 0.58</code></pre>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="PAF.html#cb461-1" tabindex="-1"></a>paf_tableOR3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pafORTH3f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 3, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item  MR1  MR3  MR2   h2   u2 com
ClearResponsibilities    4 0.84           0.79 0.21 1.2
EffectiveAnswers         5 0.67 0.41      0.64 0.36 1.8
Feedback                 6 0.65      0.30 0.58 0.42 1.8
ClearOrganization        7 0.65 0.47      0.64 0.36 1.9
ClearPresentation        8 0.62 0.57      0.74 0.26 2.2
EquitableEval           12 0.60      0.33 0.52 0.48 1.9
MultPerspectives         9 0.57      0.49 0.65 0.35 2.5
IncrUnderstanding        2      0.76      0.66 0.34 1.3
IncrInterest             3      0.75      0.69 0.31 1.5
ValObjectives            1      0.43      0.30 0.70 2.1
DEIintegration          11           0.85 0.75 0.25 1.1
InclusvClassrm          10           0.63 0.56 0.44 1.9

                       MR1  MR3  MR2
SS loadings           3.37 2.39 1.77
Proportion Var        0.28 0.20 0.15
Cumulative Var        0.28 0.48 0.63
Proportion Explained  0.45 0.32 0.23
Cumulative Proportion 0.45 0.77 1.00

Mean item complexity =  1.8
Test of the hypothesis that 3 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 33  and the objective function was  0.29 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic n.obs is  267 with the empirical chi square  19.55  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  75.2  with prob &lt;  0.000039 

Tucker Lewis Index of factoring reliability =  0.954
RMSEA index =  0.069  and the 90 % confidence intervals are  0.049 0.09
BIC =  -109.18
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   MR1  MR3  MR2
Correlation of (regression) scores with factors   0.90 0.87 0.89
Multiple R square of scores with factors          0.82 0.76 0.79
Minimum correlation of possible factor scores     0.64 0.52 0.58</code></pre>
<p>F1: Traditional Pedagogy…+MultPerspectives
F2: Valued-by-the-Student
F3: SCRPed–the 2 items;
Note: EquitableEval and MultPerspectivs have some cross-loading with first factor</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="PAF.html#cb463-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pafORTH3f)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
</div>
<div id="conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1" class="section level3 hasAnchor" number="9.10.5">
<h3><span class="header-section-number">9.10.5</span> Conduct an oblique extraction and rotation with a minimum of two different factor extractions<a href="PAF.html#conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>An oblique two factor solution</strong></p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="PAF.html#cb464-1" tabindex="-1"></a>pafOBL2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">2</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb464-2"><a href="PAF.html#cb464-2" tabindex="-1"></a>pafOBL2f</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 2, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                        MR1   MR2   h2   u2 com
ValObjectives          0.50  0.05 0.27 0.73 1.0
IncrUnderstanding      0.73 -0.12 0.46 0.54 1.1
IncrInterest           0.69  0.03 0.50 0.50 1.0
ClearResponsibilities  0.77  0.04 0.63 0.37 1.0
EffectiveAnswers       0.80  0.00 0.64 0.36 1.0
Feedback               0.64  0.18 0.54 0.46 1.2
ClearOrganization      0.85 -0.11 0.65 0.35 1.0
ClearPresentation      0.89 -0.05 0.75 0.25 1.0
MultPerspectives       0.55  0.38 0.64 0.36 1.8
InclusvClassrm         0.30  0.55 0.54 0.46 1.5
DEIintegration        -0.05  0.89 0.75 0.25 1.0
EquitableEval          0.57  0.22 0.49 0.51 1.3

                       MR1  MR2
SS loadings           5.32 1.54
Proportion Var        0.44 0.13
Cumulative Var        0.44 0.57
Proportion Explained  0.78 0.22
Cumulative Proportion 0.78 1.00

 With factor correlations of 
     MR1  MR2
MR1 1.00 0.45
MR2 0.45 1.00

Mean item complexity =  1.2
Test of the hypothesis that 2 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 43  and the objective function was  0.75 

The root mean square of the residuals (RMSR) is  0.05 
The df corrected root mean square of the residuals is  0.06 

The harmonic n.obs is  267 with the empirical chi square  90.7  with prob &lt;  0.000029 
The total n.obs was  267  with Likelihood Chi Square =  194.26  with prob &lt;  0.0000000000000000000041 

Tucker Lewis Index of factoring reliability =  0.873
RMSEA index =  0.115  and the 90 % confidence intervals are  0.099 0.132
BIC =  -46
Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   MR1  MR2
Correlation of (regression) scores with factors   0.97 0.91
Multiple R square of scores with factors          0.93 0.83
Minimum correlation of possible factor scores     0.86 0.65</code></pre>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="PAF.html#cb466-1" tabindex="-1"></a>paf_tableOBL2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pafOBL2f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 2, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   MR1   MR2   h2   u2 com
ClearPresentation        8  0.89       0.75 0.25 1.0
ClearOrganization        7  0.85       0.65 0.35 1.0
EffectiveAnswers         5  0.80       0.64 0.36 1.0
ClearResponsibilities    4  0.77       0.63 0.37 1.0
IncrUnderstanding        2  0.73       0.46 0.54 1.1
IncrInterest             3  0.69       0.50 0.50 1.0
Feedback                 6  0.64       0.54 0.46 1.2
EquitableEval           12  0.57       0.49 0.51 1.3
MultPerspectives         9  0.55  0.38 0.64 0.36 1.8
ValObjectives            1  0.50       0.27 0.73 1.0
DEIintegration          11        0.89 0.75 0.25 1.0
InclusvClassrm          10        0.55 0.54 0.46 1.5

                       MR1  MR2
SS loadings           5.32 1.54
Proportion Var        0.44 0.13
Cumulative Var        0.44 0.57
Proportion Explained  0.78 0.22
Cumulative Proportion 0.78 1.00

 With factor correlations of 
     MR1  MR2
MR1 1.00 0.45
MR2 0.45 1.00

Mean item complexity =  1.2
Test of the hypothesis that 2 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 43  and the objective function was  0.75 

The root mean square of the residuals (RMSR) is  0.05 
The df corrected root mean square of the residuals is  0.06 

The harmonic n.obs is  267 with the empirical chi square  90.7  with prob &lt;  0.000029 
The total n.obs was  267  with Likelihood Chi Square =  194.26  with prob &lt;  0.0000000000000000000041 

Tucker Lewis Index of factoring reliability =  0.873
RMSEA index =  0.115  and the 90 % confidence intervals are  0.099 0.132
BIC =  -46
Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   MR1  MR2
Correlation of (regression) scores with factors   0.97 0.91
Multiple R square of scores with factors          0.93 0.83
Minimum correlation of possible factor scores     0.86 0.65</code></pre>
<p>Curiously, there are fewer cross-loadings. F1 has everything except the 2 SCR items which are on F2.</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="PAF.html#cb468-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pafOBL2f)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-100-1.png" width="672" />
With the curved line and value between MR1 and MR2, this figure helps make “allowance” for components to correlate, clear. There was no such path on the orthogonal figures. This is because the rotation required the factors to be uncorrelated.</p>
<p><strong>An oblique three factor solution</strong></p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="PAF.html#cb469-1" tabindex="-1"></a>pafOBL3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb469-2"><a href="PAF.html#cb469-2" tabindex="-1"></a>pafOBL3f</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                        MR1   MR3   MR2   h2   u2 com
ValObjectives          0.14  0.40  0.10 0.30 0.70 1.4
IncrUnderstanding      0.03  0.81 -0.05 0.66 0.34 1.0
IncrInterest           0.00  0.78  0.13 0.69 0.31 1.1
ClearResponsibilities  0.97 -0.11 -0.04 0.79 0.21 1.0
EffectiveAnswers       0.68  0.18 -0.01 0.64 0.36 1.1
Feedback               0.69  0.00  0.15 0.58 0.42 1.1
ClearOrganization      0.64  0.27 -0.10 0.64 0.36 1.4
ClearPresentation      0.54  0.41 -0.02 0.74 0.26 1.9
MultPerspectives       0.53  0.07  0.36 0.65 0.35 1.8
InclusvClassrm         0.12  0.21  0.58 0.56 0.44 1.3
DEIintegration        -0.01 -0.02  0.88 0.75 0.25 1.0
EquitableEval          0.63 -0.01  0.19 0.52 0.48 1.2

                       MR1  MR3  MR2
SS loadings           3.80 2.18 1.56
Proportion Var        0.32 0.18 0.13
Cumulative Var        0.32 0.50 0.63
Proportion Explained  0.50 0.29 0.21
Cumulative Proportion 0.50 0.79 1.00

 With factor correlations of 
     MR1  MR3  MR2
MR1 1.00 0.65 0.43
MR3 0.65 1.00 0.31
MR2 0.43 0.31 1.00

Mean item complexity =  1.3
Test of the hypothesis that 3 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 33  and the objective function was  0.29 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic n.obs is  267 with the empirical chi square  19.55  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  75.2  with prob &lt;  0.000039 

Tucker Lewis Index of factoring reliability =  0.954
RMSEA index =  0.069  and the 90 % confidence intervals are  0.049 0.09
BIC =  -109.18
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   MR1  MR3  MR2
Correlation of (regression) scores with factors   0.96 0.93 0.91
Multiple R square of scores with factors          0.92 0.86 0.83
Minimum correlation of possible factor scores     0.84 0.71 0.65</code></pre>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="PAF.html#cb471-1" tabindex="-1"></a>paf_tableOBL3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pafOBL3f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   MR1   MR3   MR2   h2   u2 com
ClearResponsibilities    4  0.97             0.79 0.21 1.0
Feedback                 6  0.69             0.58 0.42 1.1
EffectiveAnswers         5  0.68             0.64 0.36 1.1
ClearOrganization        7  0.64             0.64 0.36 1.4
EquitableEval           12  0.63             0.52 0.48 1.2
ClearPresentation        8  0.54  0.41       0.74 0.26 1.9
MultPerspectives         9  0.53        0.36 0.65 0.35 1.8
IncrUnderstanding        2        0.81       0.66 0.34 1.0
IncrInterest             3        0.78       0.69 0.31 1.1
ValObjectives            1        0.40       0.30 0.70 1.4
DEIintegration          11              0.88 0.75 0.25 1.0
InclusvClassrm          10              0.58 0.56 0.44 1.3

                       MR1  MR3  MR2
SS loadings           3.80 2.18 1.56
Proportion Var        0.32 0.18 0.13
Cumulative Var        0.32 0.50 0.63
Proportion Explained  0.50 0.29 0.21
Cumulative Proportion 0.50 0.79 1.00

 With factor correlations of 
     MR1  MR3  MR2
MR1 1.00 0.65 0.43
MR3 0.65 1.00 0.31
MR2 0.43 0.31 1.00

Mean item complexity =  1.3
Test of the hypothesis that 3 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 33  and the objective function was  0.29 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic n.obs is  267 with the empirical chi square  19.55  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  75.2  with prob &lt;  0.000039 

Tucker Lewis Index of factoring reliability =  0.954
RMSEA index =  0.069  and the 90 % confidence intervals are  0.049 0.09
BIC =  -109.18
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   MR1  MR3  MR2
Correlation of (regression) scores with factors   0.96 0.93 0.91
Multiple R square of scores with factors          0.92 0.86 0.83
Minimum correlation of possible factor scores     0.84 0.71 0.65</code></pre>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="PAF.html#cb473-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pafOBL3f)</span></code></pre></div>
<p><img src="09-EFA_PAF_files/figure-html/unnamed-chunk-103-1.png" width="672" />
Again, pretty similar.</p>
</div>
<div id="determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest-1" class="section level3 hasAnchor" number="9.10.6">
<h3><span class="header-section-number">9.10.6</span> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest<a href="PAF.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the oblique output we see that the correlations between the three subscales range from 0.25 to 0.58. These are high. Therefore, I will choose a 3-component, oblique, solution.</p>
</div>
<div id="apa-style-results-section-with-table-and-figure-of-one-of-the-solutions-1" class="section level3 hasAnchor" number="9.10.7">
<h3><span class="header-section-number">9.10.7</span> APA style results section with table and figure of one of the solutions<a href="PAF.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<blockquote>
<p>The dimensionality of the 12 course evaluation items was analyzed using principal axis factoring (PAF). First, data were screened to determine the suitability of the data for this analyses. Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was 0.91, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span> indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0007 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>Four criteria were used to determine the number of components to extract: a priori theory, the scree test, the eigenvalue-greater-than-one criteria, and the interpretability of the solution. Kaiser’s eigenvalue-greater-than-one criteria suggested one component and explained 51% of the variance. The inflexion in the scree plot justified retaining one component. A priorily, we researchers were expecting three components – which would explain 64% of the variance. Correspondingly, we investigated two and three component solutions with orthogonal (varimax) and oblique (oblimin) procedures. Given the significant correlations (ranging from .31 to .65) and the correspondence of items loading on the a priorili hypothesized components, we determined that an oblique, three-component, solution was most appropriate.</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>The rotated solution, as shown in Table 1 and Figure 1, yielded thre interpretable components, each listed with the proportion of variance accounted for: traditional pedagogy (32%), valued-by-me (18%), and socially and culturally responsive pedagogy (13%).</p>
</blockquote>
</blockquote>
<p>Regarding the Table 1, I would include a table with ALL the values, bolding those with component membership. This is easy, though, because we can export it to a .csv file and</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="PAF.html#cb474-1" tabindex="-1"></a>pafOBL3fb <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb474-2"><a href="PAF.html#cb474-2" tabindex="-1"></a>paf_tableOBL3fb <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pafOBL3fb, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  minres
Call: psych::fa(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   MR1   MR3   MR2   h2   u2 com
ClearResponsibilities    4  0.97 -0.11 -0.04 0.79 0.21 1.0
Feedback                 6  0.69  0.00  0.15 0.58 0.42 1.1
EffectiveAnswers         5  0.68  0.18 -0.01 0.64 0.36 1.1
ClearOrganization        7  0.64  0.27 -0.10 0.64 0.36 1.4
EquitableEval           12  0.63 -0.01  0.19 0.52 0.48 1.2
ClearPresentation        8  0.54  0.41 -0.02 0.74 0.26 1.9
MultPerspectives         9  0.53  0.07  0.36 0.65 0.35 1.8
IncrUnderstanding        2  0.03  0.81 -0.05 0.66 0.34 1.0
IncrInterest             3  0.00  0.78  0.13 0.69 0.31 1.1
ValObjectives            1  0.14  0.40  0.10 0.30 0.70 1.4
DEIintegration          11 -0.01 -0.02  0.88 0.75 0.25 1.0
InclusvClassrm          10  0.12  0.21  0.58 0.56 0.44 1.3

                       MR1  MR3  MR2
SS loadings           3.80 2.18 1.56
Proportion Var        0.32 0.18 0.13
Cumulative Var        0.32 0.50 0.63
Proportion Explained  0.50 0.29 0.21
Cumulative Proportion 0.50 0.79 1.00

 With factor correlations of 
     MR1  MR3  MR2
MR1 1.00 0.65 0.43
MR3 0.65 1.00 0.31
MR2 0.43 0.31 1.00

Mean item complexity =  1.3
Test of the hypothesis that 3 factors are sufficient.

df null model =  66  with the objective function =  7.27 with Chi Square =  1897.77
df of  the model are 33  and the objective function was  0.29 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic n.obs is  267 with the empirical chi square  19.55  with prob &lt;  0.97 
The total n.obs was  267  with Likelihood Chi Square =  75.2  with prob &lt;  0.000039 

Tucker Lewis Index of factoring reliability =  0.954
RMSEA index =  0.069  and the 90 % confidence intervals are  0.049 0.09
BIC =  -109.18
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   MR1  MR3  MR2
Correlation of (regression) scores with factors   0.96 0.93 0.91
Multiple R square of scores with factors          0.92 0.86 0.83
Minimum correlation of possible factor scores     0.84 0.71 0.65</code></pre>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="PAF.html#cb476-1" tabindex="-1"></a>pafOBL3fb_table <span class="ot">&lt;-</span> <span class="fu">round</span>(pafOBL3fb<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb476-2"><a href="PAF.html#cb476-2" tabindex="-1"></a><span class="fu">write.table</span>(pafOBL3fb_table, <span class="at">file =</span> <span class="st">&quot;pafOBL3f_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb476-3"><a href="PAF.html#cb476-3" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb476-4"><a href="PAF.html#cb476-4" tabindex="-1"></a>pafOBL3fb_table</span></code></pre></div>
<pre><code>
Loadings:
                      MR1    MR3    MR2   
ValObjectives          0.140  0.398  0.103
IncrUnderstanding             0.810       
IncrInterest                  0.784  0.128
ClearResponsibilities  0.971 -0.108       
EffectiveAnswers       0.676  0.182       
Feedback               0.686         0.146
ClearOrganization      0.640  0.267       
ClearPresentation      0.543  0.405       
MultPerspectives       0.527         0.363
InclusvClassrm         0.121  0.207  0.580
DEIintegration                       0.880
EquitableEval          0.629         0.185

                 MR1   MR3   MR2
SS loadings    3.283 1.758 1.339
Proportion Var 0.274 0.146 0.112
Cumulative Var 0.274 0.420 0.532</code></pre>
</div>
<div id="explanation-to-grader-2" class="section level3 hasAnchor" number="9.10.8">
<h3><span class="header-section-number">9.10.8</span> Explanation to grader<a href="PAF.html#explanation-to-grader-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>

</div>
</div>
</div>
<h3>REFERENCES<a href="REFS.html#REFS" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-field_discovering_2012" class="csl-entry">
Field, A. P. (2012). <em>Discovering statistics using <span>R</span></em>. Sage.
</div>
<div id="ref-keum_gendered_2018" class="csl-entry">
Keum, B. T., Brady, J. L., Sharma, R., Lu, Y., Kim, Y. H., &amp; Thai, C. J. (2018). Gendered <span>Racial</span> <span>Microaggressions</span> <span>Scale</span> for <span>Asian</span> <span>American</span> <span>Women</span>: <span>Development</span> and initial validation. <em>Journal of Counseling Psychology</em>, <em>65</em>(5), 571–585. <a href="https://doi.org/10.1037/cou0000305">https://doi.org/10.1037/cou0000305</a>
</div>
<div id="ref-lewis_construction_2015" class="csl-entry">
Lewis, J. A., &amp; Neville, H. A. (2015). Construction and initial validation of the <span>Gendered</span> <span>Racial</span> <span>Microaggressions</span> <span>Scale</span> for <span>Black</span> women. <em>Journal of Counseling Psychology</em>, <em>62</em>(2), 289–302. <a href="https://doi.org/10.1037/cou0000062">https://doi.org/10.1037/cou0000062</a>
</div>
<div id="ref-najera_catalan_reliability_2019" class="csl-entry">
Najera Catalan, H. (2019). Reliability, <span>Population</span> <span>Classification</span> and <span>Weighting</span> in <span>Multidimensional</span> <span>Poverty</span> <span>Measurement</span>: <span>A</span> <span>Monte</span> <span>Carlo</span> <span>Study</span>. <em>Social Indicators Research</em>, <em>142</em>. <a href="https://doi.org/10.1007/s11205-018-1950-z">https://doi.org/10.1007/s11205-018-1950-z</a>
</div>
<div id="ref-szymanski_perceptions_2020" class="csl-entry">
Szymanski, D. M., &amp; Bissonette, D. (2020). Perceptions of the <span>LGBTQ</span> <span>College</span> <span>Campus</span> <span>Climate</span> <span>Scale</span>: <span>Development</span> and psychometric evaluation. <em>Journal of Homosexuality</em>, <em>67</em>(10), 1412–1428. <a href="https://doi.org/10.1080/00918369.2019.1591788">https://doi.org/10.1080/00918369.2019.1591788</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="PCA.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confirmatory-factor-analysis-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lhbikos/ReC_Psychometrics/edit/BRANCH/09-EFA_PAF.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ReC_Psychometrics.pdf", "ReC_Psychometrics.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
