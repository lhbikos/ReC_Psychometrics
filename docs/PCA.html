<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Principal Components Analysis | ReCentering Psych Stats: Psychometrics</title>
  <meta name="description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Principal Components Analysis | ReCentering Psych Stats: Psychometrics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://lhbikos.github.io/ReC_Psychometrics/images/ReCenterPsychStats-Psychometrics-bookcover.png" />
  <meta property="og:description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="github-repo" content="lhbikos/ReC_Psychometrics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Principal Components Analysis | ReCentering Psych Stats: Psychometrics" />
  
  <meta name="twitter:description" content="“Psychometrics” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="twitter:image" content="https://lhbikos.github.io/ReC_Psychometrics/images/ReCenterPsychStats-Psychometrics-bookcover.png" />

<meta name="author" content="Lynette H. Bikos, PhD, ABPP (she/her)" />


<meta name="date" content="2024-04-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="exploratory-factor-analysis-1.html"/>
<link rel="next" href="PAF.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ReCentering Psych Stats: Psychometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BOOK COVER</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>PREFACE</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#copyright-with-open-access"><i class="fa fa-check"></i>Copyright with Open Access</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>ACKNOWLEDGEMENTS</a></li>
<li class="chapter" data-level="1" data-path="ReCintro.html"><a href="ReCintro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ReCintro.html"><a href="ReCintro.html#what-to-expect-in-each-chapter"><i class="fa fa-check"></i><b>1.1</b> What to expect in each chapter</a></li>
<li class="chapter" data-level="1.2" data-path="ReCintro.html"><a href="ReCintro.html#strategies-for-accessing-and-using-this-oer"><i class="fa fa-check"></i><b>1.2</b> Strategies for Accessing and Using this OER</a></li>
<li class="chapter" data-level="1.3" data-path="ReCintro.html"><a href="ReCintro.html#if-you-are-new-to-r"><i class="fa fa-check"></i><b>1.3</b> If You are New to R</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ReCintro.html"><a href="ReCintro.html#base-r"><i class="fa fa-check"></i><b>1.3.1</b> Base R</a></li>
<li class="chapter" data-level="1.3.2" data-path="ReCintro.html"><a href="ReCintro.html#r-studio"><i class="fa fa-check"></i><b>1.3.2</b> R Studio</a></li>
<li class="chapter" data-level="1.3.3" data-path="ReCintro.html"><a href="ReCintro.html#r-hygiene"><i class="fa fa-check"></i><b>1.3.3</b> R Hygiene</a></li>
<li class="chapter" data-level="1.3.4" data-path="ReCintro.html"><a href="ReCintro.html#troubleshooting-in-r-markdown"><i class="fa fa-check"></i><b>1.3.4</b> tRoubleshooting in R maRkdown</a></li>
<li class="chapter" data-level="1.3.5" data-path="ReCintro.html"><a href="ReCintro.html#strategies-for-success"><i class="fa fa-check"></i><b>1.3.5</b> stRategies for success</a></li>
<li class="chapter" data-level="1.3.6" data-path="ReCintro.html"><a href="ReCintro.html#resources-for-getting-started"><i class="fa fa-check"></i><b>1.3.6</b> Resources for getting staRted</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="QuestCon.html"><a href="QuestCon.html"><i class="fa fa-check"></i><b>2</b> Questionnaire Construction: The Fundamentals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="QuestCon.html"><a href="QuestCon.html#navigating-this-lesson"><i class="fa fa-check"></i><b>2.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="QuestCon.html"><a href="QuestCon.html#learning-objectives"><i class="fa fa-check"></i><b>2.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.1.2" data-path="QuestCon.html"><a href="QuestCon.html#planning-for-practice"><i class="fa fa-check"></i><b>2.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="2.1.3" data-path="QuestCon.html"><a href="QuestCon.html#readings-resources"><i class="fa fa-check"></i><b>2.1.3</b> Readings &amp; Resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="QuestCon.html"><a href="QuestCon.html#components-of-the-questionnaire"><i class="fa fa-check"></i><b>2.2</b> Components of the Questionnaire</a></li>
<li class="chapter" data-level="2.3" data-path="QuestCon.html"><a href="QuestCon.html#what-improves-or-threatens-response-rates-and-bias"><i class="fa fa-check"></i><b>2.3</b> What Improves (or Threatens) Response Rates and Bias?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="QuestCon.html"><a href="QuestCon.html#should-likert-type-scales-include-a-midpoint"><i class="fa fa-check"></i><b>2.3.1</b> Should Likert-type scales include a midpoint?</a></li>
<li class="chapter" data-level="2.3.2" data-path="QuestCon.html"><a href="QuestCon.html#should-continuous-rating-scales-be-used-in-surveys"><i class="fa fa-check"></i><b>2.3.2</b> Should <em>continuous rating scales</em> be used in surveys?</a></li>
<li class="chapter" data-level="2.3.3" data-path="QuestCon.html"><a href="QuestCon.html#should-likert-type-response-options-use-an-ascending-or-descending-order"><i class="fa fa-check"></i><b>2.3.3</b> Should Likert-type response options use an ascending or descending order?</a></li>
<li class="chapter" data-level="2.3.4" data-path="QuestCon.html"><a href="QuestCon.html#should-surveys-include-negatively-worded-items"><i class="fa fa-check"></i><b>2.3.4</b> Should surveys include negatively worded items?</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="QuestCon.html"><a href="QuestCon.html#construct-specific-guidance"><i class="fa fa-check"></i><b>2.4</b> Construct-specific guidance</a></li>
<li class="chapter" data-level="2.5" data-path="QuestCon.html"><a href="QuestCon.html#surveying-in-the-online-environment"><i class="fa fa-check"></i><b>2.5</b> Surveying in the Online Environment</a></li>
<li class="chapter" data-level="2.6" data-path="QuestCon.html"><a href="QuestCon.html#in-my-surveys"><i class="fa fa-check"></i><b>2.6</b> In my Surveys</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="QuestCon.html"><a href="QuestCon.html#demographics-and-background-information"><i class="fa fa-check"></i><b>2.6.1</b> Demographics and Background Information</a></li>
<li class="chapter" data-level="2.6.2" data-path="QuestCon.html"><a href="QuestCon.html#survey-order"><i class="fa fa-check"></i><b>2.6.2</b> Survey Order</a></li>
<li class="chapter" data-level="2.6.3" data-path="QuestCon.html"><a href="QuestCon.html#forced-responses"><i class="fa fa-check"></i><b>2.6.3</b> Forced Responses</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="QuestCon.html"><a href="QuestCon.html#practice-problems"><i class="fa fa-check"></i><b>2.7</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="qualTRIX.html"><a href="qualTRIX.html"><i class="fa fa-check"></i><b>3</b> Be a QualTRIXter</a>
<ul>
<li class="chapter" data-level="3.1" data-path="qualTRIX.html"><a href="qualTRIX.html#navigating-this-lesson-1"><i class="fa fa-check"></i><b>3.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="qualTRIX.html"><a href="qualTRIX.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="qualTRIX.html"><a href="qualTRIX.html#planning-for-practice-1"><i class="fa fa-check"></i><b>3.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="3.1.3" data-path="qualTRIX.html"><a href="qualTRIX.html#readings-resources-1"><i class="fa fa-check"></i><b>3.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="3.1.4" data-path="qualTRIX.html"><a href="qualTRIX.html#packages-1"><i class="fa fa-check"></i><b>3.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="qualTRIX.html"><a href="qualTRIX.html#research-vignette"><i class="fa fa-check"></i><b>3.2</b> Research Vignette</a></li>
<li class="chapter" data-level="3.3" data-path="qualTRIX.html"><a href="qualTRIX.html#qualtrics-essentials"><i class="fa fa-check"></i><b>3.3</b> Qualtrics Essentials</a></li>
<li class="chapter" data-level="3.4" data-path="qualTRIX.html"><a href="qualTRIX.html#qual-trix"><i class="fa fa-check"></i><b>3.4</b> Qual-TRIX</a></li>
<li class="chapter" data-level="3.5" data-path="qualTRIX.html"><a href="qualTRIX.html#even-more-particularly-relevant-to-irb"><i class="fa fa-check"></i><b>3.5</b> Even moRe, particularly relevant to iRb</a></li>
<li class="chapter" data-level="3.6" data-path="qualTRIX.html"><a href="qualTRIX.html#intravenous-qualtrics"><i class="fa fa-check"></i><b>3.6</b> intRavenous Qualtrics</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="qualTRIX.html"><a href="qualTRIX.html#the-codebook"><i class="fa fa-check"></i><b>3.6.1</b> The Codebook</a></li>
<li class="chapter" data-level="3.6.2" data-path="qualTRIX.html"><a href="qualTRIX.html#using-data-from-an-exported-qualtrics-.csv-file"><i class="fa fa-check"></i><b>3.6.2</b> Using data from an exported Qualtrics .csv file</a></li>
<li class="chapter" data-level="3.6.3" data-path="qualTRIX.html"><a href="qualTRIX.html#tweaking-data-format"><i class="fa fa-check"></i><b>3.6.3</b> Tweaking Data Format</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="qualTRIX.html"><a href="qualTRIX.html#practice-problems-1"><i class="fa fa-check"></i><b>3.7</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="rxy.html"><a href="rxy.html"><i class="fa fa-check"></i><b>4</b> Psychometric Validity: Basic Concepts</a>
<ul>
<li class="chapter" data-level="4.1" data-path="rxy.html"><a href="rxy.html#navigating-this-lesson-2"><i class="fa fa-check"></i><b>4.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="rxy.html"><a href="rxy.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.1.2" data-path="rxy.html"><a href="rxy.html#planning-for-practice-2"><i class="fa fa-check"></i><b>4.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="4.1.3" data-path="rxy.html"><a href="rxy.html#readings-resources-2"><i class="fa fa-check"></i><b>4.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="4.1.4" data-path="rxy.html"><a href="rxy.html#packages-2"><i class="fa fa-check"></i><b>4.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="rxy.html"><a href="rxy.html#research-vignette-1"><i class="fa fa-check"></i><b>4.2</b> Research Vignette</a></li>
<li class="chapter" data-level="4.3" data-path="rxy.html"><a href="rxy.html#fundamentals-of-validity"><i class="fa fa-check"></i><b>4.3</b> Fundamentals of Validity</a></li>
<li class="chapter" data-level="4.4" data-path="rxy.html"><a href="rxy.html#validity-criteria"><i class="fa fa-check"></i><b>4.4</b> Validity Criteria</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="rxy.html"><a href="rxy.html#content-validity"><i class="fa fa-check"></i><b>4.4.1</b> Content Validity</a></li>
<li class="chapter" data-level="4.4.2" data-path="rxy.html"><a href="rxy.html#face-validity-the-unvalidity"><i class="fa fa-check"></i><b>4.4.2</b> Face Validity: The “Un”validity</a></li>
<li class="chapter" data-level="4.4.3" data-path="rxy.html"><a href="rxy.html#criterion-related-validity"><i class="fa fa-check"></i><b>4.4.3</b> Criterion-Related Validity</a></li>
<li class="chapter" data-level="4.4.4" data-path="rxy.html"><a href="rxy.html#construct-validity"><i class="fa fa-check"></i><b>4.4.4</b> Construct Validity</a></li>
<li class="chapter" data-level="4.4.5" data-path="rxy.html"><a href="rxy.html#internal-consistency"><i class="fa fa-check"></i><b>4.4.5</b> Internal Consistency</a></li>
<li class="chapter" data-level="4.4.6" data-path="rxy.html"><a href="rxy.html#structural-validity"><i class="fa fa-check"></i><b>4.4.6</b> Structural Validity</a></li>
<li class="chapter" data-level="4.4.7" data-path="rxy.html"><a href="rxy.html#experimental-interventions"><i class="fa fa-check"></i><b>4.4.7</b> Experimental Interventions</a></li>
<li class="chapter" data-level="4.4.8" data-path="rxy.html"><a href="rxy.html#convergent-and-discriminant-validity"><i class="fa fa-check"></i><b>4.4.8</b> Convergent and Discriminant Validity</a></li>
<li class="chapter" data-level="4.4.9" data-path="rxy.html"><a href="rxy.html#incremental-validity"><i class="fa fa-check"></i><b>4.4.9</b> Incremental Validity</a></li>
<li class="chapter" data-level="4.4.10" data-path="rxy.html"><a href="rxy.html#considering-the-individual-and-social-consequences-of-testing"><i class="fa fa-check"></i><b>4.4.10</b> Considering the Individual and Social Consequences of Testing</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="rxy.html"><a href="rxy.html#factors-affecting-validity-coefficients"><i class="fa fa-check"></i><b>4.5</b> Factors Affecting Validity Coefficients</a></li>
<li class="chapter" data-level="4.6" data-path="rxy.html"><a href="rxy.html#practice-problems-2"><i class="fa fa-check"></i><b>4.6</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="rxy.html"><a href="rxy.html#problem-1-play-around-with-this-simulation."><i class="fa fa-check"></i><b>4.6.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="4.6.2" data-path="rxy.html"><a href="rxy.html#problem-2-conduct-the-reliability-analysis-selecting-different-variables."><i class="fa fa-check"></i><b>4.6.2</b> Problem #2: Conduct the reliability analysis selecting different variables.</a></li>
<li class="chapter" data-level="4.6.3" data-path="rxy.html"><a href="rxy.html#problem-3-try-something-entirely-new."><i class="fa fa-check"></i><b>4.6.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="4.6.4" data-path="rxy.html"><a href="rxy.html#grading-rubric"><i class="fa fa-check"></i><b>4.6.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rxy.html"><a href="rxy.html#homeworked-example"><i class="fa fa-check"></i><b>4.7</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="rxy.html"><a href="rxy.html#check-and-if-needed-format-data"><i class="fa fa-check"></i><b>4.7.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="4.7.2" data-path="rxy.html"><a href="rxy.html#create-a-correlation-matrix-that-includes-the-instrument-of-interest-and-the-variables-that-will-have-varying-degrees-of-relation"><i class="fa fa-check"></i><b>4.7.2</b> Create a correlation matrix that includes the instrument-of-interest and the variables that will have varying degrees of relation</a></li>
<li class="chapter" data-level="4.7.3" data-path="rxy.html"><a href="rxy.html#with-convergent-and-discriminant-validity-in-mind-interpret-the-validity-coefficients-this-should-include-an-assessment-about-whether-the-correlation-coefficients-at-least-two-different-pairings-are-statistically-significantly-different-from-each-other."><i class="fa fa-check"></i><b>4.7.3</b> With convergent and discriminant validity in mind, interpret the validity coefficients; this should include an assessment about whether the correlation coefficients (at least two different pairings) are statistically significantly different from each other.</a></li>
<li class="chapter" data-level="4.7.4" data-path="rxy.html"><a href="rxy.html#with-at-least-three-variables-evaluate-the-degree-to-which-the-instrument-demonstrates-incremental-validity-this-should-involve-two-regression-equations-and-their-statistical-comparison"><i class="fa fa-check"></i><b>4.7.4</b> With at least three variables, evaluate the degree to which the instrument demonstrates incremental validity (this should involve two regression equations and their statistical comparison)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rxx.html"><a href="rxx.html"><i class="fa fa-check"></i><b>5</b> Reliability</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rxx.html"><a href="rxx.html#navigating-this-lesson-3"><i class="fa fa-check"></i><b>5.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="rxx.html"><a href="rxx.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.1.2" data-path="rxx.html"><a href="rxx.html#planning-for-practice-3"><i class="fa fa-check"></i><b>5.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="5.1.3" data-path="rxx.html"><a href="rxx.html#readings-resources-3"><i class="fa fa-check"></i><b>5.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="5.1.4" data-path="rxx.html"><a href="rxx.html#packages-3"><i class="fa fa-check"></i><b>5.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="rxx.html"><a href="rxx.html#defining-reliability"><i class="fa fa-check"></i><b>5.2</b> Defining Reliability</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="rxx.html"><a href="rxx.html#begins-with-classical-test-theory-ctt"><i class="fa fa-check"></i><b>5.2.1</b> Begins with Classical Test Theory (CTT)</a></li>
<li class="chapter" data-level="5.2.2" data-path="rxx.html"><a href="rxx.html#why-are-we-concerned-with-reliability-error"><i class="fa fa-check"></i><b>5.2.2</b> Why are we concerned with reliability? Error!</a></li>
<li class="chapter" data-level="5.2.3" data-path="rxx.html"><a href="rxx.html#the-reliability-coefficient"><i class="fa fa-check"></i><b>5.2.3</b> The Reliability Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="rxx.html"><a href="rxx.html#research-vignette-2"><i class="fa fa-check"></i><b>5.3</b> Research Vignette</a></li>
<li class="chapter" data-level="5.4" data-path="rxx.html"><a href="rxx.html#a-parade-of-reliability-coefficients"><i class="fa fa-check"></i><b>5.4</b> A Parade of Reliability Coefficients</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rxx.html"><a href="rxx.html#reliability-options-for-a-single-administration"><i class="fa fa-check"></i><b>5.4.1</b> Reliability Options for a Single Administration</a></li>
<li class="chapter" data-level="5.4.2" data-path="rxx.html"><a href="rxx.html#reliability-options-for-two-or-more-administrations"><i class="fa fa-check"></i><b>5.4.2</b> Reliability Options for Two or more Administrations</a></li>
<li class="chapter" data-level="5.4.3" data-path="rxx.html"><a href="rxx.html#interrater-reliability"><i class="fa fa-check"></i><b>5.4.3</b> Interrater Reliability</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rxx.html"><a href="rxx.html#what-do-we-do-with-these-coefficients"><i class="fa fa-check"></i><b>5.5</b> What do we do with these coefficients?</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="rxx.html"><a href="rxx.html#corrections-for-attenuation"><i class="fa fa-check"></i><b>5.5.1</b> Corrections for attenuation</a></li>
<li class="chapter" data-level="5.5.2" data-path="rxx.html"><a href="rxx.html#predicting-true-scores-and-their-cis"><i class="fa fa-check"></i><b>5.5.2</b> Predicting true scores (and their CIs)</a></li>
<li class="chapter" data-level="5.5.3" data-path="rxx.html"><a href="rxx.html#how-do-i-keep-it-all-straight"><i class="fa fa-check"></i><b>5.5.3</b> How do I keep it all straight?</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rxx.html"><a href="rxx.html#practice-problems-3"><i class="fa fa-check"></i><b>5.6</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="rxx.html"><a href="rxx.html#problem-1-play-around-with-this-simulation.-1"><i class="fa fa-check"></i><b>5.6.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="5.6.2" data-path="rxx.html"><a href="rxx.html#problem-2-use-the-data-from-the-live-recentering-psych-stats-survey."><i class="fa fa-check"></i><b>5.6.2</b> Problem #2: Use the data from the live ReCentering Psych Stats survey.</a></li>
<li class="chapter" data-level="5.6.3" data-path="rxx.html"><a href="rxx.html#problem-3-try-something-entirely-new.-1"><i class="fa fa-check"></i><b>5.6.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="5.6.4" data-path="rxx.html"><a href="rxx.html#grading-rubric-1"><i class="fa fa-check"></i><b>5.6.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="rxx.html"><a href="rxx.html#homeworked-example-1"><i class="fa fa-check"></i><b>5.7</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="rxx.html"><a href="rxx.html#check-and-if-needed-format-the-data"><i class="fa fa-check"></i><b>5.7.1</b> Check and, if needed, format the data</a></li>
<li class="chapter" data-level="5.7.2" data-path="rxx.html"><a href="rxx.html#calculate-and-report-the-alpha-coefficient-for-a-total-scale-score-and-subscales-if-the-scale-has-them"><i class="fa fa-check"></i><b>5.7.2</b> Calculate and report the alpha coefficient for a total scale score and subscales (if the scale has them)</a></li>
<li class="chapter" data-level="5.7.3" data-path="rxx.html"><a href="rxx.html#subscale-alphas"><i class="fa fa-check"></i><b>5.7.3</b> Subscale alphas</a></li>
<li class="chapter" data-level="5.7.4" data-path="rxx.html"><a href="rxx.html#calculate-and-report-ωt-and-ωh"><i class="fa fa-check"></i><b>5.7.4</b> Calculate and report ωt and ωh</a></li>
<li class="chapter" data-level="5.7.5" data-path="rxx.html"><a href="rxx.html#with-these-two-determine-what-proportion-of-the-variance-is-due-to-all-the-factors-error-and-g."><i class="fa fa-check"></i><b>5.7.5</b> With these two determine what proportion of the variance is due to all the factors, error, and g.</a></li>
<li class="chapter" data-level="5.7.6" data-path="rxx.html"><a href="rxx.html#calculate-total-and-subscale-scores."><i class="fa fa-check"></i><b>5.7.6</b> Calculate total and subscale scores.</a></li>
<li class="chapter" data-level="5.7.7" data-path="rxx.html"><a href="rxx.html#describe-other-reliability-estimates-that-would-be-appropriate-for-the-measure-you-are-evaluating."><i class="fa fa-check"></i><b>5.7.7</b> Describe other reliability estimates that would be appropriate for the measure you are evaluating.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html"><i class="fa fa-check"></i><b>6</b> Item Analysis for Educational Achievement Tests (Exams)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#navigating-this-lesson-4"><i class="fa fa-check"></i><b>6.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.1.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#planning-for-practice-4"><i class="fa fa-check"></i><b>6.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="6.1.3" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#readings-resources-4"><i class="fa fa-check"></i><b>6.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="6.1.4" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#packages-4"><i class="fa fa-check"></i><b>6.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#research-vignette-3"><i class="fa fa-check"></i><b>6.2</b> Research Vignette</a></li>
<li class="chapter" data-level="6.3" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-analysis-in-the-educationalachievement-context"><i class="fa fa-check"></i><b>6.3</b> Item Analysis in the Educational/Achievement Context</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#and-now-a-quiz-please-take-it."><i class="fa fa-check"></i><b>6.3.1</b> And now a quiz! Please take it.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-difficulty"><i class="fa fa-check"></i><b>6.4</b> Item Difficulty</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#percent-passing"><i class="fa fa-check"></i><b>6.4.1</b> Percent passing</a></li>
<li class="chapter" data-level="6.4.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#several-factors-prevent-.50-from-being-the-ideal-difficulty-level"><i class="fa fa-check"></i><b>6.4.2</b> Several factors prevent .50 from being the ideal difficulty level</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#item-discrimination"><i class="fa fa-check"></i><b>6.5</b> Item Discrimination</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#index-of-discrimination"><i class="fa fa-check"></i><b>6.5.1</b> Index of Discrimination</a></li>
<li class="chapter" data-level="6.5.2" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#application-of-item-difficulty-and-discrimination"><i class="fa fa-check"></i><b>6.5.2</b> Application of Item Difficulty and Discrimination</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#in-the-psych-package"><i class="fa fa-check"></i><b>6.6</b> In the <em>psych</em> Package</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#a-mini-introduction-to-irt"><i class="fa fa-check"></i><b>6.6.1</b> A Mini-Introduction to IRT</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#closing-thoughts-on-developing-measures-in-the-educationachievement-context"><i class="fa fa-check"></i><b>6.7</b> Closing Thoughts on Developing Measures in the Education/Achievement Context</a></li>
<li class="chapter" data-level="6.8" data-path="ItemAnalExam.html"><a href="ItemAnalExam.html#practice-problems-4"><i class="fa fa-check"></i><b>6.8</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html"><i class="fa fa-check"></i><b>7</b> Item Analysis for Likert Type Scale Construction</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#navigating-this-lesson-5"><i class="fa fa-check"></i><b>7.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.1.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#planning-for-practice-5"><i class="fa fa-check"></i><b>7.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="7.1.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#readings-resources-5"><i class="fa fa-check"></i><b>7.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="7.1.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#packages-5"><i class="fa fa-check"></i><b>7.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#introducing-item-analysis-for-survey-development"><i class="fa fa-check"></i><b>7.2</b> Introducing Item Analysis for Survey Development</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#workflow-for-item-analysis"><i class="fa fa-check"></i><b>7.2.1</b> Workflow for Item Analysis</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#research-vignette-4"><i class="fa fa-check"></i><b>7.3</b> Research Vignette</a></li>
<li class="chapter" data-level="7.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-i-corrected-item-total-correlations"><i class="fa fa-check"></i><b>7.4</b> Step I: Corrected item-total correlations</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#data-prep"><i class="fa fa-check"></i><b>7.4.1</b> Data Prep</a></li>
<li class="chapter" data-level="7.4.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#calculating-item-total-correlation-coefficients"><i class="fa fa-check"></i><b>7.4.2</b> Calculating Item-Total Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-ii-correlating-items-with-other-scale-totals"><i class="fa fa-check"></i><b>7.5</b> Step II: Correlating Items with Other Scale Totals</a></li>
<li class="chapter" data-level="7.6" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#step-iii-interpreting-and-writing-up-the-results"><i class="fa fa-check"></i><b>7.6</b> Step III: Interpreting and Writing up the Results</a></li>
<li class="chapter" data-level="7.7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#a-conversation-with-dr.-szymanski"><i class="fa fa-check"></i><b>7.7</b> A Conversation with Dr. Szymanski</a></li>
<li class="chapter" data-level="7.8" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#practice-problems-5"><i class="fa fa-check"></i><b>7.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-1-play-around-with-this-simulation.-2"><i class="fa fa-check"></i><b>7.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="7.8.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-2-use-raw-data-from-the-recentering-psych-stats-survey-on-qualtrics."><i class="fa fa-check"></i><b>7.8.2</b> Problem #2: Use raw data from the ReCentering Psych Stats survey on Qualtrics.</a></li>
<li class="chapter" data-level="7.8.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#problem-3-try-something-entirely-new.-2"><i class="fa fa-check"></i><b>7.8.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="7.8.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#grading-rubric-2"><i class="fa fa-check"></i><b>7.8.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#bonus-reel"><i class="fa fa-check"></i><b>7.9</b> Bonus Reel:</a></li>
<li class="chapter" data-level="7.10" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#homeworked-example-2"><i class="fa fa-check"></i><b>7.10</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#check-and-if-needed-format-and-score-data"><i class="fa fa-check"></i><b>7.10.1</b> Check and, if needed, format and score data</a></li>
<li class="chapter" data-level="7.10.2" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#report-alpha-coefficients-and-average-inter-item-correlations-for-the-total-and-subscales"><i class="fa fa-check"></i><b>7.10.2</b> Report alpha coefficients and average inter-item correlations for the total and subscales</a></li>
<li class="chapter" data-level="7.10.3" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#produce-and-interpret-corrected-item-total-correlations-for-total-and-subscales-separately"><i class="fa fa-check"></i><b>7.10.3</b> Produce and interpret corrected item-total correlations for total and subscales, separately</a></li>
<li class="chapter" data-level="7.10.4" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#produce-and-interpret-correlations-between-the-individual-items-of-a-given-subscale-and-the-subscale-scores-of-all-other-subscales"><i class="fa fa-check"></i><b>7.10.4</b> Produce and interpret correlations between the individual items of a given subscale and the subscale scores of all other subscales</a></li>
<li class="chapter" data-level="7.10.5" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#traditional-pedagogy-items-1"><i class="fa fa-check"></i><b>7.10.5</b> Traditional Pedagogy Items</a></li>
<li class="chapter" data-level="7.10.6" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#apa-style-results-section-with-table"><i class="fa fa-check"></i><b>7.10.6</b> APA style results section with table</a></li>
<li class="chapter" data-level="7.10.7" data-path="ItemAnalSurvey.html"><a href="ItemAnalSurvey.html#explanation-to-grader"><i class="fa fa-check"></i><b>7.10.7</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="exploratory-factor-analysis-1.html"><a href="exploratory-factor-analysis-1.html"><i class="fa fa-check"></i>EXPLORATORY <em>FACTOR</em> ANALYSIS</a></li>
<li class="chapter" data-level="8" data-path="PCA.html"><a href="PCA.html"><i class="fa fa-check"></i><b>8</b> Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="PCA.html"><a href="PCA.html#navigating-this-lesson-6"><i class="fa fa-check"></i><b>8.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="PCA.html"><a href="PCA.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.1.2" data-path="PCA.html"><a href="PCA.html#planning-for-practice-6"><i class="fa fa-check"></i><b>8.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="8.1.3" data-path="PCA.html"><a href="PCA.html#readings-resources-6"><i class="fa fa-check"></i><b>8.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="8.1.4" data-path="PCA.html"><a href="PCA.html#packages-6"><i class="fa fa-check"></i><b>8.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="PCA.html"><a href="PCA.html#exploratory-principal-components-analysis"><i class="fa fa-check"></i><b>8.2</b> Exploratory Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="PCA.html"><a href="PCA.html#some-framing-ideas-in-very-lay-terms"><i class="fa fa-check"></i><b>8.2.1</b> Some Framing Ideas (in very lay terms)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="PCA.html"><a href="PCA.html#pca-workflow"><i class="fa fa-check"></i><b>8.3</b> PCA Workflow</a></li>
<li class="chapter" data-level="8.4" data-path="PCA.html"><a href="PCA.html#research-vignette-5"><i class="fa fa-check"></i><b>8.4</b> Research Vignette</a></li>
<li class="chapter" data-level="8.5" data-path="PCA.html"><a href="PCA.html#working-the-vignette"><i class="fa fa-check"></i><b>8.5</b> Working the Vignette</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="PCA.html"><a href="PCA.html#three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factor-analysis"><i class="fa fa-check"></i><b>8.5.1</b> Three Diagnostic Tests to Evaluate the Appropriateness of the Data for Component-or-Factor Analysis</a></li>
<li class="chapter" data-level="8.5.2" data-path="PCA.html"><a href="PCA.html#principal-components-analysis"><i class="fa fa-check"></i><b>8.5.2</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="8.5.3" data-path="PCA.html"><a href="PCA.html#specifying-the-number-of-components"><i class="fa fa-check"></i><b>8.5.3</b> Specifying the Number of Components</a></li>
<li class="chapter" data-level="8.5.4" data-path="PCA.html"><a href="PCA.html#component-rotation"><i class="fa fa-check"></i><b>8.5.4</b> Component Rotation</a></li>
<li class="chapter" data-level="8.5.5" data-path="PCA.html"><a href="PCA.html#component-scores"><i class="fa fa-check"></i><b>8.5.5</b> Component Scores</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="PCA.html"><a href="PCA.html#apa-style-results"><i class="fa fa-check"></i><b>8.6</b> APA Style Results</a></li>
<li class="chapter" data-level="8.7" data-path="PCA.html"><a href="PCA.html#back-to-the-future-the-relationship-between-pca-and-item-analysis"><i class="fa fa-check"></i><b>8.7</b> Back to the FutuRe: The relationship between PCA and item analysis</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="PCA.html"><a href="PCA.html#calculating-and-extracting-item-total-correlation-coefficients"><i class="fa fa-check"></i><b>8.7.1</b> Calculating and Extracting Item-Total Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="PCA.html"><a href="PCA.html#practice-problems-6"><i class="fa fa-check"></i><b>8.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="PCA.html"><a href="PCA.html#problem-1-play-around-with-this-simulation.-3"><i class="fa fa-check"></i><b>8.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="8.8.2" data-path="PCA.html"><a href="PCA.html#problem-2-conduct-a-pca-with-another-simulated-set-of-data-in-the-oer."><i class="fa fa-check"></i><b>8.8.2</b> Problem #2: Conduct a PCA with another simulated set of data in the OER.</a></li>
<li class="chapter" data-level="8.8.3" data-path="PCA.html"><a href="PCA.html#problem-3-try-something-entirely-new.-3"><i class="fa fa-check"></i><b>8.8.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="8.8.4" data-path="PCA.html"><a href="PCA.html#grading-rubric-3"><i class="fa fa-check"></i><b>8.8.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="PCA.html"><a href="PCA.html#homeworked-example-3"><i class="fa fa-check"></i><b>8.9</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="PCA.html"><a href="PCA.html#check-and-if-needed-format-data-1"><i class="fa fa-check"></i><b>8.9.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="8.9.2" data-path="PCA.html"><a href="PCA.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant"><i class="fa fa-check"></i><b>8.9.2</b> Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant)</a></li>
<li class="chapter" data-level="8.9.3" data-path="PCA.html"><a href="PCA.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory"><i class="fa fa-check"></i><b>8.9.3</b> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)</a></li>
<li class="chapter" data-level="8.9.4" data-path="PCA.html"><a href="PCA.html#conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>8.9.4</b> Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="8.9.5" data-path="PCA.html"><a href="PCA.html#conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>8.9.5</b> Conduct an oblique extraction and rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="8.9.6" data-path="PCA.html"><a href="PCA.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest"><i class="fa fa-check"></i><b>8.9.6</b> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest</a></li>
<li class="chapter" data-level="8.9.7" data-path="PCA.html"><a href="PCA.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions"><i class="fa fa-check"></i><b>8.9.7</b> APA style results section with table and figure of one of the solutions</a></li>
<li class="chapter" data-level="8.9.8" data-path="PCA.html"><a href="PCA.html#explanation-to-grader-1"><i class="fa fa-check"></i><b>8.9.8</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="PAF.html"><a href="PAF.html"><i class="fa fa-check"></i><b>9</b> Principal Axis Factoring</a>
<ul>
<li class="chapter" data-level="9.1" data-path="PAF.html"><a href="PAF.html#navigating-this-lesson-7"><i class="fa fa-check"></i><b>9.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="PAF.html"><a href="PAF.html#learning-objectives-7"><i class="fa fa-check"></i><b>9.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="9.1.2" data-path="PAF.html"><a href="PAF.html#planning-for-practice-7"><i class="fa fa-check"></i><b>9.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="9.1.3" data-path="PAF.html"><a href="PAF.html#readings-resources-7"><i class="fa fa-check"></i><b>9.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="9.1.4" data-path="PAF.html"><a href="PAF.html#packages-7"><i class="fa fa-check"></i><b>9.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="PAF.html"><a href="PAF.html#exploratory-factor-analysis-with-a-quick-contrast-to-pca"><i class="fa fa-check"></i><b>9.2</b> Exploratory Factor Analysis (with a quick contrast to PCA)</a></li>
<li class="chapter" data-level="9.3" data-path="PAF.html"><a href="PAF.html#paf-workflow"><i class="fa fa-check"></i><b>9.3</b> PAF Workflow</a></li>
<li class="chapter" data-level="9.4" data-path="PAF.html"><a href="PAF.html#research-vignette-6"><i class="fa fa-check"></i><b>9.4</b> Research Vignette</a></li>
<li class="chapter" data-level="9.5" data-path="PAF.html"><a href="PAF.html#working-the-vignette-1"><i class="fa fa-check"></i><b>9.5</b> Working the Vignette</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="PAF.html"><a href="PAF.html#data-prep-1"><i class="fa fa-check"></i><b>9.5.1</b> Data Prep</a></li>
<li class="chapter" data-level="9.5.2" data-path="PAF.html"><a href="PAF.html#principal-axis-factoring-paf"><i class="fa fa-check"></i><b>9.5.2</b> Principal Axis Factoring (PAF)</a></li>
<li class="chapter" data-level="9.5.3" data-path="PAF.html"><a href="PAF.html#factor-rotation"><i class="fa fa-check"></i><b>9.5.3</b> Factor Rotation</a></li>
<li class="chapter" data-level="9.5.4" data-path="PAF.html"><a href="PAF.html#factor-scores"><i class="fa fa-check"></i><b>9.5.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="PAF.html"><a href="PAF.html#apa-style-results-1"><i class="fa fa-check"></i><b>9.6</b> APA Style Results</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="PAF.html"><a href="PAF.html#comparing-fa-and-pca"><i class="fa fa-check"></i><b>9.6.1</b> Comparing FA and PCA</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="PAF.html"><a href="PAF.html#going-back-to-the-future-what-then-is-omega"><i class="fa fa-check"></i><b>9.7</b> Going Back to the Future: What, then, is Omega?</a></li>
<li class="chapter" data-level="9.8" data-path="PAF.html"><a href="PAF.html#comparing-pfa-to-item-analysis-and-pca"><i class="fa fa-check"></i><b>9.8</b> Comparing PFA to Item Analysis and PCA</a></li>
<li class="chapter" data-level="9.9" data-path="PAF.html"><a href="PAF.html#practice-problems-7"><i class="fa fa-check"></i><b>9.9</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="PAF.html"><a href="PAF.html#problem-1-play-around-with-this-simulation.-4"><i class="fa fa-check"></i><b>9.9.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="9.9.2" data-path="PAF.html"><a href="PAF.html#problem-2-conduct-a-paf-with-another-simulated-set-of-data-in-the-oer."><i class="fa fa-check"></i><b>9.9.2</b> Problem #2: Conduct a PAF with another simulated set of data in the OER.</a></li>
<li class="chapter" data-level="9.9.3" data-path="PAF.html"><a href="PAF.html#problem-3-try-something-entirely-new.-4"><i class="fa fa-check"></i><b>9.9.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="9.9.4" data-path="PAF.html"><a href="PAF.html#grading-rubric-4"><i class="fa fa-check"></i><b>9.9.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="PAF.html"><a href="PAF.html#homeworked-example-4"><i class="fa fa-check"></i><b>9.10</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="PAF.html"><a href="PAF.html#check-and-if-needed-format-data-2"><i class="fa fa-check"></i><b>9.10.1</b> Check and, if needed, format data</a></li>
<li class="chapter" data-level="9.10.2" data-path="PAF.html"><a href="PAF.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-paf-is-appropriate-as-an-analysis-kmo-bartletts-determinant"><i class="fa fa-check"></i><b>9.10.2</b> Conduct and interpret the three diagnostic tests to determine if PAF is appropriate as an analysis (KMO, Bartlett’s, determinant)</a></li>
<li class="chapter" data-level="9.10.3" data-path="PAF.html"><a href="PAF.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory-1"><i class="fa fa-check"></i><b>9.10.3</b> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)</a></li>
<li class="chapter" data-level="9.10.4" data-path="PAF.html"><a href="PAF.html#conduct-an-orthogonal-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>9.10.4</b> Conduct an orthogonal rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="9.10.5" data-path="PAF.html"><a href="PAF.html#conduct-an-oblique-rotation-with-a-minimum-of-two-different-factor-extractions"><i class="fa fa-check"></i><b>9.10.5</b> Conduct an oblique rotation with a minimum of two different factor extractions</a></li>
<li class="chapter" data-level="9.10.6" data-path="PAF.html"><a href="PAF.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest-1"><i class="fa fa-check"></i><b>9.10.6</b> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest</a></li>
<li class="chapter" data-level="9.10.7" data-path="PAF.html"><a href="PAF.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions-1"><i class="fa fa-check"></i><b>9.10.7</b> APA style results section with table and figure of one of the solutions</a></li>
<li class="chapter" data-level="9.10.8" data-path="PAF.html"><a href="PAF.html#explanation-to-grader-2"><i class="fa fa-check"></i><b>9.10.8</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="confirmatory-factor-analysis-1.html"><a href="confirmatory-factor-analysis-1.html"><i class="fa fa-check"></i>Confirmatory Factor Analysis</a></li>
<li class="chapter" data-level="10" data-path="CFA1st.html"><a href="CFA1st.html"><i class="fa fa-check"></i><b>10</b> CFA: First Order Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="CFA1st.html"><a href="CFA1st.html#navigating-this-lesson-8"><i class="fa fa-check"></i><b>10.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="CFA1st.html"><a href="CFA1st.html#learning-objectives-8"><i class="fa fa-check"></i><b>10.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.1.2" data-path="CFA1st.html"><a href="CFA1st.html#planning-for-practice-8"><i class="fa fa-check"></i><b>10.1.2</b> Planning for Practice</a></li>
<li class="chapter" data-level="10.1.3" data-path="CFA1st.html"><a href="CFA1st.html#readings-resources-8"><i class="fa fa-check"></i><b>10.1.3</b> Readings &amp; Resources</a></li>
<li class="chapter" data-level="10.1.4" data-path="CFA1st.html"><a href="CFA1st.html#packages-8"><i class="fa fa-check"></i><b>10.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="CFA1st.html"><a href="CFA1st.html#two-broad-categories-of-factor-analysis-exploratory-and-confirmatory"><i class="fa fa-check"></i><b>10.2</b> Two Broad Categories of Factor Analysis: Exploratory and Confirmatory</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="CFA1st.html"><a href="CFA1st.html#common-to-both-exploratory-and-confirmatory-approaches"><i class="fa fa-check"></i><b>10.2.1</b> Common to Both Exploratory and Confirmatory Approaches</a></li>
<li class="chapter" data-level="10.2.2" data-path="CFA1st.html"><a href="CFA1st.html#differences-between-efa-and-cfa"><i class="fa fa-check"></i><b>10.2.2</b> Differences between EFA and CFA</a></li>
<li class="chapter" data-level="10.2.3" data-path="CFA1st.html"><a href="CFA1st.html#on-the-relationship-between-efa-and-cfa"><i class="fa fa-check"></i><b>10.2.3</b> On the relationship between EFA and CFA</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="CFA1st.html"><a href="CFA1st.html#exploring-a-standard-cfa-model"><i class="fa fa-check"></i><b>10.3</b> Exploring a Standard CFA Model</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="CFA1st.html"><a href="CFA1st.html#model-identification-for-cfa"><i class="fa fa-check"></i><b>10.3.1</b> Model Identification for CFA</a></li>
<li class="chapter" data-level="10.3.2" data-path="CFA1st.html"><a href="CFA1st.html#selecting-indicatorsitems-for-a-reflective-measurement"><i class="fa fa-check"></i><b>10.3.2</b> Selecting Indicators/Items for a Reflective Measurement</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="CFA1st.html"><a href="CFA1st.html#cfa-workflow"><i class="fa fa-check"></i><b>10.4</b> CFA Workflow</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="CFA1st.html"><a href="CFA1st.html#cfa-in-lavaan-requires-fluency-with-the-syntax"><i class="fa fa-check"></i><b>10.4.1</b> CFA in <em>lavaan</em> Requires Fluency with the Syntax</a></li>
<li class="chapter" data-level="10.4.2" data-path="CFA1st.html"><a href="CFA1st.html#differing-factor-structures"><i class="fa fa-check"></i><b>10.4.2</b> Differing Factor Structures</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="CFA1st.html"><a href="CFA1st.html#research-vignette-7"><i class="fa fa-check"></i><b>10.5</b> Research Vignette</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="CFA1st.html"><a href="CFA1st.html#modeling-the-grmsaaw-as-unidimensional"><i class="fa fa-check"></i><b>10.5.1</b> Modeling the GRMSAAW as Unidimensional</a></li>
<li class="chapter" data-level="10.5.2" data-path="CFA1st.html"><a href="CFA1st.html#modeling-the-grmsaaw-as-a-first-order-4-factor-model"><i class="fa fa-check"></i><b>10.5.2</b> Modeling the GRMSAAW as a First-Order, 4-factor model</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="CFA1st.html"><a href="CFA1st.html#model-comparison"><i class="fa fa-check"></i><b>10.6</b> Model Comparison</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="CFA1st.html"><a href="CFA1st.html#apa-results-section-so-far"><i class="fa fa-check"></i><b>10.6.1</b> APA Results Section (so far…)</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="CFA1st.html"><a href="CFA1st.html#a-concluding-thought"><i class="fa fa-check"></i><b>10.7</b> A concluding thought</a></li>
<li class="chapter" data-level="10.8" data-path="CFA1st.html"><a href="CFA1st.html#practice-problems-8"><i class="fa fa-check"></i><b>10.8</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="CFA1st.html"><a href="CFA1st.html#problem-1-play-around-with-this-simulation.-5"><i class="fa fa-check"></i><b>10.8.1</b> Problem #1: Play around with this simulation.</a></li>
<li class="chapter" data-level="10.8.2" data-path="CFA1st.html"><a href="CFA1st.html#problem-2-use-simulated-data-from-other-lessons."><i class="fa fa-check"></i><b>10.8.2</b> Problem #2: Use simulated data from other lessons.</a></li>
<li class="chapter" data-level="10.8.3" data-path="CFA1st.html"><a href="CFA1st.html#problem-3-try-something-entirely-new.-5"><i class="fa fa-check"></i><b>10.8.3</b> Problem #3: Try something entirely new.</a></li>
<li class="chapter" data-level="10.8.4" data-path="CFA1st.html"><a href="CFA1st.html#grading-rubric-5"><i class="fa fa-check"></i><b>10.8.4</b> Grading Rubric</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="CFA1st.html"><a href="CFA1st.html#homeworked-example-5"><i class="fa fa-check"></i><b>10.9</b> Homeworked Example</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="CFA1st.html"><a href="CFA1st.html#prepare-data-for-cfa-items-only-df-reverse-scored"><i class="fa fa-check"></i><b>10.9.1</b> Prepare data for CFA (items only df, reverse-scored)</a></li>
<li class="chapter" data-level="10.9.2" data-path="CFA1st.html"><a href="CFA1st.html#specify-and-run-a-unidimensional-model"><i class="fa fa-check"></i><b>10.9.2</b> Specify and run a unidimensional model</a></li>
<li class="chapter" data-level="10.9.3" data-path="CFA1st.html"><a href="CFA1st.html#narrate-adequacy-of-fit-with-chi-2-cfi-rmsea-srmr-write-a-mini-results-section"><i class="fa fa-check"></i><b>10.9.3</b> Narrate adequacy of fit with <span class="math inline">\(\chi ^{2}\)</span>, CFI, RMSEA, SRMR (write a mini-results section)</a></li>
<li class="chapter" data-level="10.9.4" data-path="CFA1st.html"><a href="CFA1st.html#specify-and-run-a-single-order-model-with-correlated-factors"><i class="fa fa-check"></i><b>10.9.4</b> Specify and run a single-order model with correlated factors</a></li>
<li class="chapter" data-level="10.9.5" data-path="CFA1st.html"><a href="CFA1st.html#narrate-adequacy-of-fit-with-chi-2-cfi-rmsea-srmr-write-a-mini-results-section-1"><i class="fa fa-check"></i><b>10.9.5</b> Narrate adequacy of fit with <span class="math inline">\(\chi ^{2}\)</span>, CFI, RMSEA, SRMR (write a mini-results section)</a></li>
<li class="chapter" data-level="10.9.6" data-path="CFA1st.html"><a href="CFA1st.html#compare-model-fit-with-chi-2delta-aic-bic"><i class="fa fa-check"></i><b>10.9.6</b> Compare model fit with <span class="math inline">\(\chi ^{2}\Delta\)</span>, AIC, BIC</a></li>
<li class="chapter" data-level="10.9.7" data-path="CFA1st.html"><a href="CFA1st.html#apa-style-results-with-tables-and-figure"><i class="fa fa-check"></i><b>10.9.7</b> APA style results with table(s) and figure</a></li>
<li class="chapter" data-level="10.9.8" data-path="CFA1st.html"><a href="CFA1st.html#explanation-to-grader-3"><i class="fa fa-check"></i><b>10.9.8</b> Explanation to grader</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sims.html"><a href="sims.html"><i class="fa fa-check"></i><b>11</b> Additional Simulations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sims.html"><a href="sims.html#ibelong-scale"><i class="fa fa-check"></i><b>11.1</b> iBelong Scale</a></li>
<li class="chapter" data-level="11.2" data-path="sims.html"><a href="sims.html#identity-threat"><i class="fa fa-check"></i><b>11.2</b> Identity Threat</a></li>
<li class="chapter" data-level="11.3" data-path="sims.html"><a href="sims.html#anti-racism-behavioral-inventory"><i class="fa fa-check"></i><b>11.3</b> Anti-Racism Behavioral Inventory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="REFS.html"><a href="REFS.html"><i class="fa fa-check"></i>REFERENCES</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ReCentering Psych Stats: Psychometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="PCA" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Principal Components Analysis<a href="PCA.html#PCA" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><a href="https://youtube.com/playlist?list=PLtz5cFLQl4KNzmApvhfVE7gNpZOQL1OVR&amp;si=F65ij19VytmImI4Z">Screencasted Lecture Link</a></p>
<p>In this lesson on principal components analysis (PCA) I provide an introduction to the exploratory factor analysis (EFA) arena. We will review the theoretical and technical aspects of PCA, we will work through a research vignette, and then consider the relationship of PCA to item analysis and reliability coefficients.</p>
<p>Please note, although PCA is frequently grouped into EFA techniques, it is <em>exploratory</em> but it is not <em>factor analysis</em>. We’ll discuss the difference in the lecture.</p>
<div id="navigating-this-lesson-6" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Navigating this Lesson<a href="PCA.html#navigating-this-lesson-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are about two hours of lecture. If you work through the materials with me, I would be plan for an additional hour-and-a-half.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_Psychometrics">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="ReCintro.html#ReCintro">introduction</a></p>
<div id="learning-objectives-6" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Learning Objectives<a href="PCA.html#learning-objectives-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Focusing on this week’s materials, make sure you can:</p>
<ul>
<li>Distinguish between PCA and PAF on several levels:
<ul>
<li>which path diagram represents each best, and</li>
<li>keywords associated with each: factor loadings, linear components, describe versus explain.</li>
</ul></li>
<li>Recognize/define an identity matrix – what test would you use to diagnose it?</li>
<li>Recognize/define multicollinearity and singularity – what test would you use to diagnose it?</li>
<li>Describe the pattern of “loadings” (i.e., the relative weights of an item on its own scale compared to other scales)that supports the structure of the instrument.</li>
<li>Compare the results from item analysis and PCA.</li>
</ul>
</div>
<div id="planning-for-practice-6" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Planning for Practice<a href="PCA.html#planning-for-practice-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. The least complex is to change the random seed in the research and rework the problem demonstrated in the lesson. The results <em>should</em> map onto the ones obtained in the lecture.</p>
<p>The second option involves utilizing one of the simulated datasets available in this OER. The <a href="sims.html#sims">last lesson</a> in the OER contains three simulations that could be used for all of the statistics-based practice suggestions. Especially if you started with one of these examples in an earlier lesson, I highly recommend you continue with that.</p>
<p>Alternatively, Keum et al.’s Gendered Racial Microaggressions Scale for Asian American Women <span class="citation">(<a href="#ref-keum_gendered_2018">2018</a>)</span> will be used in the lessons on confirmatory factor analysis and Conover et al.’s <span class="citation">(<a href="#ref-conover_development_2017">2017</a>)</span> Ableist Microaggressions Scale is used in the lesson on invariance testing. Both of these would be suitable for the PCA and PAF homework assignments.</p>
<p>As a third option, you are welcome to use data to which you have access and is suitable for PCA. These could include other vignettes from this OER, other simulated data, or your own data (presuming you have permission to use it). In any case, please plan to:</p>
<ul>
<li>Properly format and prepare the data.</li>
<li>Conduct diagnostic tests to determine the suitability of the data for PCA.</li>
<li>Conducting tests to guide the decisions about number of components to extract.</li>
<li>Conducting orthogonal and oblique extractions (at least two each with different numbers of components).</li>
<li>Selecting one solution and preparing an APA style results section (with table and figure).</li>
<li>Compare your results in light of any other psychometrics lessons where you have used this data.</li>
</ul>
</div>
<div id="readings-resources-6" class="section level3 hasAnchor" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Readings &amp; Resources<a href="PCA.html#readings-resources-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li>Revelle, William. (n.d.). Chapter 6: Constructs, components, and factor models. In <em>An introduction to psychometric theory with applications in R</em>. Retrieved from <a href="https://personality-project.org/r/book/#chapter6" class="uri">https://personality-project.org/r/book/#chapter6</a>
<ul>
<li>pp. 145 to 150 (we’ll continue with the rest in the next lecture). Stop at “6.2 Exploratory Factor Analysis.”</li>
<li>A simultaneously theoretical review of psychometric theory while working with R and data to understand the concepts.</li>
</ul></li>
<li>Revelle, W. (2019). <em>How To: Use the psych package for Factor Analysis and data reduction</em>.
<ul>
<li>pp. 13 throuh 24 provide technical information about what we are doing</li>
</ul></li>
<li>Dekay, Nicole (2021). Quick Reference Guide: The statistics for psychometrics <a href="https://www.humanalysts.com/quick-reference-guide-the-statistics-for-psychometrics" class="uri">https://www.humanalysts.com/quick-reference-guide-the-statistics-for-psychometrics</a></li>
<li>Lewis, J. A., &amp; Neville, H. A. (2015). Construction and initial validation of the Gendered Racial Microaggressions Scale for Black Women. <em>Journal of Counseling Psychology, 62</em>(2), 289–302. <a href="https://doi.org/10.1037/cou0000062" class="uri">https://doi.org/10.1037/cou0000062</a>
<ul>
<li>Our research vignette for this lesson.</li>
</ul></li>
</ul>
</div>
<div id="packages-6" class="section level3 hasAnchor" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Packages<a href="PCA.html#packages-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The packages used in this lesson are embedded in this code. When the hashtags are removed, the script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="PCA.html#cb222-1" tabindex="-1"></a><span class="co"># will install the package if not already installed</span></span>
<span id="cb222-2"><a href="PCA.html#cb222-2" tabindex="-1"></a><span class="co"># if(!require(psych)){install.packages(&#39;psych&#39;)}</span></span>
<span id="cb222-3"><a href="PCA.html#cb222-3" tabindex="-1"></a><span class="co"># if(!require(tidyverse)){install.packages(&#39;tidyverse&#39;)}</span></span>
<span id="cb222-4"><a href="PCA.html#cb222-4" tabindex="-1"></a><span class="co"># if(!require(MASS)){install.packages(&#39;MASS&#39;)}</span></span>
<span id="cb222-5"><a href="PCA.html#cb222-5" tabindex="-1"></a><span class="co"># if(!require(sjstats)){install.packages(&#39;sjstats&#39;)}</span></span>
<span id="cb222-6"><a href="PCA.html#cb222-6" tabindex="-1"></a><span class="co"># if(!require(apaTables)){install.packages(&#39;apaTables&#39;)}</span></span>
<span id="cb222-7"><a href="PCA.html#cb222-7" tabindex="-1"></a><span class="co"># if(!require(qualtRics)){install.packages(&#39;qualtRics&#39;)}</span></span></code></pre></div>
</div>
</div>
<div id="exploratory-principal-components-analysis" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Exploratory Principal Components Analysis<a href="PCA.html#exploratory-principal-components-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The psychometric version of <em>parsimony</em> is seen in our attempt to <em>describe</em> (components) or to <em>explain</em> (factors) in the relationships between many observed variables in terms of a more limited set of components, latent factors, or dimensions.</p>
<p>That is, we are trying to:</p>
<ul>
<li>understand the structure of a set of variables,</li>
<li>construct a questionnaire to measure an underlying latent variable, and</li>
<li>reduce a data set to a more manageable size (e.g., representing bundles of items as subscale scores) while retaining as much of the information as possible</li>
</ul>
<div id="some-framing-ideas-in-very-lay-terms" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Some Framing Ideas (in very lay terms)<a href="PCA.html#some-framing-ideas-in-very-lay-terms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Exploratory</em> versus <em>confirmatory</em> factor analysis.</p>
<ul>
<li><p>Both exploratory and confirmatory approaches to components/factor analysis are used in scale construction. Think of “scales” as being interchangeable with “factors” and “components.”</p>
<ul>
<li>That said, “factors” and “components” are not interchangeable terms.</li>
</ul></li>
<li><p><strong>Exploratory</strong>: Even though we may have an a priori model in mind, we <em>explore</em> the structure of the items by using diagnostics (KMO, Barlett’s, determinant), factor extraction, and rotation to determine the number of scales (i.e., components or factors) that exist within the raw data or correlation matrix. The algorithms (including matrix algebra) determine the relationship of each item to its respective scales (i.e., components or factors).</p></li>
<li><p><strong>Confirmatory</strong>: Starting with an a priori theory, we specify the structure (i.e., number and levels of factors) and which items belong to factors. We use structural equation modeling as the framework. We evaluate the quality of the model with a number of fit indices.</p></li>
</ul>
<p>Within the <em>exploratory</em> category we will focus on two further distinctions (there are even more). The first is principal components analysis (PCA). The second is principal axis factoring (PAF). PAF is one of the approaches that is commonly termed “exploratory factor analysis” (EFA). In this first lesson we focus on the differences between PCA and EFA.</p>
<ul>
<li><p><strong>Option #1/Component model</strong>: PCA approximates the correlation matrix in terms of the product of components where each is a weighted linear sum of the variables. In the figure below, note how the arrows in the components analysis (a <em>path</em> model) point from variables to the component. Perhaps an oversimplification, think of each of these as a predictor variable contributing to an outcome.</p></li>
<li><p><strong>Option #2/Factor model</strong>: EFA (and in the next lesson, PAF/principal axis factoring) approximates the correlation matrix by the product of the two factors; this approach presumes that the factors are the causes (rather than as consequences). In the figure below, note how the arrows in the factor analysis model (a <em>structural</em> model) point from latent variable (or factor) to the observed variables (items). Factor analysis has been termed <em>causal modeling</em> because the latent variables are theorized to cause the responses to the individual items. There are other popular approaches, including parallel analysis (which is what the authors used in this lesson’s research vignette).</p></li>
</ul>
<p>Well-crafted figures provide important clues to the analyses. In structural models, rectangles and squares indicate the presence of <em>observed</em> (also called <em>manifest</em>) variables. These are variables that have a column in the dataset. In our particular case, they are the responses to the 25 items in the GRMS.</p>
<p>Circles or ovals represent latent variables or factors. These were never raw data, but are composed of the relations of variables that were collected. They are more complex than mean or sum scores. Rather, they represent what the variables that represent them share in common.</p>
<div class="float">
<img src="images/PCA/PCAvPAF.png" alt="Comparison of path models for PCA and EFA for our research vignette" />
<div class="figcaption">Comparison of path models for PCA and EFA for our research vignette</div>
</div>
<p>Our focus today is on the principal component analysis (PCA) approach to scale construction.</p>
</div>
</div>
<div id="pca-workflow" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> PCA Workflow<a href="PCA.html#pca-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below is a screenshot of the workflow. The original document is located in the <a href="https://github.com/lhbikos/ReC_Psychometrics">Github site</a> that hosts the ReCentering Psych Stats: Psychometrics OER.</p>
<div class="float">
<img src="images/PCA/PCAworkflow.png" alt="Image of the workflow for PCA" />
<div class="figcaption">Image of the workflow for PCA</div>
</div>
<p>Steps in the process include:</p>
<ul>
<li>Creating an <em>items only</em> dataframe where any items are scaled in the same direction (e.g., negatively worded items are reverse-scored).</li>
<li>Conducting tests that assess the statistical assumptions of PCA to ensure that the data is appropriate for PCA.</li>
<li>Determining the number of components (think “subscales”) to extract.</li>
<li>Conducting the component extraction – this process will likely occur iteratively,
<ul>
<li>exploring orthogonal (uncorrelated/independent) and oblique (correlated)components, and</li>
<li>changing the number of components to extract</li>
</ul></li>
</ul>
<p>Because the intended audience for the ReCentering Psych Stats OER is the scientist-practitioner-advocate, this lesson focuses on the workflow and decisions. As you might guess, the details of PCA can be quite complex. Some important notions to consider that may not be obvious from lesson, are these:</p>
<ul>
<li>The values of component loadings are directly related to the correlation (similarly, the covariance) matrix between the items.
<ul>
<li>Although I do not explain this in detail, nearly every analytic step attempts to convey this notion by presenting equivalent analytic options using the raw data and correlation matrix.</li>
</ul></li>
<li>PCA is about <em>dimension reduction</em> – our goal is fewer components (i.e., subscales) than there are items.
<ul>
<li>In this lesson’s vignette there are 25 items on the scale and we will end up with 4 subscales.</li>
</ul></li>
<li>Principal component analysis is <em>exploratory</em>, but it is not “factor analysis.”</li>
<li>Matrix algebra (e.g., using the transpose of a matrix, multiplying matrices together) plays a critical role in the analytic solution.</li>
</ul>
</div>
<div id="research-vignette-5" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Research Vignette<a href="PCA.html#research-vignette-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This lesson’s research vignette emerges from Lewis and Neville’s Gendered Racial Microaggressions Scale for Black Women <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span>. The article reports on two separate studies that comprised the development, refinement, and psychometric evaluation of two parallel versions (stress appraisal, frequency) of the scale. Below, I simulate data from the final construction of the stress appraisal version as the basis of the lecture. Items were on a 6-point Likert scale ranging from 0 (<em>not at all stressful</em>) to 5 (<em>extremely stressful</em>).</p>
<p>Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> reported support for a total scale score (25 items) and four subscales. Below, I list the four subscales along with the items and their abbreviation. At the outset, let me provide a content advisory. For those who hold this particular identity (or related identities) the content in the items may be upsetting. In other lessons, I often provide a variable name that gives an indication of the primary content of the item. In the case of the GRMS, I will simply provide an abbreviation of the subscale name and its respective item number. This will allow us to easily inspect the alignment of the item with its intended factor, and hopefully minimize discomfort.</p>
<p>If you are not a member of this particular identity, I encourage you to learn about these microaggressions by reading the article in its entirety. Please do not ask members of this group to explain why these microaggressions are harmful or ask if they have encountered them. The four factors, number of items, and sample item are as follows:</p>
<ul>
<li>Assumptions of Beauty and Sexual Objectification (10 items)
<ul>
<li>Unattractive because of size of butt (Obj1)</li>
<li>Negative comments about size of facial features (Obj2)</li>
<li>Imitated the way they think Black women speak (Obj3)</li>
<li>Someone made me feel unattractive (Obj4)</li>
<li>Negative comment about skin tone (Obj5)</li>
<li>Someone assumed I speak a certain way (Obj6)</li>
<li>Objectified me based on physical features(Obj7)</li>
<li>Someone assumed I have a certain body type (Obj8; stress only)</li>
<li>Made a sexually inappropriate comment (Obj9)</li>
<li>Negative comments about my hair when natural (Obj10)</li>
<li>Assumed I was sexually promiscuous (frequency only; not used in this simulation)</li>
</ul></li>
<li>Silenced and Marginalized (7 items)
<ul>
<li>I have felt unheard (Marg1)</li>
<li>My comments have been ignored (Marg2)</li>
<li>Someone challenged my authority (Marg3)</li>
<li>I have been disrespected in workplace (Marg4)</li>
<li>Someone has tried to “put me in my place” (Marg5)</li>
<li>Felt excluded from networking opportunities (Marg6)</li>
<li>Assumed I did not have much to contribute to the conversation (Marg7)</li>
</ul></li>
<li>Strong Black Woman Stereotype (5 items)
<ul>
<li>Someone assumed I was sassy and straightforward (Str1; stress only)</li>
<li>I have been told that I am too independent (Str2)</li>
<li>Someone made me feel exotic as a Black woman (Str2; stress only)</li>
<li>I have been told that I am too assertive</li>
<li>Assumed to be a strong Black woman</li>
</ul></li>
<li>Angry Black Woman Stereotype (3 items)
<ul>
<li>Someone has told me to calm down (Ang1)</li>
<li>Perceived to be “angry Black woman” (Ang2)</li>
<li>Someone accused me of being angry when speaking calm (Ang3)</li>
</ul></li>
</ul>
<p>Three additional scales were reported in the Lewis and Neville article <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span>.
Because (a) the focus of this lesson is on exploratory factor analytic approaches and, therefore, only requires item-level data for the scale, and (b) the article does not include correlations between the subscales/scales of all involved measures, I only simulated item-level data for the GRMS items.</p>
<p>Below, I walk through the data simulation. This is not an essential portion of the lesson, but I will lecture it in case you are interested. None of the items are negatively worded (relative to the other items), so there is no need to reverse-score any items.</p>
<p>Simulating the data involved using factor loadings, means, standard deviations, and correlations between the scales. Because the simulation will produce “out-of-bounds” values, the code below rescales the scores into the range of the Likert-type scaling and rounds them to whole values.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="PCA.html#cb223-1" tabindex="-1"></a><span class="co"># Entering the intercorrelations, means, and standard deviations from</span></span>
<span id="cb223-2"><a href="PCA.html#cb223-2" tabindex="-1"></a><span class="co"># the journal article</span></span>
<span id="cb223-3"><a href="PCA.html#cb223-3" tabindex="-1"></a></span>
<span id="cb223-4"><a href="PCA.html#cb223-4" tabindex="-1"></a>LewisGRMS_generating_model <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb223-5"><a href="PCA.html#cb223-5" tabindex="-1"></a><span class="st">        #measurement model</span></span>
<span id="cb223-6"><a href="PCA.html#cb223-6" tabindex="-1"></a><span class="st">        Objectification =~ .69*Obj1 + .69*Obj2 + .60*Obj3 + .59*Obj4 + .55*Obj5 + .55*Obj6 + .54*Obj7 + .50*Obj8 + .41*Obj9 + .41*Obj10</span></span>
<span id="cb223-7"><a href="PCA.html#cb223-7" tabindex="-1"></a><span class="st">        Marginalized =~ .93*Marg1 + .81*Marg2 +.69*Marg3 + .67*Marg4 + .61*Marg5 + .58*Marg6 +.54*Marg7</span></span>
<span id="cb223-8"><a href="PCA.html#cb223-8" tabindex="-1"></a><span class="st">        Strong =~ .59*Str1 + .55*Str2 + .54*Str3 + .54*Str4 + .51*Str5</span></span>
<span id="cb223-9"><a href="PCA.html#cb223-9" tabindex="-1"></a><span class="st">        Angry =~ .70*Ang1 + .69*Ang2 + .68*Ang3</span></span>
<span id="cb223-10"><a href="PCA.html#cb223-10" tabindex="-1"></a><span class="st">        </span></span>
<span id="cb223-11"><a href="PCA.html#cb223-11" tabindex="-1"></a><span class="st">        #Means</span></span>
<span id="cb223-12"><a href="PCA.html#cb223-12" tabindex="-1"></a><span class="st">         Objectification ~ 1.85*1</span></span>
<span id="cb223-13"><a href="PCA.html#cb223-13" tabindex="-1"></a><span class="st">         Marginalized ~ 2.67*1</span></span>
<span id="cb223-14"><a href="PCA.html#cb223-14" tabindex="-1"></a><span class="st">         Strong ~ 1.61*1</span></span>
<span id="cb223-15"><a href="PCA.html#cb223-15" tabindex="-1"></a><span class="st">         Angry ~ 2.29*1</span></span>
<span id="cb223-16"><a href="PCA.html#cb223-16" tabindex="-1"></a><span class="st">         </span></span>
<span id="cb223-17"><a href="PCA.html#cb223-17" tabindex="-1"></a><span class="st">        #Correlations</span></span>
<span id="cb223-18"><a href="PCA.html#cb223-18" tabindex="-1"></a><span class="st">         Objectification ~~ .63*Marginalized</span></span>
<span id="cb223-19"><a href="PCA.html#cb223-19" tabindex="-1"></a><span class="st">         Objectification ~~ .66*Strong</span></span>
<span id="cb223-20"><a href="PCA.html#cb223-20" tabindex="-1"></a><span class="st">         Objectification ~~ .51*Angry</span></span>
<span id="cb223-21"><a href="PCA.html#cb223-21" tabindex="-1"></a><span class="st">         </span></span>
<span id="cb223-22"><a href="PCA.html#cb223-22" tabindex="-1"></a><span class="st">         Marginalized ~~ .59*Strong</span></span>
<span id="cb223-23"><a href="PCA.html#cb223-23" tabindex="-1"></a><span class="st">         Marginalized ~~ .62*Angry</span></span>
<span id="cb223-24"><a href="PCA.html#cb223-24" tabindex="-1"></a></span>
<span id="cb223-25"><a href="PCA.html#cb223-25" tabindex="-1"></a><span class="st">         Strong ~~ .61*Angry</span></span>
<span id="cb223-26"><a href="PCA.html#cb223-26" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb223-27"><a href="PCA.html#cb223-27" tabindex="-1"></a><span class="st">        &quot;</span></span>
<span id="cb223-28"><a href="PCA.html#cb223-28" tabindex="-1"></a></span>
<span id="cb223-29"><a href="PCA.html#cb223-29" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">240311</span>)</span>
<span id="cb223-30"><a href="PCA.html#cb223-30" tabindex="-1"></a>dfGRMS <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">simulateData</span>(<span class="at">model =</span> LewisGRMS_generating_model, <span class="at">model.type =</span> <span class="st">&quot;sem&quot;</span>,</span>
<span id="cb223-31"><a href="PCA.html#cb223-31" tabindex="-1"></a>    <span class="at">meanstructure =</span> T, <span class="at">sample.nobs =</span> <span class="dv">259</span>, <span class="at">standardized =</span> <span class="cn">FALSE</span>)</span>
<span id="cb223-32"><a href="PCA.html#cb223-32" tabindex="-1"></a></span>
<span id="cb223-33"><a href="PCA.html#cb223-33" tabindex="-1"></a><span class="co"># used to retrieve column indices used in the rescaling script below</span></span>
<span id="cb223-34"><a href="PCA.html#cb223-34" tabindex="-1"></a>col_index <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">colnames</span>(dfGRMS))</span>
<span id="cb223-35"><a href="PCA.html#cb223-35" tabindex="-1"></a></span>
<span id="cb223-36"><a href="PCA.html#cb223-36" tabindex="-1"></a><span class="co"># The code below loops through each column of the dataframe and</span></span>
<span id="cb223-37"><a href="PCA.html#cb223-37" tabindex="-1"></a><span class="co"># assigns the scaling accordingly Rows 1 thru 26 are the GRMS items</span></span>
<span id="cb223-38"><a href="PCA.html#cb223-38" tabindex="-1"></a></span>
<span id="cb223-39"><a href="PCA.html#cb223-39" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(dfGRMS)) {</span>
<span id="cb223-40"><a href="PCA.html#cb223-40" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="sc">&gt;=</span> <span class="dv">1</span> <span class="sc">&amp;</span> i <span class="sc">&lt;=</span> <span class="dv">25</span>) {</span>
<span id="cb223-41"><a href="PCA.html#cb223-41" tabindex="-1"></a>        dfGRMS[, i] <span class="ot">&lt;-</span> scales<span class="sc">::</span><span class="fu">rescale</span>(dfGRMS[, i], <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">5</span>))</span>
<span id="cb223-42"><a href="PCA.html#cb223-42" tabindex="-1"></a>    }</span>
<span id="cb223-43"><a href="PCA.html#cb223-43" tabindex="-1"></a>}</span>
<span id="cb223-44"><a href="PCA.html#cb223-44" tabindex="-1"></a></span>
<span id="cb223-45"><a href="PCA.html#cb223-45" tabindex="-1"></a><span class="co"># rounding to integers so that the data resembles that which was</span></span>
<span id="cb223-46"><a href="PCA.html#cb223-46" tabindex="-1"></a><span class="co"># collected</span></span>
<span id="cb223-47"><a href="PCA.html#cb223-47" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb223-48"><a href="PCA.html#cb223-48" tabindex="-1"></a>dfGRMS <span class="ot">&lt;-</span> dfGRMS <span class="sc">%&gt;%</span></span>
<span id="cb223-49"><a href="PCA.html#cb223-49" tabindex="-1"></a>    <span class="fu">round</span>(<span class="dv">0</span>)</span>
<span id="cb223-50"><a href="PCA.html#cb223-50" tabindex="-1"></a></span>
<span id="cb223-51"><a href="PCA.html#cb223-51" tabindex="-1"></a><span class="co"># quick check of my work psych::describe(dfGRMS)</span></span></code></pre></div>
<p>The optional script below will let you save the simulated data to your computing environment as either an .rds object (preserves any formatting you might do) or a .csv file (think “Excel lite”).</p>
<p>An .rds file preserves all formatting to variables prior to the export and re-import. For the purpose of this chapter, you don’t need to do either. That is, you can re-simulate the data each time you work the problem.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="PCA.html#cb224-1" tabindex="-1"></a><span class="co"># to save the df as an .rds (think &#39;R object&#39;) file on your computer;</span></span>
<span id="cb224-2"><a href="PCA.html#cb224-2" tabindex="-1"></a><span class="co"># it should save in the same file as the .rmd file you are working</span></span>
<span id="cb224-3"><a href="PCA.html#cb224-3" tabindex="-1"></a><span class="co"># with saveRDS(dfGRMS, &#39;dfGRMS.rds&#39;) bring back the simulated dat</span></span>
<span id="cb224-4"><a href="PCA.html#cb224-4" tabindex="-1"></a><span class="co"># from an .rds file dfGRMS &lt;- readRDS(&#39;dfGRMS.rds&#39;)</span></span></code></pre></div>
<p>If you save the .csv file and bring it back in, you will lose any formatting (e.g., ordered factors will be interpreted as character variables).</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="PCA.html#cb225-1" tabindex="-1"></a><span class="co"># write the simulated data as a .csv write.table(dfGRMS,</span></span>
<span id="cb225-2"><a href="PCA.html#cb225-2" tabindex="-1"></a><span class="co"># file=&#39;dfGRMS.csv&#39;, sep=&#39;,&#39;, col.names=TRUE, row.names=FALSE) bring</span></span>
<span id="cb225-3"><a href="PCA.html#cb225-3" tabindex="-1"></a><span class="co"># back the simulated dat from a .csv file dfGRMS &lt;- read.csv</span></span>
<span id="cb225-4"><a href="PCA.html#cb225-4" tabindex="-1"></a><span class="co"># (&#39;dfGRMS.csv&#39;, header = TRUE)</span></span></code></pre></div>
<p>Before moving on, I want to acknowledge that (at their first drafting), I try to select research vignettes that have been published within the prior 5 years. With a publication date of 2015, this article clearly falls outside that range. I have continued to include it because (a) the scholarship is superior – especially as the measure captures an intersectional identity, (b) the article has been a model for research that follows (e.g., Keum et al’s <span class="citation">(<a href="#ref-keum_gendered_2018">2018</a>)</span> Gendered Racial Microaggression Scale for Asian American Women), and (c) there is often a time lag between the initial publication of a psychometric scale and it’s use. A key reason I have retained the GRMS as a psychometrics research vignette is that in <a href="https://lhbikos.github.io/ReC_MultivModel/">ReCentering Psych Stats: Multivariate Modeling</a>, GRMS scales are used in a couple of more recently published research vignettes.</p>
</div>
<div id="working-the-vignette" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Working the Vignette<a href="PCA.html#working-the-vignette" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below we will create a correlation matrix of our items. Whether we are conducting PCA or PAF, the <em>dimension-reduction</em> we are looking for clusters of correlated items in the <span class="math inline">\(R\)</span>-matrix. Essentially, these are <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span>:</p>
<ul>
<li>Statistical entities that can be plotted as classification axes where coordinates of variables along each axis represent the strength of the relationship between that variable to each component (later, factor).</li>
<li>Mathematical equations, resembling regression equations, where each variable is represented according to its relative weight.</li>
</ul>
<p>PCA in particular establishes which linear components exist within the data and how a particular variable might contribute to that component.</p>
<p>Below is the correlation matrix of our items. I have saved it as an object so that I can show you that PCA (and later, PAF) can also be conducted with just correlation data. It would be quite a daunting exercise to visually inspect this and manually cluster the correlations of items.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="PCA.html#cb226-1" tabindex="-1"></a>GRMSmatrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(dfGRMS)  <span class="co">#correlation matrix created and saved as object</span></span>
<span id="cb226-2"><a href="PCA.html#cb226-2" tabindex="-1"></a><span class="fu">round</span>(GRMSmatrix, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>      Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7  Obj8 Obj9 Obj10 Marg1 Marg2 Marg3
Obj1  1.00 0.35 0.25 0.27 0.28 0.25 0.28  0.35 0.15  0.24  0.19  0.25  0.17
Obj2  0.35 1.00 0.31 0.25 0.27 0.23 0.31  0.28 0.26  0.24  0.22  0.21  0.25
Obj3  0.25 0.31 1.00 0.24 0.28 0.28 0.20  0.25 0.21  0.22  0.17  0.23  0.17
Obj4  0.27 0.25 0.24 1.00 0.39 0.23 0.28  0.30 0.26  0.28  0.22  0.18  0.14
Obj5  0.28 0.27 0.28 0.39 1.00 0.15 0.18  0.29 0.25  0.20  0.17  0.20  0.23
Obj6  0.25 0.23 0.28 0.23 0.15 1.00 0.20  0.14 0.21  0.12  0.10  0.14  0.05
Obj7  0.28 0.31 0.20 0.28 0.18 0.20 1.00  0.31 0.19  0.28  0.30  0.21  0.20
Obj8  0.35 0.28 0.25 0.30 0.29 0.14 0.31  1.00 0.19  0.23  0.27  0.14  0.14
Obj9  0.15 0.26 0.21 0.26 0.25 0.21 0.19  0.19 1.00  0.20  0.10  0.12  0.21
Obj10 0.24 0.24 0.22 0.28 0.20 0.12 0.28  0.23 0.20  1.00  0.09  0.12  0.17
Marg1 0.19 0.22 0.17 0.22 0.17 0.10 0.30  0.27 0.10  0.09  1.00  0.43  0.41
Marg2 0.25 0.21 0.23 0.18 0.20 0.14 0.21  0.14 0.12  0.12  0.43  1.00  0.35
Marg3 0.17 0.25 0.17 0.14 0.23 0.05 0.20  0.14 0.21  0.17  0.41  0.35  1.00
Marg4 0.19 0.18 0.24 0.26 0.20 0.10 0.25  0.24 0.07  0.12  0.38  0.23  0.32
Marg5 0.17 0.22 0.21 0.27 0.25 0.16 0.23  0.19 0.19  0.11  0.41  0.40  0.25
Marg6 0.18 0.27 0.16 0.23 0.22 0.26 0.28  0.26 0.15  0.26  0.35  0.27  0.25
Marg7 0.13 0.19 0.14 0.19 0.06 0.17 0.16  0.14 0.10  0.11  0.31  0.33  0.20
Str1  0.22 0.18 0.14 0.06 0.23 0.07 0.25  0.17 0.19  0.10  0.19  0.25  0.20
Str2  0.19 0.18 0.19 0.19 0.12 0.15 0.13  0.06 0.18  0.19  0.12  0.18  0.17
Str3  0.10 0.09 0.09 0.08 0.11 0.09 0.19  0.05 0.12  0.10  0.13  0.18  0.10
Str4  0.09 0.14 0.18 0.15 0.12 0.08 0.07  0.13 0.05  0.02  0.08  0.12  0.08
Str5  0.20 0.15 0.15 0.08 0.19 0.11 0.15  0.04 0.07  0.09  0.10  0.23  0.12
Ang1  0.06 0.07 0.07 0.09 0.12 0.04 0.15  0.07 0.17  0.06  0.16  0.23  0.18
Ang2  0.06 0.15 0.08 0.06 0.09 0.20 0.13 -0.03 0.00  0.14  0.17  0.19  0.19
Ang3  0.21 0.13 0.11 0.14 0.11 0.16 0.23  0.07 0.06  0.08  0.28  0.28  0.11
      Marg4 Marg5 Marg6 Marg7 Str1 Str2 Str3 Str4 Str5 Ang1  Ang2 Ang3
Obj1   0.19  0.17  0.18  0.13 0.22 0.19 0.10 0.09 0.20 0.06  0.06 0.21
Obj2   0.18  0.22  0.27  0.19 0.18 0.18 0.09 0.14 0.15 0.07  0.15 0.13
Obj3   0.24  0.21  0.16  0.14 0.14 0.19 0.09 0.18 0.15 0.07  0.08 0.11
Obj4   0.26  0.27  0.23  0.19 0.06 0.19 0.08 0.15 0.08 0.09  0.06 0.14
Obj5   0.20  0.25  0.22  0.06 0.23 0.12 0.11 0.12 0.19 0.12  0.09 0.11
Obj6   0.10  0.16  0.26  0.17 0.07 0.15 0.09 0.08 0.11 0.04  0.20 0.16
Obj7   0.25  0.23  0.28  0.16 0.25 0.13 0.19 0.07 0.15 0.15  0.13 0.23
Obj8   0.24  0.19  0.26  0.14 0.17 0.06 0.05 0.13 0.04 0.07 -0.03 0.07
Obj9   0.07  0.19  0.15  0.10 0.19 0.18 0.12 0.05 0.07 0.17  0.00 0.06
Obj10  0.12  0.11  0.26  0.11 0.10 0.19 0.10 0.02 0.09 0.06  0.14 0.08
Marg1  0.38  0.41  0.35  0.31 0.19 0.12 0.13 0.08 0.10 0.16  0.17 0.28
Marg2  0.23  0.40  0.27  0.33 0.25 0.18 0.18 0.12 0.23 0.23  0.19 0.28
Marg3  0.32  0.25  0.25  0.20 0.20 0.17 0.10 0.08 0.12 0.18  0.19 0.11
Marg4  1.00  0.30  0.26  0.16 0.10 0.21 0.05 0.06 0.03 0.12  0.22 0.17
Marg5  0.30  1.00  0.29  0.28 0.16 0.13 0.16 0.14 0.18 0.12  0.14 0.21
Marg6  0.26  0.29  1.00  0.20 0.13 0.18 0.15 0.13 0.08 0.11  0.21 0.12
Marg7  0.16  0.28  0.20  1.00 0.14 0.05 0.04 0.02 0.12 0.17  0.13 0.09
Str1   0.10  0.16  0.13  0.14 1.00 0.21 0.30 0.23 0.23 0.18  0.05 0.10
Str2   0.21  0.13  0.18  0.05 0.21 1.00 0.20 0.20 0.12 0.16  0.12 0.16
Str3   0.05  0.16  0.15  0.04 0.30 0.20 1.00 0.27 0.18 0.20  0.07 0.15
Str4   0.06  0.14  0.13  0.02 0.23 0.20 0.27 1.00 0.12 0.15  0.03 0.02
Str5   0.03  0.18  0.08  0.12 0.23 0.12 0.18 0.12 1.00 0.22  0.15 0.11
Ang1   0.12  0.12  0.11  0.17 0.18 0.16 0.20 0.15 0.22 1.00  0.24 0.23
Ang2   0.22  0.14  0.21  0.13 0.05 0.12 0.07 0.03 0.15 0.24  1.00 0.25
Ang3   0.17  0.21  0.12  0.09 0.10 0.16 0.15 0.02 0.11 0.23  0.25 1.00</code></pre>
<p>This correlation matrix is so big that you might wish to write code so that you can examine it in sections</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="PCA.html#cb228-1" tabindex="-1"></a><span class="co"># round(GRMSmatrix[,1:8], 2) round(GRMSmatrix[,9:16], 2)</span></span>
<span id="cb228-2"><a href="PCA.html#cb228-2" tabindex="-1"></a><span class="co"># round(GRMSmatrix[,17:25], 2)</span></span></code></pre></div>
<p>With component and factor analytic procedures we can analyze the data with either raw data or correlation matrix. Using the correlation matrix helps us perceive how this is a <em>structural</em> analysis. That is, we are trying to see if our more parsimonious extraction (i.e., our <em>dimension reduction</em>) reproduces this original correlation matrix. In each of the analyses I will include code for running the analyses with raw data and the <em>r</em>-matrix.</p>
<div id="three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factor-analysis" class="section level3 hasAnchor" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> Three Diagnostic Tests to Evaluate the Appropriateness of the Data for Component-or-Factor Analysis<a href="PCA.html#three-diagnostic-tests-to-evaluate-the-appropriateness-of-the-data-for-component-or-factor-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below is a snip from the workflow to remind us where we are in the steps to PCA.</p>
<div class="float">
<img src="images/PCA/assumptions.png" alt="Image of an excerpt from the workflow" />
<div class="figcaption">Image of an excerpt from the workflow</div>
</div>
<div id="is-my-sample-adequate-for-pca" class="section level4 hasAnchor" number="8.5.1.1">
<h4><span class="header-section-number">8.5.1.1</span> Is my sample adequate for PCA?<a href="PCA.html#is-my-sample-adequate-for-pca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There have been a number of generic guidelines (some supported with empirical evidence, some not) about “how big” the sample size should be:</p>
<ul>
<li>10-15 participants per variable</li>
<li>10 times as many participants as variables (Nunnally, 1978)</li>
<li>5 and 10 participants per variable up to 300 (Kass &amp; Tinsley, 1979)</li>
<li>300 (Tabachnick &amp; Fidell, 2007)</li>
<li>1000 = excellent, 300 = good, 100 = poor (Comrey &amp; Lee, 1992)</li>
</ul>
<p>Of course it is more complicated. Monte Carlo studies have shown that:</p>
<ul>
<li>if factor loadings are large (~.6), the solution is reliable regardless of size</li>
<li>if communalities are large (~.6), relatively small samples (~100) are sufficient, but when they are lower (well below .5), then larger samples (&gt;500 are indicated).</li>
</ul>
<p>The <strong>Kaiser-Meyer-Olkin</strong> index (KMO) is an index of <em>sampling adequacy</em> that can be used with the actual sample to let us know if the sample size is sufficient relative to the statistical characteristics of the data. If the KMO is below the recommendations, we should probably collect more data to see if it can achieve a satisfactory value.</p>
<p>Kaiser’s 1974 recommendations were:</p>
<ul>
<li>bare minimum of .5</li>
<li>values between .5 and .7 as mediocre</li>
<li>values between .7 and .8 as good</li>
<li>values above .9 are superb</li>
</ul>
<p>Revelle has included a KMO test in the psych package. The function can use either raw or matrix data. Either way, the only variables in the matrix should be the items of interest. This means that everything else (e.g., total or subscale scores, ID numbers) should be removed.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="PCA.html#cb229-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">KMO</span>(dfGRMS)</span></code></pre></div>
<pre><code>Kaiser-Meyer-Olkin factor adequacy
Call: psych::KMO(r = dfGRMS)
Overall MSA =  0.85
MSA for each item = 
 Obj1  Obj2  Obj3  Obj4  Obj5  Obj6  Obj7  Obj8  Obj9 Obj10 Marg1 Marg2 Marg3 
 0.87  0.91  0.88  0.85  0.85  0.80  0.90  0.85  0.81  0.85  0.86  0.89  0.86 
Marg4 Marg5 Marg6 Marg7  Str1  Str2  Str3  Str4  Str5  Ang1  Ang2  Ang3 
 0.86  0.90  0.89  0.84  0.83  0.85  0.82  0.74  0.84  0.78  0.76  0.81 </code></pre>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="PCA.html#cb231-1" tabindex="-1"></a><span class="co"># psych::KMO(GRMSmatrix)</span></span></code></pre></div>
<p>We examine the KMO values for both the overall matrix and the individual items.</p>
<p>At the matrix level, our <span class="math inline">\(KMO = .85\)</span>, which falls into Kaiser’s definition of <em>good</em>. You can locate this value as the “Overall MSA.”</p>
<p>At the item level, the KMO should be &gt; .50. Variables with values below .50 should be evaluated for exclusion from the analysis (or run the analysis with and without the variable and compare the difference). Because removing and adding variables impacts the KMO, be sure to re-evaluate the sampling adequacy if changes are made to the items (and/or sample size).</p>
<p>At the item level, our KMO values range between .74 (Str4) and .91 (Obj2).</p>
<p>Considering both item and matrix levels, we conclude that the sample size and the data are adequate for component (or factor) analysis.</p>
</div>
<div id="are-the-correlations-among-the-variables-large-enough-to-be-analyzed" class="section level4 hasAnchor" number="8.5.1.2">
<h4><span class="header-section-number">8.5.1.2</span> Are the correlations among the variables large enough to be analyzed?<a href="PCA.html#are-the-correlations-among-the-variables-large-enough-to-be-analyzed" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Bartlett’s test</strong> lets us know if a matrix is an <em>identity matrix.</em> In an identity matrix all correlation coefficients (everything on the off-diagonal) would be 0.0 (and everything on the diagonal would be 1.0.</p>
<p>A significant Barlett’s (i.e., <span class="math inline">\(p &lt; .05\)</span>) tells that the <span class="math inline">\(R\)</span>-matrix is not an identity matrix. That is, there are some relationships between variables that can be analyzed.</p>
<p>The <em>cortest.bartlett()</em> function is in the <em>psych</em> package and can be run either from the raw data or R matrix formats.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="PCA.html#cb232-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">cortest.bartlett</span>(dfGRMS)  <span class="co">#from the raw data</span></span></code></pre></div>
<pre><code>R was not square, finding R from data</code></pre>
<pre><code>$chisq
[1] 1217.508

$p.value
[1] 0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001107085

$df
[1] 300</code></pre>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="PCA.html#cb235-1" tabindex="-1"></a><span class="co"># raw data produces the warning &#39;R was not square, finding R from</span></span>
<span id="cb235-2"><a href="PCA.html#cb235-2" tabindex="-1"></a><span class="co"># data.&#39; This means nothing other than we fed it raw data and the</span></span>
<span id="cb235-3"><a href="PCA.html#cb235-3" tabindex="-1"></a><span class="co"># function is creating a matrix from which to do the analysis.</span></span>
<span id="cb235-4"><a href="PCA.html#cb235-4" tabindex="-1"></a></span>
<span id="cb235-5"><a href="PCA.html#cb235-5" tabindex="-1"></a><span class="co"># psych::cortest.bartlett(GRMSmatrix, n = 259) #if using the matrix,</span></span>
<span id="cb235-6"><a href="PCA.html#cb235-6" tabindex="-1"></a><span class="co"># must specify sample</span></span></code></pre></div>
<p>Our Bartlett’s test is significant: <span class="math inline">\(\chi^{2}(300)=1217.508, p &lt; .001\)</span>. This means that our sample correlation matrix is statistically significantly different than an identity matrix and, therefore, supports a component-or-factor analytic approach for investigating the data.</p>
</div>
<div id="is-there-multicollinearity-or-singularity-in-my-data" class="section level4 hasAnchor" number="8.5.1.3">
<h4><span class="header-section-number">8.5.1.3</span> Is there multicollinearity or singularity in my data?<a href="PCA.html#is-there-multicollinearity-or-singularity-in-my-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <strong>determinant of the correlation matrix</strong> should be greater than 0.00001 (that would be 4 zeros, then the 1). If it is smaller than 0.00001 then we may have an issue with <em>multicollinearity</em> (i.e., variables that are too highly correlated) or <em>singularity</em> (variables that are perfectly correlated).</p>
<p>The determinant function we use comes from base R. It is easiest to compute when the correlation matrix is the object. However, it is also possible to specify the command to work with the raw data.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="PCA.html#cb236-1" tabindex="-1"></a><span class="fu">det</span>(GRMSmatrix)</span></code></pre></div>
<pre><code>[1] 0.007499909</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="PCA.html#cb238-1" tabindex="-1"></a><span class="co"># det(cor(dfGRMS))#if using the raw data</span></span></code></pre></div>
<p>With a value of 0.0075, our determinant is greater than the 0.00001 requirement. If it were not, then we could identify problematic variables (i.e., those correlating too highly with others; those not correlating sufficiently with others) and re-run the diagnostic statistics.</p>
</div>
<div id="apa-style-summary-so-far" class="section level4 hasAnchor" number="8.5.1.4">
<h4><span class="header-section-number">8.5.1.4</span> APA Style Summary So Far<a href="PCA.html#apa-style-summary-so-far" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was .85, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^{2}(300)=1217.508, p &lt; .001\)</span>, indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0075, supporting the suitability of our data for analysis.</p>
</blockquote>
</div>
</div>
<div id="principal-components-analysis" class="section level3 hasAnchor" number="8.5.2">
<h3><span class="header-section-number">8.5.2</span> Principal Components Analysis<a href="PCA.html#principal-components-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below is a snip from the workflow to remind us where we are in the steps to PCA.</p>
<div class="float">
<img src="images/PCA/NumComponents.png" alt="Image of an excerpt from the workflow" />
<div class="figcaption">Image of an excerpt from the workflow</div>
</div>
<p>We can use the <em>principal()</em> function from the <em>psych</em> package with raw or matrix data.</p>
<p>We start by creating a principal components model that has the same number of components as there are variables in the data. This allows us to inspect the component’s eigenvalues and make decisions about which to extract.</p>
<ul>
<li>Note, this is different than actual <em>factor</em> analysis where you <em>must</em> extract fewer factors than variables (e.g., extracting 18 [an arbitray number] instead of 25).</li>
</ul>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="PCA.html#cb239-1" tabindex="-1"></a><span class="co"># All of the code sets below are functionally identical. They simply</span></span>
<span id="cb239-2"><a href="PCA.html#cb239-2" tabindex="-1"></a><span class="co"># swap out using the df or r-matrix, and whether I specify the number</span></span>
<span id="cb239-3"><a href="PCA.html#cb239-3" tabindex="-1"></a><span class="co"># of factors or write code to instruct R to calculate it.</span></span>
<span id="cb239-4"><a href="PCA.html#cb239-4" tabindex="-1"></a></span>
<span id="cb239-5"><a href="PCA.html#cb239-5" tabindex="-1"></a><span class="co"># pca1 &lt;- psych::principal(GRMSmatrix, nfactors=25, rotate = &#39;none&#39;)</span></span>
<span id="cb239-6"><a href="PCA.html#cb239-6" tabindex="-1"></a><span class="co"># #using the matrix form of the data and specifying the # factors</span></span>
<span id="cb239-7"><a href="PCA.html#cb239-7" tabindex="-1"></a></span>
<span id="cb239-8"><a href="PCA.html#cb239-8" tabindex="-1"></a><span class="co"># pca1 &lt;- psych::principal(GRMSmatrix,</span></span>
<span id="cb239-9"><a href="PCA.html#cb239-9" tabindex="-1"></a><span class="co"># nfactors=length(GRMSmatrix[,1]), rotate = &#39;none&#39;) #using the matrix</span></span>
<span id="cb239-10"><a href="PCA.html#cb239-10" tabindex="-1"></a><span class="co"># form of the data and letting the length function automatically</span></span>
<span id="cb239-11"><a href="PCA.html#cb239-11" tabindex="-1"></a><span class="co"># calculate the # factors as a function of how many columns in the</span></span>
<span id="cb239-12"><a href="PCA.html#cb239-12" tabindex="-1"></a><span class="co"># matrix</span></span>
<span id="cb239-13"><a href="PCA.html#cb239-13" tabindex="-1"></a></span>
<span id="cb239-14"><a href="PCA.html#cb239-14" tabindex="-1"></a><span class="co"># pca1 &lt;- psych::principal(dfGRMS, nfactors=25, rotate=&#39;none&#39;) #using</span></span>
<span id="cb239-15"><a href="PCA.html#cb239-15" tabindex="-1"></a><span class="co"># raw data and specifying # factors</span></span>
<span id="cb239-16"><a href="PCA.html#cb239-16" tabindex="-1"></a></span>
<span id="cb239-17"><a href="PCA.html#cb239-17" tabindex="-1"></a>pca1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(dfGRMS, <span class="at">nfactors =</span> <span class="fu">length</span>(dfGRMS), <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co"># using raw data and letting the length function automatically calculate the # factors as a function of how many columns in the raw data</span></span>
<span id="cb239-18"><a href="PCA.html#cb239-18" tabindex="-1"></a>pca1</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = length(dfGRMS), rotate = &quot;none&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10  PC11  PC12
Obj1  0.52 -0.29  0.06  0.08 -0.23 -0.12 -0.33 -0.15 -0.19 -0.18  0.04  0.09
Obj2  0.55 -0.28  0.00  0.07 -0.11  0.00  0.03  0.09 -0.28 -0.12  0.14 -0.16
Obj3  0.49 -0.26  0.06  0.06 -0.04  0.32  0.06 -0.24 -0.17 -0.13  0.15  0.01
Obj4  0.52 -0.35 -0.09  0.02  0.08  0.09  0.04 -0.15  0.40  0.18 -0.08  0.28
Obj5  0.51 -0.29  0.09 -0.12 -0.08 -0.04  0.14 -0.42  0.11  0.27 -0.23 -0.20
Obj6  0.40 -0.20  0.01  0.47 -0.14  0.44 -0.03  0.22  0.05 -0.12  0.00 -0.24
Obj7  0.56 -0.11 -0.03  0.06  0.02 -0.33 -0.28  0.26  0.07  0.01  0.04 -0.06
Obj8  0.48 -0.40 -0.13 -0.25  0.00 -0.14 -0.26  0.01  0.07  0.14  0.33 -0.05
Obj9  0.40 -0.28  0.16 -0.04 -0.07 -0.11  0.53  0.12  0.33 -0.29  0.00 -0.23
Obj10 0.42 -0.32  0.00  0.23  0.12 -0.35  0.14  0.21 -0.13  0.19 -0.18  0.39
Marg1 0.58  0.31 -0.36 -0.26  0.06 -0.02 -0.13  0.05  0.04 -0.06 -0.01 -0.07
Marg2 0.58  0.38 -0.08 -0.13 -0.21  0.09 -0.02 -0.03 -0.04 -0.13 -0.14  0.14
Marg3 0.51  0.23 -0.18 -0.23  0.11 -0.18  0.36 -0.08 -0.28 -0.10 -0.02 -0.16
Marg4 0.50  0.10 -0.35 -0.07  0.38  0.01 -0.05 -0.28 -0.10 -0.01  0.11  0.02
Marg5 0.56  0.19 -0.19 -0.20 -0.08  0.27 -0.01 -0.03  0.20  0.03 -0.31  0.01
Marg6 0.54 -0.01 -0.19  0.05  0.24  0.09  0.00  0.37 -0.09  0.27 -0.16 -0.17
Marg7 0.41  0.21 -0.27 -0.08 -0.38  0.20  0.16  0.34  0.04  0.01  0.25  0.36
Str1  0.43  0.12  0.45 -0.30 -0.11 -0.19 -0.06  0.11 -0.16 -0.13  0.00 -0.12
Str2  0.40  0.03  0.31  0.15  0.43  0.07  0.15 -0.05 -0.13 -0.37 -0.07  0.37
Str3  0.33  0.22  0.54 -0.08  0.17  0.00 -0.18  0.26  0.15  0.04 -0.22 -0.07
Str4  0.29  0.03  0.48 -0.23  0.31  0.41 -0.14 -0.01 -0.02  0.21  0.26  0.02
Str5  0.34  0.20  0.37  0.10 -0.46 -0.01  0.01 -0.19 -0.23  0.28 -0.16  0.11
Ang1  0.35  0.40  0.27  0.14 -0.04 -0.23  0.22 -0.10  0.30  0.17  0.47  0.04
Ang2  0.33  0.37 -0.10  0.57  0.13 -0.02  0.11 -0.06 -0.18  0.28  0.07 -0.19
Ang3  0.38  0.31 -0.04  0.37  0.00 -0.16 -0.35 -0.21  0.32 -0.29 -0.05 -0.05
       PC13  PC14  PC15  PC16  PC17  PC18  PC19  PC20  PC21  PC22  PC23  PC24
Obj1  -0.30 -0.09  0.04 -0.02  0.24  0.14  0.20 -0.19  0.14 -0.06  0.14 -0.24
Obj2   0.03 -0.28 -0.38  0.25 -0.05  0.21 -0.27 -0.01 -0.01  0.00 -0.22  0.07
Obj3   0.54  0.01  0.22 -0.15 -0.08 -0.03 -0.15  0.01  0.00 -0.03  0.11 -0.18
Obj4  -0.10  0.06 -0.10  0.23  0.18 -0.19 -0.08  0.02 -0.12 -0.17 -0.10 -0.09
Obj5  -0.14 -0.02  0.21  0.15 -0.07  0.00 -0.22 -0.03  0.03  0.18  0.09  0.05
Obj6  -0.12  0.20  0.15 -0.08  0.17 -0.15  0.10 -0.01  0.00  0.18 -0.23  0.10
Obj7   0.25  0.25 -0.26  0.05 -0.01 -0.29 -0.06 -0.23 -0.08  0.11  0.20  0.02
Obj8  -0.09  0.01  0.12 -0.22 -0.11  0.19  0.13  0.19 -0.29  0.07  0.03  0.19
Obj9   0.03  0.01 -0.11 -0.08 -0.04  0.06  0.21  0.07  0.02 -0.26  0.11  0.00
Obj10  0.22 -0.21  0.18 -0.03 -0.04 -0.02  0.20  0.06  0.12  0.07 -0.19  0.03
Marg1  0.00 -0.03 -0.02 -0.09  0.06 -0.09 -0.05  0.26 -0.12 -0.02 -0.20 -0.35
Marg2  0.00 -0.22  0.16 -0.11 -0.02 -0.10 -0.02 -0.33 -0.24 -0.23 -0.07  0.24
Marg3 -0.01 -0.10  0.01 -0.01  0.37 -0.19  0.07  0.08  0.01  0.21  0.10  0.09
Marg4  0.08  0.41 -0.02  0.05  0.06  0.17  0.06 -0.07  0.25 -0.18 -0.12  0.19
Marg5  0.11 -0.02 -0.22  0.00 -0.23  0.22  0.28 -0.14  0.05  0.27 -0.01 -0.08
Marg6 -0.24 -0.08  0.04 -0.30 -0.15 -0.02 -0.22 -0.04  0.21 -0.16  0.13 -0.05
Marg7 -0.06  0.08  0.12  0.25  0.02  0.09 -0.10  0.14  0.12  0.05  0.21  0.06
Str1  -0.10  0.23  0.25  0.27 -0.31 -0.16  0.07  0.02  0.08 -0.05 -0.15 -0.07
Str2  -0.26  0.13 -0.10 -0.10 -0.16  0.04 -0.12  0.05 -0.18  0.15  0.08 -0.01
Str3   0.19  0.04  0.14  0.07  0.35  0.36 -0.11  0.04 -0.07 -0.02  0.03  0.02
Str4   0.00 -0.28 -0.14  0.08  0.02 -0.22  0.21  0.03  0.11 -0.03  0.06  0.06
Str5   0.01  0.22 -0.30 -0.26  0.04 -0.04  0.01  0.24  0.02 -0.09 -0.01  0.07
Ang1  -0.05 -0.03  0.01 -0.20  0.02  0.07 -0.11 -0.22  0.09  0.13 -0.16 -0.10
Ang2  -0.02 -0.01  0.06  0.27 -0.10  0.10  0.20  0.02 -0.26 -0.10  0.13 -0.10
Ang3   0.04 -0.24  0.04  0.03 -0.11 -0.08 -0.05  0.26  0.19  0.00  0.08  0.15
       PC25 h2                   u2  com
Obj1   0.02  1 -0.00000000000000044  8.5
Obj2  -0.02  1 -0.00000000000000178  6.8
Obj3  -0.11  1  0.00000000000000056  6.0
Obj4  -0.26  1  0.00000000000000078  7.4
Obj5   0.26  1  0.00000000000000000  7.9
Obj6   0.05  1  0.00000000000000067  7.8
Obj7   0.11  1 -0.00000000000000022  7.0
Obj8  -0.10  1 -0.00000000000000089  8.8
Obj9   0.12  1  0.00000000000000022  6.9
Obj10  0.09  1  0.00000000000000289 10.6
Marg1  0.25  1  0.00000000000000011  5.8
Marg2  0.07  1  0.00000000000000022  6.2
Marg3 -0.21  1  0.00000000000000000  8.0
Marg4  0.09  1  0.00000000000000044  7.2
Marg5 -0.13  1 -0.00000000000000022  7.2
Marg6 -0.13  1  0.00000000000000078  7.5
Marg7  0.08  1 -0.00000000000000178 10.2
Str1  -0.17  1  0.00000000000000122  9.1
Str2   0.05  1  0.00000000000000133  8.8
Str3  -0.01  1  0.00000000000000000  7.1
Str4   0.13  1  0.00000000000000056  8.4
Str5   0.00  1  0.00000000000000100  9.2
Ang1  -0.04  1  0.00000000000000067  8.7
Ang2  -0.01  1  0.00000000000000022  6.5
Ang3  -0.08  1  0.00000000000000056 10.3

                       PC1  PC2  PC3  PC4  PC5  PC6  PC7  PC8  PC9 PC10 PC11
SS loadings           5.37 1.71 1.54 1.22 1.08 1.04 1.02 0.98 0.95 0.90 0.84
Proportion Var        0.21 0.07 0.06 0.05 0.04 0.04 0.04 0.04 0.04 0.04 0.03
Cumulative Var        0.21 0.28 0.34 0.39 0.44 0.48 0.52 0.56 0.60 0.63 0.67
Proportion Explained  0.21 0.07 0.06 0.05 0.04 0.04 0.04 0.04 0.04 0.04 0.03
Cumulative Proportion 0.21 0.28 0.34 0.39 0.44 0.48 0.52 0.56 0.60 0.63 0.67
                      PC12 PC13 PC14 PC15 PC16 PC17 PC18 PC19 PC20 PC21 PC22
SS loadings           0.83 0.75 0.73 0.69 0.68 0.64 0.61 0.58 0.55 0.51 0.48
Proportion Var        0.03 0.03 0.03 0.03 0.03 0.03 0.02 0.02 0.02 0.02 0.02
Cumulative Var        0.70 0.73 0.76 0.79 0.81 0.84 0.86 0.89 0.91 0.93 0.95
Proportion Explained  0.03 0.03 0.03 0.03 0.03 0.03 0.02 0.02 0.02 0.02 0.02
Cumulative Proportion 0.70 0.73 0.76 0.79 0.81 0.84 0.86 0.89 0.91 0.93 0.95
                      PC23 PC24 PC25
SS loadings           0.45 0.45 0.41
Proportion Var        0.02 0.02 0.02
Cumulative Var        0.97 0.98 1.00
Proportion Explained  0.02 0.02 0.02
Cumulative Proportion 0.97 0.98 1.00

Mean item complexity =  7.9
Test of the hypothesis that 25 components are sufficient.

The root mean square of the residuals (RMSR) is  0 
 with the empirical chi square  0  with prob &lt;  NA 

Fit based upon off diagonal values = 1</code></pre>
<p>The total variance for a particular variable will have two components: some of it will be share with other variables (common variance, h2) and some of it will be specific to that measure (unique variance, u2). Random variance is also specific to one item, but not reliably so.</p>
<p>We can examine this most easily by examining the matrix (second screen).</p>
<p>The columns PC1 thru PC25 are the (uninteresting at this point) unrotated loadings. PC stands for “principal component.” Although these don’t align with the specific items, at this point in the procedure, there are as many components as variables.</p>
<p><strong>Communalities</strong> are represented as <span class="math inline">\(h^2\)</span>. These are the proportions of common variance present in the variables. A variable that has no specific (or random) variance would have a communality of 1.0. If a variable shares none of its variance with any other variable its communality would be 0.0.</p>
<p>Because we extracted the same number components as variables, they all equal 1.0. That is we have explained all the variance in each variable. When we specify fewer components, the value of the communalities will decrease.</p>
<p>**Uniquenesses* are represented as <span class="math inline">\(u2\)</span>. These are the amount of unique variance for each variable. They are calculated as <span class="math inline">\(1 - h^2\)</span> (or 1 minus the communality). Technically (at this point in the analysis where we have an equal number of components as items), they should all be zero, but the <em>psych</em> package is very “quantsy” and decimals are reported to the 15th and 16th decimal places! (hence the u2 for Q1 is -0.0000000000000006661338).</p>
<p>The final column, <em>com</em>, represents <em>item complexity.</em> This is an indication of how well an item reflects a single construct. If it is 1.0 then the item loads only on one component, if it is 2.0, it loads evenly on two components, and so forth. For now, we can ignore this. <em>I mostly wanted to reassure you that “com” is not “communality”; h2 is communality</em>.</p>
<p>Let’s switch to the first screen of output.</p>
<p><strong>Eigenvalues</strong> are displayed in the row called <em>SS loadings</em> (i.e., the sum of squared loadings). They represent the variance explained by the particular linear component. PC1 explains 5.37 units of variance (out of a possible 25, the total of components). As a proportion, this is 5.37/25 = 0.21 (reported in the <em>Proportion Var</em> row).</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="PCA.html#cb241-1" tabindex="-1"></a><span class="fl">5.37</span><span class="sc">/</span><span class="dv">25</span></span></code></pre></div>
<pre><code>[1] 0.2148</code></pre>
<p>Note:</p>
<ul>
<li><em>Cumulative Var</em> is helpful in determining how many components we would like to retain to balance parsimony (where the goal is frequently “as few as possible”) with the amount of variance we want to explain.</li>
<li>The eigenvalues are in descending order. If we were to use the <em>eigenvalue &gt; 1.0</em> (i.e., “Kaiser’s”) criteria to determine how many components to extract, we would select 7. Joliffe’s critera was 0.7 (thus, we would select 14 components). Eigenvalues are only one criteria, let’s look at he scree plot.</li>
</ul>
<p><em>Scree plot</em>: We can gain another view of how many components to extract by creating a scree plot.</p>
<p>Eigenvalues are stored in the pca1 object’s variable, “values”. We can see all the values captured by this object with the <em>names()</em> function:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="PCA.html#cb243-1" tabindex="-1"></a><span class="fu">names</span>(pca1)</span></code></pre></div>
<pre><code> [1] &quot;values&quot;       &quot;rotation&quot;     &quot;n.obs&quot;        &quot;communality&quot;  &quot;loadings&quot;    
 [6] &quot;fit&quot;          &quot;fit.off&quot;      &quot;fn&quot;           &quot;Call&quot;         &quot;uniquenesses&quot;
[11] &quot;complexity&quot;   &quot;valid&quot;        &quot;chi&quot;          &quot;EPVAL&quot;        &quot;R2&quot;          
[16] &quot;objective&quot;    &quot;residual&quot;     &quot;rms&quot;          &quot;factors&quot;      &quot;dof&quot;         
[21] &quot;null.dof&quot;     &quot;null.model&quot;   &quot;criteria&quot;     &quot;STATISTIC&quot;    &quot;PVAL&quot;        
[26] &quot;weights&quot;      &quot;r.scores&quot;     &quot;Vaccounted&quot;   &quot;Structure&quot;    &quot;scores&quot;      </code></pre>
<p>Plotting the eigen<em>values</em> produces a scree plot. We can use this to further guage the number of factors we should extract.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="PCA.html#cb245-1" tabindex="-1"></a><span class="fu">plot</span>(pca1<span class="sc">$</span>values, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>)  <span class="co">#type = &#39;b&#39; gives us &#39;both&#39; lines and points;  type = &#39;l&#39; gives lines and is relatively worthless</span></span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We look for the point of <em>inflexion</em>. That is, where the baseline levels out into a plateau. It seems to me that there is only one clear component above the plateau. However, we see that components #5 and 5 flatten out, and then there is another drop. So it could be 1, 2, or 4.</p>
</div>
<div id="specifying-the-number-of-components" class="section level3 hasAnchor" number="8.5.3">
<h3><span class="header-section-number">8.5.3</span> Specifying the Number of Components<a href="PCA.html#specifying-the-number-of-components" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below is a snip from the workflow to remind us where we are in the steps to PCA.</p>
<div class="float">
<img src="images/PCA/SpecifyCompNum.png" alt="Image of an excerpt from the workflow" />
<div class="figcaption">Image of an excerpt from the workflow</div>
</div>
<p>Having determined the number of components, we re-run the analysis with this specification. Especially when researchers may not have a clear theoretical structure that guides the process, researchers may do this iteratively with varying numbers of factors. Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">J. A. Lewis &amp; Neville, 2015</a>)</span> examined solutions with 2, 3, 4, and 5 factors. Further, they used a parallel <em>factor</em> analysis, whereas we used a principal components analysis).</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="PCA.html#cb246-1" tabindex="-1"></a><span class="co"># pca2 &lt;- psych::principal(GRMSmatrix, nfactors=4, rotate=&#39;none&#39;)</span></span>
<span id="cb246-2"><a href="PCA.html#cb246-2" tabindex="-1"></a>pca2 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(dfGRMS, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co">#can copy prior script, but change nfactors and object name</span></span>
<span id="cb246-3"><a href="PCA.html#cb246-3" tabindex="-1"></a>pca2</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = 4, rotate = &quot;none&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
       PC1   PC2   PC3   PC4   h2   u2 com
Obj1  0.52 -0.29  0.06  0.08 0.37 0.63 1.7
Obj2  0.55 -0.28  0.00  0.07 0.39 0.61 1.5
Obj3  0.49 -0.26  0.06  0.06 0.32 0.68 1.6
Obj4  0.52 -0.35 -0.09  0.02 0.40 0.60 1.8
Obj5  0.51 -0.29  0.09 -0.12 0.36 0.64 1.8
Obj6  0.40 -0.20  0.01  0.47 0.42 0.58 2.3
Obj7  0.56 -0.11 -0.03  0.06 0.32 0.68 1.1
Obj8  0.48 -0.40 -0.13 -0.25 0.47 0.53 2.6
Obj9  0.40 -0.28  0.16 -0.04 0.27 0.73 2.2
Obj10 0.42 -0.32  0.00  0.23 0.33 0.67 2.5
Marg1 0.58  0.31 -0.36 -0.26 0.63 0.37 2.7
Marg2 0.58  0.38 -0.08 -0.13 0.50 0.50 1.9
Marg3 0.51  0.23 -0.18 -0.23 0.40 0.60 2.1
Marg4 0.50  0.10 -0.35 -0.07 0.39 0.61 2.0
Marg5 0.56  0.19 -0.19 -0.20 0.43 0.57 1.8
Marg6 0.54 -0.01 -0.19  0.05 0.33 0.67 1.2
Marg7 0.41  0.21 -0.27 -0.08 0.29 0.71 2.4
Str1  0.43  0.12  0.45 -0.30 0.50 0.50 2.9
Str2  0.40  0.03  0.31  0.15 0.28 0.72 2.2
Str3  0.33  0.22  0.54 -0.08 0.45 0.55 2.1
Str4  0.29  0.03  0.48 -0.23 0.37 0.63 2.1
Str5  0.34  0.20  0.37  0.10 0.30 0.70 2.7
Ang1  0.35  0.40  0.27  0.14 0.37 0.63 3.0
Ang2  0.33  0.37 -0.10  0.57 0.57 0.43 2.5
Ang3  0.38  0.31 -0.04  0.37 0.38 0.62 2.9

                       PC1  PC2  PC3  PC4
SS loadings           5.37 1.71 1.54 1.22
Proportion Var        0.21 0.07 0.06 0.05
Cumulative Var        0.21 0.28 0.34 0.39
Proportion Explained  0.55 0.17 0.16 0.12
Cumulative Proportion 0.55 0.72 0.88 1.00

Mean item complexity =  2.1
Test of the hypothesis that 4 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  639.9  with prob &lt;  0.00000000000000000000000000000000000000000000056 

Fit based upon off diagonal values = 0.89</code></pre>
<p>Our eigenvalues/SS loadings remain the same. With 4 components, we explain 39% of the variance (we can see this in the “Cumulative Var” row.</p>
<p><em>Communality</em> is the proportion of common variance within a variable. Principal components analysis assumes that all variance is common. Before extraction, all variance was set at 1.0, therefore, changing from 25 to 4 components will change this value (<span class="math inline">\(h2\)</span>) as well as its associated <em>uniqueness</em> (<span class="math inline">\(u2\)</span>), which is calculated as “1.0 minus the communality.”</p>
<p>The <em>communalities</em> (<span class="math inline">\(h2\)</span>) and <em>uniquenesses</em> (<span class="math inline">\(u2\)</span>) have changed.</p>
<p>Now we see that 37% of the variance associate with Obj1 is common/shared (the <span class="math inline">\(h2\)</span> value).</p>
<p>Recall that we could represent this scale with all 25 items as components, but we want a more <em>parsimonious</em> explanation. By respecifying a smaller number of components, we lose some information. That is, the retained components (now 4) cannot explain all of the variance present in the data (as we saw, it explains about 39%, cumulatively). The amount of variance explained in each variable is represented by the communalities after extraction.</p>
<p>We can examine the communalities through the lens of Kaiser’s criterion (the eigenvalue &gt; 1 criteria) to see if we think that “four” was a good number of components to extract.</p>
<p>Kaiser’s criterion is believed to be accurate if:</p>
<ul>
<li>when there are fewer than 30 variables (we had 25) and, after extraction, the communalities are greater than .70
<ul>
<li>looking at our data, none are &gt; .70, so, this does not support extracting four components</li>
</ul></li>
<li>when the sample size is greater than 250 (ours was 259) and the average communality is &gt; .60
<ul>
<li>we can extract the communalities from our object and calculate the mean the average communality</li>
</ul></li>
</ul>
<p>Using the <em>names()</em> function again, we see that “communality” is available. Thus, we can easily calculate their mean. To get this value let’s first examine the possible contents of the object we created from this PCA analysis by asking for its names.</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="PCA.html#cb248-1" tabindex="-1"></a><span class="fu">names</span>(pca2)</span></code></pre></div>
<pre><code> [1] &quot;values&quot;       &quot;rotation&quot;     &quot;n.obs&quot;        &quot;communality&quot;  &quot;loadings&quot;    
 [6] &quot;fit&quot;          &quot;fit.off&quot;      &quot;fn&quot;           &quot;Call&quot;         &quot;uniquenesses&quot;
[11] &quot;complexity&quot;   &quot;valid&quot;        &quot;chi&quot;          &quot;EPVAL&quot;        &quot;R2&quot;          
[16] &quot;objective&quot;    &quot;residual&quot;     &quot;rms&quot;          &quot;factors&quot;      &quot;dof&quot;         
[21] &quot;null.dof&quot;     &quot;null.model&quot;   &quot;criteria&quot;     &quot;STATISTIC&quot;    &quot;PVAL&quot;        
[26] &quot;weights&quot;      &quot;r.scores&quot;     &quot;Vaccounted&quot;   &quot;Structure&quot;    &quot;scores&quot;      </code></pre>
<p>We see that it includes communalities. Thus, we can easily calculate their mean.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="PCA.html#cb250-1" tabindex="-1"></a><span class="fu">mean</span>(pca2<span class="sc">$</span>communality)</span></code></pre></div>
<pre><code>[1] 0.3932201</code></pre>
<p>We see that the average communality is 0.39. These two criteria would suggest that we may not have the best solution. That said (in our defense):</p>
<ul>
<li>We used the scree plot as a guide and there was support for four dimensions.</li>
<li>We have an adequate sample size and that was supported with the KMO.</li>
<li>Are the number of components consistent with theory? We have not yet inspected the component loadings. This will provide us with more information.</li>
</ul>
<p>We could do several things:</p>
<ul>
<li>re-run with a different number of components (recall Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> ran models with 2, 3, 4, and 5 factors)</li>
<li>conduct more diagnostics
<ul>
<li>reproduced correlation matrix</li>
<li>the difference between the reproduced correlation matrix and the correlation matrix in the data</li>
</ul></li>
</ul>
<p>The <em>factor.model()</em> function in <em>psych</em> produces the <em>reproduced correlation matrix</em> by using the <em>loadings</em> from our extracted object. Conceptually, this matrix is the correlations that should be produced if we did not have the raw data but we only had the component loadings. We could do fancy matrix algebra and produce these.</p>
<p>The questions, though, is: How close did we get? How different is the <em>reproduced correlation matrix</em> from <em>GRMSmatrix</em> – the <span class="math inline">\(R\)</span>-matrix produced from our raw data.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="PCA.html#cb252-1" tabindex="-1"></a><span class="co"># produces the reproduced correlation matrix</span></span>
<span id="cb252-2"><a href="PCA.html#cb252-2" tabindex="-1"></a><span class="fu">round</span>(psych<span class="sc">::</span><span class="fu">factor.model</span>(pca2<span class="sc">$</span>loadings), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>       Obj1  Obj2  Obj3  Obj4   Obj5  Obj6  Obj7   Obj8   Obj9 Obj10 Marg1
Obj1  0.368 0.375 0.343 0.372  0.346 0.308 0.324  0.340  0.298 0.329 0.171
Obj2  0.375 0.387 0.350 0.388  0.352 0.313 0.341  0.358  0.297 0.335 0.217
Obj3  0.343 0.350 0.321 0.346  0.326 0.281 0.305  0.320  0.280 0.303 0.169
Obj4  0.372 0.388 0.346 0.404  0.356 0.291 0.333  0.397  0.292 0.335 0.224
Obj5  0.346 0.352 0.326 0.356  0.365 0.208 0.303  0.377  0.305 0.277 0.205
Obj6  0.308 0.313 0.281 0.291  0.208 0.424 0.274  0.157  0.202 0.338 0.044
Obj7  0.324 0.341 0.305 0.333  0.303 0.274 0.325  0.298  0.247 0.280 0.285
Obj8  0.340 0.358 0.320 0.397  0.377 0.157 0.298  0.469  0.294 0.273 0.264
Obj9  0.298 0.297 0.280 0.292  0.305 0.202 0.247  0.294  0.268 0.247 0.101
Obj10 0.329 0.335 0.303 0.335  0.277 0.338 0.280  0.273  0.247 0.326 0.085
Marg1 0.171 0.217 0.169 0.224  0.205 0.044 0.285  0.264  0.101 0.085 0.633
Marg2 0.177 0.207 0.175 0.179  0.195 0.093 0.276  0.170  0.122 0.092 0.519
Marg3 0.171 0.203 0.169 0.201  0.206 0.047 0.250  0.234  0.124 0.088 0.493
Marg4 0.203 0.242 0.194 0.256  0.199 0.143 0.272  0.259  0.118 0.159 0.465
Marg5 0.211 0.244 0.205 0.242  0.238 0.090 0.284  0.268  0.152 0.129 0.505
Marg6 0.277 0.305 0.261 0.304  0.255 0.238 0.310  0.275  0.189 0.238 0.368
Marg7 0.130 0.163 0.127 0.165  0.133 0.081 0.207  0.166  0.068 0.086 0.418
Str1  0.189 0.180 0.188 0.133  0.260 0.009 0.191  0.172  0.225 0.070 0.203
Str2  0.229 0.222 0.216 0.174  0.204 0.227 0.218  0.103  0.197 0.189 0.095
Str3  0.130 0.113 0.131 0.044  0.162 0.052 0.135  0.020  0.162 0.045 0.088
Str4  0.150 0.132 0.148 0.089  0.207 0.006 0.125  0.119  0.194 0.057 0.061
Str5  0.148 0.140 0.144 0.078  0.136 0.148 0.162  0.010  0.138 0.100 0.101
Ang1  0.088 0.089 0.089 0.020  0.068 0.123 0.148 -0.065  0.066 0.045 0.197
Ang2  0.101 0.119 0.092 0.065 -0.017 0.321 0.180 -0.119 -0.009 0.145 0.196
Ang3  0.138 0.154 0.129 0.107  0.059 0.265 0.205 -0.027  0.050 0.145 0.238
      Marg2 Marg3  Marg4 Marg5 Marg6 Marg7   Str1  Str2  Str3   Str4  Str5
Obj1  0.177 0.171  0.203 0.211 0.277 0.130  0.189 0.229 0.130  0.150 0.148
Obj2  0.207 0.203  0.242 0.244 0.305 0.163  0.180 0.222 0.113  0.132 0.140
Obj3  0.175 0.169  0.194 0.205 0.261 0.127  0.188 0.216 0.131  0.148 0.144
Obj4  0.179 0.201  0.256 0.242 0.304 0.165  0.133 0.174 0.044  0.089 0.078
Obj5  0.195 0.206  0.199 0.238 0.255 0.133  0.260 0.204 0.162  0.207 0.136
Obj6  0.093 0.047  0.143 0.090 0.238 0.081  0.009 0.227 0.052  0.006 0.148
Obj7  0.276 0.250  0.272 0.284 0.310 0.207  0.191 0.218 0.135  0.125 0.162
Obj8  0.170 0.234  0.259 0.268 0.275 0.166  0.172 0.103 0.020  0.119 0.010
Obj9  0.122 0.124  0.118 0.152 0.189 0.068  0.225 0.197 0.162  0.194 0.138
Obj10 0.092 0.088  0.159 0.129 0.238 0.086  0.070 0.189 0.045  0.057 0.100
Marg1 0.519 0.493  0.465 0.505 0.368 0.418  0.203 0.095 0.088  0.061 0.101
Marg2 0.501 0.426  0.365 0.437 0.321 0.347  0.295 0.198 0.237  0.165 0.226
Marg3 0.426 0.398  0.356 0.409 0.298 0.321  0.234 0.122 0.139  0.118 0.128
Marg4 0.365 0.356  0.386 0.378 0.331 0.323  0.085 0.084 0.001 -0.011 0.052
Marg5 0.437 0.409  0.378 0.425 0.328 0.334  0.237 0.142 0.139  0.119 0.136
Marg6 0.321 0.298  0.331 0.328 0.329 0.265  0.132 0.166 0.072  0.054 0.119
Marg7 0.347 0.321  0.323 0.334 0.265 0.286  0.103 0.076 0.043  0.012 0.074
Str1  0.295 0.234  0.085 0.237 0.132 0.103  0.495 0.269 0.435  0.413 0.303
Str2  0.198 0.122  0.084 0.142 0.166 0.076  0.269 0.276 0.289  0.229 0.269
Str3  0.237 0.139  0.001 0.139 0.072 0.043  0.435 0.289 0.449  0.377 0.341
Str4  0.165 0.118 -0.011 0.119 0.054 0.012  0.413 0.229 0.377  0.366 0.255
Str5  0.226 0.128  0.052 0.136 0.119 0.074  0.303 0.269 0.341  0.255 0.298
Ang1  0.311 0.188  0.110 0.191 0.141 0.143  0.277 0.253 0.333  0.208 0.309
Ang2  0.262 0.138  0.198 0.157 0.219 0.192 -0.034 0.195 0.085 -0.074 0.205
Ang3  0.293 0.187  0.211 0.206 0.230 0.201  0.073 0.207 0.143  0.016 0.216
        Ang1   Ang2   Ang3
Obj1   0.088  0.101  0.138
Obj2   0.089  0.119  0.154
Obj3   0.089  0.092  0.129
Obj4   0.020  0.065  0.107
Obj5   0.068 -0.017  0.059
Obj6   0.123  0.321  0.265
Obj7   0.148  0.180  0.205
Obj8  -0.065 -0.119 -0.027
Obj9   0.066 -0.009  0.050
Obj10  0.045  0.145  0.145
Marg1  0.197  0.196  0.238
Marg2  0.311  0.262  0.293
Marg3  0.188  0.138  0.187
Marg4  0.110  0.198  0.211
Marg5  0.191  0.157  0.206
Marg6  0.141  0.219  0.230
Marg7  0.143  0.192  0.201
Str1   0.277 -0.034  0.073
Str2   0.253  0.195  0.207
Str3   0.333  0.085  0.143
Str4   0.208 -0.074  0.016
Str5   0.309  0.205  0.216
Ang1   0.372  0.312  0.299
Ang2   0.312  0.575  0.454
Ang3   0.299  0.454  0.383</code></pre>
<p>We’re not really interested in this matrix. We just need it to compare it to the <em>GRMSmatrix</em> to produce the residuals. We do that next.</p>
<p><strong>Residuals</strong> are the difference between the reproduced (i.e., those created from our component loadings) and <span class="math inline">\(R\)</span>-matrix produced by the raw data.</p>
<p>If we look at the <span class="math inline">\(r_{_{Obj1Obj2}}\)</span> in our original correlation matrix (theoretically from the raw data [although we simulated data]), the value is 0.35 The reproduced correlation that we just calculated for this pair is 0.375. The diffference is -0.025.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="PCA.html#cb254-1" tabindex="-1"></a><span class="fl">0.35</span> <span class="sc">-</span> <span class="fl">0.375</span></span></code></pre></div>
<pre><code>[1] -0.025</code></pre>
<p>By using the <em>factor.residuals()</em> function R will calculate the residuals for each pair.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="PCA.html#cb256-1" tabindex="-1"></a><span class="fu">round</span>(psych<span class="sc">::</span><span class="fu">factor.residuals</span>(GRMSmatrix, pca2<span class="sc">$</span>loadings), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>        Obj1   Obj2   Obj3   Obj4   Obj5   Obj6   Obj7   Obj8   Obj9  Obj10
Obj1   0.632 -0.020 -0.093 -0.101 -0.063 -0.057 -0.044  0.006 -0.145 -0.088
Obj2  -0.020  0.613 -0.038 -0.140 -0.085 -0.079 -0.029 -0.076 -0.035 -0.090
Obj3  -0.093 -0.038  0.679 -0.105 -0.043 -0.002 -0.103 -0.072 -0.070 -0.088
Obj4  -0.101 -0.140 -0.105  0.596  0.031 -0.060 -0.048 -0.100 -0.036 -0.055
Obj5  -0.063 -0.085 -0.043  0.031  0.635 -0.055 -0.126 -0.086 -0.053 -0.072
Obj6  -0.057 -0.079 -0.002 -0.060 -0.055  0.576 -0.075 -0.015  0.004 -0.217
Obj7  -0.044 -0.029 -0.103 -0.048 -0.126 -0.075  0.675  0.009 -0.054  0.004
Obj8   0.006 -0.076 -0.072 -0.100 -0.086 -0.015  0.009  0.531 -0.101 -0.043
Obj9  -0.145 -0.035 -0.070 -0.036 -0.053  0.004 -0.054 -0.101  0.732 -0.049
Obj10 -0.088 -0.090 -0.088 -0.055 -0.072 -0.217  0.004 -0.043 -0.049  0.674
Marg1  0.014 -0.002  0.000 -0.005 -0.039  0.058  0.011  0.004  0.000  0.009
Marg2  0.068  0.000  0.055 -0.002  0.002  0.045 -0.061 -0.034 -0.004  0.031
Marg3 -0.002  0.042  0.005 -0.064  0.020  0.005 -0.052 -0.095  0.091  0.077
Marg4 -0.015 -0.061  0.048  0.000 -0.002 -0.041 -0.021 -0.020 -0.051 -0.038
Marg5 -0.039 -0.025  0.007  0.026  0.014  0.072 -0.053 -0.081  0.037 -0.020
Marg6 -0.099 -0.036 -0.102 -0.076 -0.030  0.024 -0.025 -0.014 -0.039  0.018
Marg7 -0.001  0.028  0.015  0.029 -0.076  0.093 -0.052 -0.025  0.037  0.023
Str1   0.026  0.005 -0.046 -0.071 -0.029  0.057  0.056 -0.006 -0.034  0.031
Str2  -0.041 -0.038 -0.027  0.016 -0.088 -0.075 -0.083 -0.040 -0.014 -0.002
Str3  -0.033 -0.025 -0.040  0.036 -0.052  0.042  0.052  0.026 -0.046  0.053
Str4  -0.056  0.008  0.036  0.061 -0.087  0.077 -0.055  0.009 -0.141 -0.034
Str5   0.049  0.006  0.009  0.002  0.054 -0.035 -0.013  0.027 -0.072 -0.009
Ang1  -0.025 -0.021 -0.016  0.072  0.050 -0.083  0.003  0.138  0.103  0.018
Ang2  -0.043  0.026 -0.009 -0.005  0.104 -0.124 -0.050  0.093  0.005 -0.007
Ang3   0.068 -0.027 -0.017  0.033  0.046 -0.110  0.021  0.092  0.012 -0.062
       Marg1  Marg2  Marg3  Marg4  Marg5  Marg6  Marg7   Str1   Str2   Str3
Obj1   0.014  0.068 -0.002 -0.015 -0.039 -0.099 -0.001  0.026 -0.041 -0.033
Obj2  -0.002  0.000  0.042 -0.061 -0.025 -0.036  0.028  0.005 -0.038 -0.025
Obj3   0.000  0.055  0.005  0.048  0.007 -0.102  0.015 -0.046 -0.027 -0.040
Obj4  -0.005 -0.002 -0.064  0.000  0.026 -0.076  0.029 -0.071  0.016  0.036
Obj5  -0.039  0.002  0.020 -0.002  0.014 -0.030 -0.076 -0.029 -0.088 -0.052
Obj6   0.058  0.045  0.005 -0.041  0.072  0.024  0.093  0.057 -0.075  0.042
Obj7   0.011 -0.061 -0.052 -0.021 -0.053 -0.025 -0.052  0.056 -0.083  0.052
Obj8   0.004 -0.034 -0.095 -0.020 -0.081 -0.014 -0.025 -0.006 -0.040  0.026
Obj9   0.000 -0.004  0.091 -0.051  0.037 -0.039  0.037 -0.034 -0.014 -0.046
Obj10  0.009  0.031  0.077 -0.038 -0.020  0.018  0.023  0.031 -0.002  0.053
Marg1  0.367 -0.094 -0.086 -0.089 -0.098 -0.020 -0.110 -0.012  0.026  0.043
Marg2 -0.094  0.499 -0.078 -0.134 -0.034 -0.053 -0.022 -0.041 -0.016 -0.057
Marg3 -0.086 -0.078  0.602 -0.033 -0.158 -0.044 -0.117 -0.031  0.051 -0.043
Marg4 -0.089 -0.134 -0.033  0.614 -0.079 -0.073 -0.159  0.015  0.128  0.048
Marg5 -0.098 -0.034 -0.158 -0.079  0.575 -0.038 -0.052 -0.079 -0.009  0.019
Marg6 -0.020 -0.053 -0.044 -0.073 -0.038  0.671 -0.066 -0.003  0.018  0.075
Marg7 -0.110 -0.022 -0.117 -0.159 -0.052 -0.066  0.714  0.037 -0.024 -0.002
Str1  -0.012 -0.041 -0.031  0.015 -0.079 -0.003  0.037  0.505 -0.054 -0.133
Str2   0.026 -0.016  0.051  0.128 -0.009  0.018 -0.024 -0.054  0.724 -0.091
Str3   0.043 -0.057 -0.043  0.048  0.019  0.075 -0.002 -0.133 -0.091  0.551
Str4   0.023 -0.048 -0.039  0.073  0.021  0.080  0.005 -0.187 -0.026 -0.109
Str5  -0.001  0.003 -0.005 -0.020  0.040 -0.035  0.049 -0.073 -0.148 -0.161
Ang1  -0.034 -0.079 -0.006  0.008 -0.076 -0.036  0.028 -0.096 -0.093 -0.134
Ang2  -0.026 -0.077  0.054  0.024 -0.015 -0.006 -0.059  0.084 -0.074 -0.011
Ang3   0.041 -0.015 -0.077 -0.038  0.003 -0.114 -0.115  0.029 -0.052  0.004
        Str4   Str5   Ang1   Ang2   Ang3
Obj1  -0.056  0.049 -0.025 -0.043  0.068
Obj2   0.008  0.006 -0.021  0.026 -0.027
Obj3   0.036  0.009 -0.016 -0.009 -0.017
Obj4   0.061  0.002  0.072 -0.005  0.033
Obj5  -0.087  0.054  0.050  0.104  0.046
Obj6   0.077 -0.035 -0.083 -0.124 -0.110
Obj7  -0.055 -0.013  0.003 -0.050  0.021
Obj8   0.009  0.027  0.138  0.093  0.092
Obj9  -0.141 -0.072  0.103  0.005  0.012
Obj10 -0.034 -0.009  0.018 -0.007 -0.062
Marg1  0.023 -0.001 -0.034 -0.026  0.041
Marg2 -0.048  0.003 -0.079 -0.077 -0.015
Marg3 -0.039 -0.005 -0.006  0.054 -0.077
Marg4  0.073 -0.020  0.008  0.024 -0.038
Marg5  0.021  0.040 -0.076 -0.015  0.003
Marg6  0.080 -0.035 -0.036 -0.006 -0.114
Marg7  0.005  0.049  0.028 -0.059 -0.115
Str1  -0.187 -0.073 -0.096  0.084  0.029
Str2  -0.026 -0.148 -0.093 -0.074 -0.052
Str3  -0.109 -0.161 -0.134 -0.011  0.004
Str4   0.634 -0.136 -0.054  0.105  0.006
Str5  -0.136  0.702 -0.085 -0.051 -0.110
Ang1  -0.054 -0.085  0.628 -0.072 -0.067
Ang2   0.105 -0.051 -0.072  0.425 -0.204
Ang3   0.006 -0.110 -0.067 -0.204  0.617</code></pre>
<p>Their calculated difference (-0.20) is quite close to our hand calculation (-0.25).
There are several strategies to evaluate this matrix:</p>
<ul>
<li>See how large the residuals are compared to the original correlations.
<ul>
<li>The worst possible model would occur if we extracted no components and would be the size of the original correlations.</li>
<li>If the correlations were small to start with, we expect small residuals.</li>
<li>If the correlations were large to start with, the residuals will be relatively larger (this is not terribly problematic).</li>
</ul></li>
<li>Comparing residuals requires squaring them first (because residuals can be both positive and negative).
<ul>
<li>The sum of the squared residuals divided by the sum of the squared correlations is an estimate of model fit.Subtracting this from 1.0 means that it ranges from 0 to 1. Values &gt; .95 are an indication of good fit.</li>
</ul></li>
</ul>
<p>Analyzing the residuals means we need to extract only the upper right of the triangle of the matrix into an object. We can do this in steps.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="PCA.html#cb258-1" tabindex="-1"></a><span class="co"># first extract the residuals</span></span>
<span id="cb258-2"><a href="PCA.html#cb258-2" tabindex="-1"></a>pca2_resids <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">factor.residuals</span>(GRMSmatrix, pca2<span class="sc">$</span>loadings)</span>
<span id="cb258-3"><a href="PCA.html#cb258-3" tabindex="-1"></a><span class="co"># the object has the residuals in a single column</span></span>
<span id="cb258-4"><a href="PCA.html#cb258-4" tabindex="-1"></a>pca2_resids <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(pca2_resids[<span class="fu">upper.tri</span>(pca2_resids)])</span>
<span id="cb258-5"><a href="PCA.html#cb258-5" tabindex="-1"></a><span class="co"># display the first 6 rows of the residuals</span></span>
<span id="cb258-6"><a href="PCA.html#cb258-6" tabindex="-1"></a><span class="fu">head</span>(pca2_resids)</span></code></pre></div>
<pre><code>            [,1]
[1,] -0.02024211
[2,] -0.09293107
[3,] -0.03803285
[4,] -0.10123779
[5,] -0.14040791
[6,] -0.10510587</code></pre>
<p>One criteria of residual analysis is to see how many residuals there are that are greater than an absolute value of 0.05. The result will be a single column with TRUE if it is &gt; |0.05| and false if it is smaller. The sum function will tell us how many TRUE responses are in the matrix. Further, we can write script to obtain the proportion of total number of residuals.</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="PCA.html#cb260-1" tabindex="-1"></a>large.resid <span class="ot">&lt;-</span> <span class="fu">abs</span>(pca2_resids) <span class="sc">&gt;</span> <span class="fl">0.05</span></span>
<span id="cb260-2"><a href="PCA.html#cb260-2" tabindex="-1"></a><span class="co"># large.resid</span></span>
<span id="cb260-3"><a href="PCA.html#cb260-3" tabindex="-1"></a><span class="fu">sum</span>(large.resid)</span></code></pre></div>
<pre><code>[1] 129</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="PCA.html#cb262-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sum</span>(large.resid)<span class="sc">/</span><span class="fu">nrow</span>(pca2_resids), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>[1] 0.43</code></pre>
<p>We learn that there are 129 residuals greater than the absolute value of 0.05. This represents 43% of the total number of residuals.</p>
<p>There are no hard rules about what proportion of residuals can be greater than 0.05. A common practice is to stay below 50% <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span>.</p>
<p>Another approach to analyzing residuals is to look at their mean. Because of the +/- valences, we need to square them (to eliminate the negative), take the average, then take the square root.</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="PCA.html#cb264-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="fu">mean</span>(pca2_resids<span class="sc">^</span><span class="dv">2</span>)), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>[1] 0.064</code></pre>
<p>While there are no clear guidelines to interpret these, one recommendation is to consider extracting more components if the value is higher than 0.08 <span class="citation">(<a href="#ref-field_discovering_2012">Field, 2012</a>)</span>. Our value of 0.064 is &lt; 0.08.</p>
<p>Finally, we expect our residuals to be normally distributed. A histogram can help us inspect the distribution.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="PCA.html#cb266-1" tabindex="-1"></a><span class="fu">hist</span>(pca2_resids)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-24-1.png" width="672" />
This looks reasonably normal to me and I do not see an indication of outliers.</p>
<div id="quick-recap-of-how-to-evaluate-the-of-components-we-extracted" class="section level4 hasAnchor" number="8.5.3.1">
<h4><span class="header-section-number">8.5.3.1</span> Quick recap of how to evaluate the # of components we extracted<a href="PCA.html#quick-recap-of-how-to-evaluate-the-of-components-we-extracted" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>If fewer than 30 variables, the eigenvalue &gt; 1 (Kaiser’s) critera is fine, so long as communalities are all &gt; .70.</li>
<li>If sample size &gt; 250 and the average communalities are .6 or greater, this is acceptable.</li>
<li>When <em>N</em> &gt; 200, the scree plot can be used.</li>
<li>Regarding residuals:
<ul>
<li>Fewer than 50% should have absolute values &gt; 0.05.</li>
<li>Model fit should be &gt; 0.90.</li>
</ul></li>
</ul>
</div>
</div>
<div id="component-rotation" class="section level3 hasAnchor" number="8.5.4">
<h3><span class="header-section-number">8.5.4</span> Component Rotation<a href="PCA.html#component-rotation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below is a snip from the workflow to remind us where we are in the steps to PCA.</p>
<div class="float">
<img src="images/PCA/rotation.png" alt="Image of an excerpt from the workflow" />
<div class="figcaption">Image of an excerpt from the workflow</div>
</div>
<p>Rotation improves the interpretation of the components by maximizing the loading on each variable on one of the extracted components while minimizing the loading on all other components. Rotation works by changing the absolute values of the variables while keeping their differential values constant.</p>
<p>There are two big choices and we need to make them on theoretical grounds:</p>
<ul>
<li>Orthogonal rotation if you think that the components are independent/unrelated.
<ul>
<li>Varimax is the most common orthogonal rotation.</li>
</ul></li>
<li>Oblique rotation if you think that the components are related correlated.
<ul>
<li>Oblimin and promax are common oblique rotations.</li>
</ul></li>
</ul>
<p>Which to do?</p>
<ul>
<li>Orthogonal is sometimes considered to be “easier” because it minimizes cross-loadings, but</li>
<li>Can you think of a measure where the subscales would <em>not</em> be correlated?</li>
</ul>
<div id="orthogonal-rotation" class="section level4 hasAnchor" number="8.5.4.1">
<h4><span class="header-section-number">8.5.4.1</span> Orthogonal rotation<a href="PCA.html#orthogonal-rotation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="PCA.html#cb267-1" tabindex="-1"></a><span class="co"># pcaORTH &lt;- psych::principal(GRMSmatrix, nfactors = 4, rotate =</span></span>
<span id="cb267-2"><a href="PCA.html#cb267-2" tabindex="-1"></a><span class="co"># &#39;varimax&#39;)</span></span>
<span id="cb267-3"><a href="PCA.html#cb267-3" tabindex="-1"></a>pcaORTH <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(dfGRMS, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb267-4"><a href="PCA.html#cb267-4" tabindex="-1"></a>pcaORTH</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = 4, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
        RC1   RC2   RC3   RC4   h2   u2 com
Obj1   0.57  0.12  0.13  0.08 0.37 0.63 1.2
Obj2   0.58  0.18  0.10  0.09 0.39 0.61 1.3
Obj3   0.53  0.13  0.14  0.07 0.32 0.68 1.3
Obj4   0.60  0.20  0.00  0.01 0.40 0.60 1.2
Obj5   0.53  0.18  0.20 -0.10 0.36 0.64 1.6
Obj6   0.49 -0.04 -0.02  0.43 0.42 0.58 2.0
Obj7   0.46  0.28  0.13  0.15 0.32 0.68 2.1
Obj8   0.57  0.27  0.00 -0.26 0.47 0.53 1.9
Obj9   0.47  0.05  0.21 -0.05 0.27 0.73 1.4
Obj10  0.54  0.02  0.00  0.17 0.33 0.67 1.2
Marg1  0.11  0.78  0.06  0.05 0.63 0.37 1.1
Marg2  0.09  0.61  0.28  0.18 0.50 0.50 1.7
Marg3  0.13  0.60  0.16  0.02 0.40 0.60 1.2
Marg4  0.24  0.56 -0.07  0.11 0.39 0.61 1.5
Marg5  0.20  0.60  0.15  0.04 0.43 0.57 1.4
Marg6  0.37  0.40  0.03  0.18 0.33 0.67 2.4
Marg7  0.10  0.51  0.00  0.12 0.29 0.71 1.2
Str1   0.16  0.19  0.65 -0.12 0.50 0.50 1.4
Str2   0.27  0.04  0.38  0.24 0.28 0.72 2.6
Str3   0.05  0.05  0.66  0.09 0.45 0.55 1.1
Str4   0.14  0.02  0.57 -0.12 0.37 0.63 1.2
Str5   0.10  0.06  0.47  0.25 0.30 0.70 1.7
Ang1  -0.04  0.20  0.44  0.37 0.37 0.63 2.4
Ang2   0.03  0.19  0.01  0.73 0.57 0.43 1.1
Ang3   0.09  0.25  0.12  0.55 0.38 0.62 1.5

                       RC1  RC2  RC3  RC4
SS loadings           3.31 2.92 2.05 1.56
Proportion Var        0.13 0.12 0.08 0.06
Cumulative Var        0.13 0.25 0.33 0.39
Proportion Explained  0.34 0.30 0.21 0.16
Cumulative Proportion 0.34 0.63 0.84 1.00

Mean item complexity =  1.5
Test of the hypothesis that 4 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  639.9  with prob &lt;  0.00000000000000000000000000000000000000000000056 

Fit based upon off diagonal values = 0.89</code></pre>
<p>Essentially, we have the same information as before, except that loadings are calculated after rotation (which adjusts the absolute values of the component loadings while keeping their differential values constant). Our communality and uniqueness values remain the same. The eigenvalues (SS loadings) should even out, but the proportion of variance explained and cumulative variance will remain the same (39%).</p>
<p>The <em>print.psych()</em> function facilitates interpretation and prioritizes the information about which we care most:</p>
<ul>
<li>“cut” will display loadings above .3
<ul>
<li>if some items load on no factors</li>
<li>if some items have cross-loadings (and their relative weights)</li>
</ul></li>
<li>“sort” will reorder the loadings to make it clearer (to the best of its ability…in the case of ties) to which component/scale it belongs</li>
</ul>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="PCA.html#cb269-1" tabindex="-1"></a>pca_table <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaORTH, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = 4, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
      item   RC1   RC2   RC3   RC4   h2   u2 com
Obj4     4  0.60                   0.40 0.60 1.2
Obj2     2  0.58                   0.39 0.61 1.3
Obj1     1  0.57                   0.37 0.63 1.2
Obj8     8  0.57                   0.47 0.53 1.9
Obj10   10  0.54                   0.33 0.67 1.2
Obj5     5  0.53                   0.36 0.64 1.6
Obj3     3  0.53                   0.32 0.68 1.3
Obj6     6  0.49              0.43 0.42 0.58 2.0
Obj9     9  0.47                   0.27 0.73 1.4
Obj7     7  0.46                   0.32 0.68 2.1
Marg1   11        0.78             0.63 0.37 1.1
Marg2   12        0.61             0.50 0.50 1.7
Marg5   15        0.60             0.43 0.57 1.4
Marg3   13        0.60             0.40 0.60 1.2
Marg4   14        0.56             0.39 0.61 1.5
Marg7   17        0.51             0.29 0.71 1.2
Marg6   16  0.37  0.40             0.33 0.67 2.4
Str3    20              0.66       0.45 0.55 1.1
Str1    18              0.65       0.50 0.50 1.4
Str4    21              0.57       0.37 0.63 1.2
Str5    22              0.47       0.30 0.70 1.7
Ang1    23              0.44  0.37 0.37 0.63 2.4
Str2    19              0.38       0.28 0.72 2.6
Ang2    24                    0.73 0.57 0.43 1.1
Ang3    25                    0.55 0.38 0.62 1.5

                       RC1  RC2  RC3  RC4
SS loadings           3.31 2.92 2.05 1.56
Proportion Var        0.13 0.12 0.08 0.06
Cumulative Var        0.13 0.25 0.33 0.39
Proportion Explained  0.34 0.30 0.21 0.16
Cumulative Proportion 0.34 0.63 0.84 1.00

Mean item complexity =  1.5
Test of the hypothesis that 4 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  639.9  with prob &lt;  0.00000000000000000000000000000000000000000000056 

Fit based upon off diagonal values = 0.89</code></pre>
<p>In the unrotated solution, most variables loaded on the first component. After rotation, there are four clear components/scales. Further, there is clear (or at least reasonable) component/scale membership for each item. This table lists all factor loadings that are greater than 0.30. When an item has multiple factor loadings listed, we inspect it for “cross-loading.” We observe cross-loadings with the following items: Obj6, Marg6, Ang1.</p>
<p>If this were a new scale and we had not yet established ideas for subscales, the next step would be to examine the items, themselves, and try to name the scales/components. If our scale construction included a priori/planned subscales, this is where we hope that the items fall where they were hypothesized to do so. Our simulated data worked pretty well, and with the exception of one item (i.e., Ang1) replicated the four scales that Lewis and Neville <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> reported in the article.</p>
<ul>
<li>Assumptions of Beauty and Sexual Objectification</li>
<li>Silenced and Marginalized</li>
<li>Strong Woman Stereotype</li>
<li>Angry Woman Stereotype</li>
</ul>
<p>We can also create a figure of the result.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="PCA.html#cb271-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaORTH)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>We can extract the component loadings and write them to a table. This can be useful in preparing an APA style table for a manuscript or presentation.</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="PCA.html#cb272-1" tabindex="-1"></a><span class="fu">names</span>(pcaORTH)</span></code></pre></div>
<pre><code> [1] &quot;values&quot;       &quot;rotation&quot;     &quot;n.obs&quot;        &quot;communality&quot;  &quot;loadings&quot;    
 [6] &quot;fit&quot;          &quot;fit.off&quot;      &quot;fn&quot;           &quot;Call&quot;         &quot;uniquenesses&quot;
[11] &quot;complexity&quot;   &quot;valid&quot;        &quot;chi&quot;          &quot;EPVAL&quot;        &quot;R2&quot;          
[16] &quot;objective&quot;    &quot;residual&quot;     &quot;rms&quot;          &quot;factors&quot;      &quot;dof&quot;         
[21] &quot;null.dof&quot;     &quot;null.model&quot;   &quot;criteria&quot;     &quot;STATISTIC&quot;    &quot;PVAL&quot;        
[26] &quot;weights&quot;      &quot;r.scores&quot;     &quot;rot.mat&quot;      &quot;Vaccounted&quot;   &quot;Structure&quot;   
[31] &quot;scores&quot;      </code></pre>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="PCA.html#cb274-1" tabindex="-1"></a>pcaORTH_table <span class="ot">&lt;-</span> <span class="fu">round</span>(pcaORTH<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb274-2"><a href="PCA.html#cb274-2" tabindex="-1"></a><span class="fu">write.table</span>(pcaORTH_table, <span class="at">file =</span> <span class="st">&quot;pcaORTH_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb274-3"><a href="PCA.html#cb274-3" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb274-4"><a href="PCA.html#cb274-4" tabindex="-1"></a>pcaORTH_table</span></code></pre></div>
<pre><code>
Loadings:
      RC1    RC2    RC3    RC4   
Obj1   0.574  0.121  0.131       
Obj2   0.581  0.181              
Obj3   0.531  0.125  0.137       
Obj4   0.604  0.200              
Obj5   0.532  0.176  0.202       
Obj6   0.489                0.428
Obj7   0.457  0.278  0.128  0.150
Obj8   0.572  0.273        -0.260
Obj9   0.468         0.210       
Obj10  0.545                0.170
Marg1  0.111  0.784              
Marg2         0.615  0.284  0.185
Marg3  0.134  0.596  0.155       
Marg4  0.237  0.559         0.113
Marg5  0.201  0.601  0.146       
Marg6  0.368  0.403         0.176
Marg7  0.102  0.511         0.121
Str1   0.157  0.192  0.648 -0.117
Str2   0.271         0.381  0.238
Str3                 0.660       
Str4   0.142         0.574 -0.124
Str5   0.104         0.470  0.250
Ang1          0.196  0.444  0.367
Ang2          0.195         0.732
Ang3          0.245  0.118  0.549

                 RC1   RC2   RC3   RC4
SS loadings    3.310 2.916 2.045 1.559
Proportion Var 0.132 0.117 0.082 0.062
Cumulative Var 0.132 0.249 0.331 0.393</code></pre>
</div>
<div id="oblique-rotation" class="section level4 hasAnchor" number="8.5.4.2">
<h4><span class="header-section-number">8.5.4.2</span> Oblique rotation<a href="PCA.html#oblique-rotation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Whereas the orthogonal rotation sought to maximize the independence/unrelatedness of the components, an oblique rotation will allow them to be correlated. Researchers often explore both solutions but then only report one.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="PCA.html#cb276-1" tabindex="-1"></a><span class="co"># pcaOBL &lt;- psych::principal(GRMSmatrix, nfactors = 4, rotate =</span></span>
<span id="cb276-2"><a href="PCA.html#cb276-2" tabindex="-1"></a><span class="co"># &#39;oblimin&#39;)</span></span>
<span id="cb276-3"><a href="PCA.html#cb276-3" tabindex="-1"></a>pcaOBL <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(dfGRMS, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span></code></pre></div>
<pre><code>Loading required namespace: GPArotation</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="PCA.html#cb278-1" tabindex="-1"></a>pcaOBL</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = 4, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
        TC2   TC1   TC3   TC4   h2   u2 com
Obj1   0.57  0.01  0.09  0.03 0.37 0.63 1.1
Obj2   0.57  0.08  0.05  0.04 0.39 0.61 1.1
Obj3   0.53  0.02  0.10  0.02 0.32 0.68 1.1
Obj4   0.60  0.11 -0.05 -0.04 0.40 0.60 1.1
Obj5   0.51  0.09  0.17 -0.15 0.36 0.64 1.5
Obj6   0.53 -0.17 -0.05  0.40 0.42 0.58 2.1
Obj7   0.42  0.19  0.07  0.10 0.32 0.68 1.6
Obj8   0.55  0.22 -0.05 -0.32 0.47 0.53 2.0
Obj9   0.46 -0.04  0.19 -0.09 0.27 0.73 1.4
Obj10  0.58 -0.09 -0.04  0.13 0.33 0.67 1.2
Marg1 -0.03  0.81 -0.03  0.01 0.63 0.37 1.0
Marg2 -0.04  0.60  0.21  0.14 0.50 0.50 1.4
Marg3  0.02  0.60  0.08 -0.02 0.40 0.60 1.0
Marg4  0.16  0.55 -0.16  0.07 0.39 0.61 1.4
Marg5  0.09  0.59  0.07  0.00 0.43 0.57 1.1
Marg6  0.32  0.35 -0.04  0.13 0.33 0.67 2.3
Marg7  0.02  0.52 -0.06  0.09 0.29 0.71 1.1
Str1   0.06  0.13  0.64 -0.15 0.50 0.50 1.2
Str2   0.24 -0.07  0.37  0.21 0.28 0.72 2.5
Str3  -0.02 -0.03  0.67  0.07 0.45 0.55 1.0
Str4   0.09 -0.04  0.59 -0.15 0.37 0.63 1.2
Str5   0.05 -0.02  0.46  0.23 0.30 0.70 1.5
Ang1  -0.12  0.14  0.42  0.36 0.37 0.63 2.4
Ang2   0.01  0.13 -0.04  0.73 0.57 0.43 1.1
Ang3   0.05  0.18  0.07  0.54 0.38 0.62 1.3

                       TC2  TC1  TC3  TC4
SS loadings           3.34 2.90 2.05 1.55
Proportion Var        0.13 0.12 0.08 0.06
Cumulative Var        0.13 0.25 0.33 0.39
Proportion Explained  0.34 0.29 0.21 0.16
Cumulative Proportion 0.34 0.63 0.84 1.00

 With component correlations of 
     TC2  TC1  TC3  TC4
TC2 1.00 0.35 0.20 0.10
TC1 0.35 1.00 0.24 0.16
TC3 0.20 0.24 1.00 0.09
TC4 0.10 0.16 0.09 1.00

Mean item complexity =  1.4
Test of the hypothesis that 4 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  639.9  with prob &lt;  0.00000000000000000000000000000000000000000000056 

Fit based upon off diagonal values = 0.89</code></pre>
<p>We can make it a little easier to interpret by removing all factor loadings below .30.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="PCA.html#cb280-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaOBL, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = dfGRMS, nfactors = 4, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
      item   TC2   TC1   TC3   TC4   h2   u2 com
Obj4     4  0.60                   0.40 0.60 1.1
Obj10   10  0.58                   0.33 0.67 1.2
Obj1     1  0.57                   0.37 0.63 1.1
Obj2     2  0.57                   0.39 0.61 1.1
Obj8     8  0.55             -0.32 0.47 0.53 2.0
Obj6     6  0.53              0.40 0.42 0.58 2.1
Obj3     3  0.53                   0.32 0.68 1.1
Obj5     5  0.51                   0.36 0.64 1.5
Obj9     9  0.46                   0.27 0.73 1.4
Obj7     7  0.42                   0.32 0.68 1.6
Marg1   11        0.81             0.63 0.37 1.0
Marg3   13        0.60             0.40 0.60 1.0
Marg2   12        0.60             0.50 0.50 1.4
Marg5   15        0.59             0.43 0.57 1.1
Marg4   14        0.55             0.39 0.61 1.4
Marg7   17        0.52             0.29 0.71 1.1
Marg6   16  0.32  0.35             0.33 0.67 2.3
Str3    20              0.67       0.45 0.55 1.0
Str1    18              0.64       0.50 0.50 1.2
Str4    21              0.59       0.37 0.63 1.2
Str5    22              0.46       0.30 0.70 1.5
Ang1    23              0.42  0.36 0.37 0.63 2.4
Str2    19              0.37       0.28 0.72 2.5
Ang2    24                    0.73 0.57 0.43 1.1
Ang3    25                    0.54 0.38 0.62 1.3

                       TC2  TC1  TC3  TC4
SS loadings           3.34 2.90 2.05 1.55
Proportion Var        0.13 0.12 0.08 0.06
Cumulative Var        0.13 0.25 0.33 0.39
Proportion Explained  0.34 0.29 0.21 0.16
Cumulative Proportion 0.34 0.63 0.84 1.00

 With component correlations of 
     TC2  TC1  TC3  TC4
TC2 1.00 0.35 0.20 0.10
TC1 0.35 1.00 0.24 0.16
TC3 0.20 0.24 1.00 0.09
TC4 0.10 0.16 0.09 1.00

Mean item complexity =  1.4
Test of the hypothesis that 4 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  639.9  with prob &lt;  0.00000000000000000000000000000000000000000000056 

Fit based upon off diagonal values = 0.89</code></pre>
<p>The solution from the oblique rotation was similar to the orthogonal one. Note, though, that because our specification included “sort=TRUE” that the relative weights wiggled around and so the items are listed in a little different order.</p>
<p>Let’s create a table and write it to a file.</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="PCA.html#cb282-1" tabindex="-1"></a>pcaOBL_table <span class="ot">&lt;-</span> <span class="fu">round</span>(pcaOBL<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb282-2"><a href="PCA.html#cb282-2" tabindex="-1"></a><span class="fu">write.table</span>(pcaOBL_table, <span class="at">file =</span> <span class="st">&quot;pcaOBL_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb282-3"><a href="PCA.html#cb282-3" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb282-4"><a href="PCA.html#cb282-4" tabindex="-1"></a>pcaOBL_table</span></code></pre></div>
<pre><code>
Loadings:
      TC2    TC1    TC3    TC4   
Obj1   0.574                     
Obj2   0.574                     
Obj3   0.526                     
Obj4   0.604  0.108              
Obj5   0.509         0.166 -0.149
Obj6   0.533 -0.170         0.401
Obj7   0.424  0.192         0.103
Obj8   0.553  0.219        -0.318
Obj9   0.464         0.190       
Obj10  0.576                0.132
Marg1         0.810              
Marg2         0.600  0.211  0.145
Marg3         0.600              
Marg4  0.163  0.554 -0.155       
Marg5         0.592              
Marg6  0.319  0.349         0.131
Marg7         0.518              
Str1          0.129  0.644 -0.152
Str2   0.245         0.366  0.212
Str3                 0.670       
Str4                 0.589 -0.148
Str5                 0.463  0.234
Ang1  -0.116  0.140  0.423  0.356
Ang2          0.131         0.729
Ang3          0.183         0.535

                 TC2   TC1   TC3   TC4
SS loadings    3.107 2.668 1.930 1.471
Proportion Var 0.124 0.107 0.077 0.059
Cumulative Var 0.124 0.231 0.308 0.367</code></pre>
<p>The same four components/scales have emerged, but they are in different order.</p>
<p>The oblique rotation allows us to see the correlation between the components/scales. This was not available in the orthogonal rotation because the assumption of the orthogonal/varimax rotation is that the scales/components are uncorrelated; hence in the analysis they were fixed to 0.0.</p>
<p>We can see that all the scales have low to moderate (i.e, 0.09 to 0.35) correlations with each other.</p>
<p>Of course, there is always a little complexity. In oblique rotations, there is a distinction between the <em>pattern</em> matrix (which reports component loadings and is comparable to the matrix we interpreted for the orthogonal rotation) and the <em>structure</em> matrix (takes into account the relationship between the components/scales – it is a product of the pattern matrix and the matrix containing the correlation coefficients between the components/scales). Most interpret the pattern matrix because it is simpler; however, it could be that values in the pattern matrix are suppressed because of relations between the components. Therefore, the structure matrix can be a useful check and some editors will request it.</p>
<p>Obtaining the structure matrix requires two steps. First, we multiply the factor loadings with the phi matrix.</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="PCA.html#cb284-1" tabindex="-1"></a><span class="co"># names(pcaOBL)</span></span>
<span id="cb284-2"><a href="PCA.html#cb284-2" tabindex="-1"></a>pcaOBL<span class="sc">$</span>loadings <span class="sc">%*%</span> pcaOBL<span class="sc">$</span>Phi</span></code></pre></div>
<pre><code>             TC2       TC1        TC3         TC4
Obj1  0.59854109 0.2370854 0.21076193  0.10026056
Obj2  0.61370763 0.2936877 0.18613777  0.11300577
Obj3  0.55625886 0.2340806 0.21133177  0.08838322
Obj4  0.62653372 0.2994708 0.09212284  0.03271529
Obj5  0.55782211 0.2813705 0.27627677 -0.06671857
Obj6  0.50436458 0.0686600 0.04959170  0.42362055
Obj7  0.51583784 0.3746086 0.21323217  0.18475919
Obj8  0.58631883 0.3483430 0.08569629 -0.22925474
Obj9  0.47739175 0.1500764 0.26407686 -0.03124475
Obj10 0.55033661 0.1232499 0.06974955  0.17330360
Marg1 0.25202377 0.7945638 0.16105543  0.13171661
Marg2 0.22669221 0.6607073 0.36285145  0.25811600
Marg3 0.24653097 0.6246027 0.23339896  0.08632620
Marg4 0.33257030 0.5843225 0.01980084  0.16383648
Marg5 0.31382840 0.6413860 0.23355689  0.10932345
Marg6 0.44535049 0.4708617 0.11768477  0.21681782
Marg7 0.19733852 0.5242792 0.07531732  0.17048225
Str1  0.22295271 0.2846102 0.67447904 -0.06303143
Str2  0.31665124 0.1416729 0.41881452  0.26069989
Str3  0.11375939 0.1383416 0.66583221  0.12771942
Str4  0.17266253 0.1046982 0.58122385 -0.09110045
Str5  0.16426964 0.1477531 0.49084330  0.27949111
Ang1  0.05479887 0.2604643 0.46720892  0.40679247
Ang2  0.12294975 0.2431195 0.06259901  0.74708242
Ang3  0.17778840 0.3025083 0.17023961  0.57585722</code></pre>
<p>Next, we can use Field’s <span class="citation">(<a href="#ref-field_discovering_2012">2012</a>)</span> function to produce the matrix.</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="PCA.html#cb286-1" tabindex="-1"></a><span class="co"># Field&#39;s function to produce the structure matrix</span></span>
<span id="cb286-2"><a href="PCA.html#cb286-2" tabindex="-1"></a>factor.structure <span class="ot">&lt;-</span> <span class="cf">function</span>(fa, <span class="at">cut =</span> <span class="fl">0.2</span>, <span class="at">decimals =</span> <span class="dv">2</span>) {</span>
<span id="cb286-3"><a href="PCA.html#cb286-3" tabindex="-1"></a>    structure.matrix <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa.sort</span>(fa<span class="sc">$</span>loadings <span class="sc">%*%</span> fa<span class="sc">$</span>Phi)</span>
<span id="cb286-4"><a href="PCA.html#cb286-4" tabindex="-1"></a>    structure.matrix <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(structure.matrix) <span class="sc">&lt;</span> cut,</span>
<span id="cb286-5"><a href="PCA.html#cb286-5" tabindex="-1"></a>        <span class="st">&quot;&quot;</span>, <span class="fu">round</span>(structure.matrix, decimals)))</span>
<span id="cb286-6"><a href="PCA.html#cb286-6" tabindex="-1"></a>    <span class="fu">return</span>(structure.matrix)</span>
<span id="cb286-7"><a href="PCA.html#cb286-7" tabindex="-1"></a>}</span>
<span id="cb286-8"><a href="PCA.html#cb286-8" tabindex="-1"></a></span>
<span id="cb286-9"><a href="PCA.html#cb286-9" tabindex="-1"></a><span class="fu">factor.structure</span>(pcaOBL, <span class="at">cut =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<pre><code>       TC2  TC1  TC3  TC4
Obj4  0.63               
Obj2  0.61               
Obj1   0.6               
Obj8  0.59 0.35          
Obj5  0.56               
Obj3  0.56               
Obj10 0.55               
Obj7  0.52 0.37          
Obj6   0.5           0.42
Obj9  0.48               
Marg1      0.79          
Marg2      0.66 0.36     
Marg5 0.31 0.64          
Marg3      0.62          
Marg4 0.33 0.58          
Marg7      0.52          
Marg6 0.45 0.47          
Str1            0.67     
Str3            0.67     
Str4            0.58     
Str5            0.49     
Ang1            0.47 0.41
Str2  0.32      0.42     
Ang2                 0.75
Ang3        0.3      0.58</code></pre>
<p>Although some of the relative values changed, our items were stable regarding their component membership.</p>
</div>
</div>
<div id="component-scores" class="section level3 hasAnchor" number="8.5.5">
<h3><span class="header-section-number">8.5.5</span> Component Scores<a href="PCA.html#component-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Component <em>scores</em> (PC scores) can be created for each case (row) on each component (column). These can be used to assess the relative standing of one person on the construct/variable to another. We can also use them in regression (in place of means or sums) when groups of predictors correlate so highly that there is multicollinearity.</p>
<p>Computation involves multiplying an individual’s item-level responses by the component loadings we obtained through the PCA process. The results will be one score per component for each row/case.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="PCA.html#cb288-1" tabindex="-1"></a>pcaOBL <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(dfGRMS, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>, <span class="at">scores =</span> <span class="cn">TRUE</span>)</span>
<span id="cb288-2"><a href="PCA.html#cb288-2" tabindex="-1"></a><span class="fu">head</span>(pcaOBL<span class="sc">$</span>scores, <span class="dv">10</span>)  <span class="co">#shows us only the first 10 (of N = 2571)</span></span></code></pre></div>
<pre><code>             TC2        TC1         TC3         TC4
 [1,] -0.6458500 -1.5519979  0.73544246 -0.76005053
 [2,]  0.5116784 -1.0097579  0.74427743  0.29538913
 [3,]  0.5825763  0.1327654 -0.03596272  1.40125523
 [4,] -1.1296840 -1.0820066  0.46203018 -2.08203840
 [5,] -0.3066491  0.7020903 -1.15731968 -0.08696116
 [6,] -0.6165563  0.5443947 -0.37332546  1.06336132
 [7,]  0.3100935  0.7005788 -1.12949607 -0.99349900
 [8,] -1.7404874 -0.6389406  0.51456794  1.23689663
 [9,] -0.4801252 -1.0772976 -0.71350564  0.77814794
[10,]  0.3986271 -0.5906088 -0.71507356  0.80831256</code></pre>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="PCA.html#cb290-1" tabindex="-1"></a>dfGRMS <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dfGRMS, pcaOBL<span class="sc">$</span>scores)  <span class="co">#adds them to our raw dataset</span></span></code></pre></div>
<p>To bring this full circle, we can see the correlation of the component scores; the pattern maps onto what we saw previously.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="PCA.html#cb291-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">corr.test</span>(dfGRMS[<span class="fu">c</span>(<span class="st">&quot;TC1&quot;</span>, <span class="st">&quot;TC4&quot;</span>, <span class="st">&quot;TC3&quot;</span>, <span class="st">&quot;TC2&quot;</span>)])</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = dfGRMS[c(&quot;TC1&quot;, &quot;TC4&quot;, &quot;TC3&quot;, &quot;TC2&quot;)])
Correlation matrix 
     TC1  TC4  TC3  TC2
TC1 1.00 0.16 0.24 0.35
TC4 0.16 1.00 0.09 0.10
TC3 0.24 0.09 1.00 0.20
TC2 0.35 0.10 0.20 1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
     TC1  TC4  TC3  TC2
TC1 0.00 0.03 0.00 0.00
TC4 0.01 0.00 0.19 0.19
TC3 0.00 0.13 0.00 0.00
TC2 0.00 0.10 0.00 0.00

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<p>And now for a figure of the oblique rotation. Note that figure includes semi-circles between TC1/TC2 and TC1/TC4. These represent significant correlation coefficients between the components that are named. In contrast, the orthogonal rotation required the components to be uncorrelated.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="PCA.html#cb293-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaOBL, <span class="at">error =</span> <span class="cn">TRUE</span>, <span class="at">side =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
</div>
</div>
<div id="apa-style-results" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> APA Style Results<a href="PCA.html#apa-style-results" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Results</strong></p>
<blockquote>
<p>The dimensionality of the 25 items from the Gendered Racial Microagressions Scale for Black Women was analyzed using principal components analysis. Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was .85, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^{2}(300)=1217.508, p &lt; .001\)</span>, indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0075, supporting the suitability of our data for analysis.</p>
</blockquote>
<blockquote>
<p>Four criteria were used to determine the number of components to extract: a priori theory, the scree test, the eigenvalue-greater-than-one criteria, and the interpretability of the solution. Kaiser’s eigenvalue-greater-than-one criteria suggested seven components, and, in combination explained 39% of the variance. The inflexion in the scree plot suggested retaining between one and four components. Considering the a priori theory obtained from the original psychometric article <span class="citation">(<a href="#ref-lewis_construction_2015">J. A. Lewis &amp; Neville, 2015</a>)</span>, four components were extracted. We investigated each with orthogonal (varimax) and oblique (oblimin) procedures. Given the low-to-moderate correlations (ranging from 0.09 to 0.35) and the clear component loadings, we determined that an oblique solution was most appropriate.</p>
</blockquote>
<blockquote>
<p>The rotated solution, as shown in Table 1 and Figure 1, yielded four interpretable components, each listed with the proportion of variance accounted for: assumptions of beauty and sexual objectification (13%), silenced and marginalized (12%), strong woman stereotype (8%), and angry woman stereotype (6%).</p>
</blockquote>
<p>Regarding the Table 1, I would include a table with all the values, bolding those with component membership. This is easy, though, because it is how the table was exported when we wrote it to a .csv file.</p>
</div>
<div id="back-to-the-future-the-relationship-between-pca-and-item-analysis" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Back to the FutuRe: The relationship between PCA and item analysis<a href="PCA.html#back-to-the-future-the-relationship-between-pca-and-item-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Earlier in the ReCentering Psych Stats OER I included the lesson on <a href="ItemAnalSurvey.html#ItemAnalSurvey">item analysis</a> because I find it to be a useful stepping stone into principal components and principal factor analyses.</p>
<p>Nearing the end of the lesson on PCA, we can ask, “How do the results we obtained from PCA compare to those found in item analysis?” To answer these questions we will (a) calculate corrected item-total correlation coefficients, (c) calculate correlations between each item and the mean scores from the remaining scales, (c) calculate component loadings for a PCA with an orthogonal rotation, and (d) calculate component loadings for a PCA with an oblique rotation. I will teach the last step – assembling them into a single table – in R. The code is complicated and many might choose to do it in a spreadsheet, outside of the R environment. After assembly, though, we can compare the results.</p>
<p>First, we score the total and subscales using the dataset we simulated above (dfGRMS).</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="PCA.html#cb294-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb294-2"><a href="PCA.html#cb294-2" tabindex="-1"></a>GRMSVars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>,</span>
<span id="cb294-3"><a href="PCA.html#cb294-3" tabindex="-1"></a>    <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>, <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>,</span>
<span id="cb294-4"><a href="PCA.html#cb294-4" tabindex="-1"></a>    <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Str1&quot;</span>, <span class="st">&quot;Str2&quot;</span>, <span class="st">&quot;Str3&quot;</span>, <span class="st">&quot;Str4&quot;</span>, <span class="st">&quot;Str5&quot;</span>, <span class="st">&quot;Ang1&quot;</span>, <span class="st">&quot;Ang2&quot;</span>, <span class="st">&quot;Ang3&quot;</span>)</span>
<span id="cb294-5"><a href="PCA.html#cb294-5" tabindex="-1"></a>ObjectifiedVars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>,</span>
<span id="cb294-6"><a href="PCA.html#cb294-6" tabindex="-1"></a>    <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>)</span>
<span id="cb294-7"><a href="PCA.html#cb294-7" tabindex="-1"></a>MarginalizedVars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>, <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>,</span>
<span id="cb294-8"><a href="PCA.html#cb294-8" tabindex="-1"></a>    <span class="st">&quot;Marg7&quot;</span>)</span>
<span id="cb294-9"><a href="PCA.html#cb294-9" tabindex="-1"></a>StrongVars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Str1&quot;</span>, <span class="st">&quot;Str2&quot;</span>, <span class="st">&quot;Str3&quot;</span>, <span class="st">&quot;Str4&quot;</span>, <span class="st">&quot;Str5&quot;</span>)</span>
<span id="cb294-10"><a href="PCA.html#cb294-10" tabindex="-1"></a>AngryVars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Ang1&quot;</span>, <span class="st">&quot;Ang2&quot;</span>, <span class="st">&quot;Ang3&quot;</span>)</span>
<span id="cb294-11"><a href="PCA.html#cb294-11" tabindex="-1"></a></span>
<span id="cb294-12"><a href="PCA.html#cb294-12" tabindex="-1"></a>dfGRMS<span class="sc">$</span>GRMStot <span class="ot">&lt;-</span> sjstats<span class="sc">::</span><span class="fu">mean_n</span>(dfGRMS[, GRMSVars], <span class="fl">0.8</span>)  <span class="co">#will create the mean for each individual if 80% of variables are present </span></span>
<span id="cb294-13"><a href="PCA.html#cb294-13" tabindex="-1"></a>dfGRMS<span class="sc">$</span>Objectified <span class="ot">&lt;-</span> sjstats<span class="sc">::</span><span class="fu">mean_n</span>(dfGRMS[, ObjectifiedVars], <span class="fl">0.8</span>)  <span class="co">#will create the mean for each individual if 80% of variables are present </span></span>
<span id="cb294-14"><a href="PCA.html#cb294-14" tabindex="-1"></a>dfGRMS<span class="sc">$</span>Marginalized <span class="ot">&lt;-</span> sjstats<span class="sc">::</span><span class="fu">mean_n</span>(dfGRMS[, MarginalizedVars], <span class="fl">0.8</span>)  <span class="co">#will create the mean for each individual if 80% of variables are present </span></span>
<span id="cb294-15"><a href="PCA.html#cb294-15" tabindex="-1"></a>dfGRMS<span class="sc">$</span>Strong <span class="ot">&lt;-</span> sjstats<span class="sc">::</span><span class="fu">mean_n</span>(dfGRMS[, StrongVars], <span class="fl">0.8</span>)  <span class="co">#will create the mean for each individual if 80% of variables are present (in this case all variables must be present)</span></span>
<span id="cb294-16"><a href="PCA.html#cb294-16" tabindex="-1"></a>dfGRMS<span class="sc">$</span>Angry <span class="ot">&lt;-</span> sjstats<span class="sc">::</span><span class="fu">mean_n</span>(dfGRMS[, AngryVars], <span class="fl">0.8</span>)  <span class="co">#will create the mean for each individual if 80% of variables are present (in this case all variables must be present)</span></span></code></pre></div>
<p>While we are at it, let’s just create tiny dfs with just our variables of interest.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="PCA.html#cb295-1" tabindex="-1"></a>GRMStotal <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(dfGRMS, Obj1<span class="sc">:</span>Ang3)</span>
<span id="cb295-2"><a href="PCA.html#cb295-2" tabindex="-1"></a>Objectification <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(dfGRMS, Obj1<span class="sc">:</span>Obj10)</span>
<span id="cb295-3"><a href="PCA.html#cb295-3" tabindex="-1"></a>Marginalization <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(dfGRMS, Marg1<span class="sc">:</span>Marg7)</span>
<span id="cb295-4"><a href="PCA.html#cb295-4" tabindex="-1"></a>Strong <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(dfGRMS, Str1<span class="sc">:</span>Str5)</span>
<span id="cb295-5"><a href="PCA.html#cb295-5" tabindex="-1"></a>Angry <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(dfGRMS, Ang1<span class="sc">:</span>Ang3)</span></code></pre></div>
<div id="calculating-and-extracting-item-total-correlation-coefficients" class="section level3 hasAnchor" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> Calculating and Extracting Item-Total Correlation Coefficients<a href="PCA.html#calculating-and-extracting-item-total-correlation-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="corrected-item-total-correlations-from-the-psychalpha" class="section level4 hasAnchor" number="8.7.1.1">
<h4><span class="header-section-number">8.7.1.1</span> Corrected item-total correlations from the <em>psych::alpha()</em><a href="PCA.html#corrected-item-total-correlations-from-the-psychalpha" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s first ask, “Is there support for this instrument as a unidimensional measure?” To do that, we get an alpha for the whole scale score.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="PCA.html#cb296-1" tabindex="-1"></a>GRMSalpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(GRMStotal)  <span class="co">#creating an object from this analysis so I can extract and manipulate the item statistics (specifically the r.drop)</span></span>
<span id="cb296-2"><a href="PCA.html#cb296-2" tabindex="-1"></a>GRMSalpha</span></code></pre></div>
<pre><code>
Reliability analysis   
Call: psych::alpha(x = GRMStotal)

  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r
      0.84      0.84    0.86      0.18 5.3 0.014  2.5 0.44     0.18

    95% confidence boundaries 
         lower alpha upper
Feldt     0.81  0.84  0.87
Duhachek  0.81  0.84  0.87

 Reliability if an item is dropped:
      raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r
Obj1       0.83      0.83    0.85      0.17 5.0    0.015 0.0066  0.17
Obj2       0.83      0.83    0.85      0.17 5.0    0.015 0.0066  0.17
Obj3       0.83      0.84    0.85      0.17 5.1    0.015 0.0068  0.17
Obj4       0.83      0.83    0.85      0.17 5.0    0.015 0.0065  0.17
Obj5       0.83      0.83    0.85      0.17 5.0    0.015 0.0066  0.17
Obj6       0.84      0.84    0.85      0.18 5.2    0.015 0.0067  0.18
Obj7       0.83      0.83    0.85      0.17 5.0    0.015 0.0066  0.17
Obj8       0.84      0.84    0.85      0.18 5.1    0.015 0.0063  0.18
Obj9       0.84      0.84    0.85      0.18 5.2    0.015 0.0067  0.18
Obj10      0.84      0.84    0.85      0.18 5.2    0.015 0.0067  0.18
Marg1      0.83      0.83    0.85      0.17 5.0    0.015 0.0059  0.17
Marg2      0.83      0.83    0.85      0.17 5.0    0.015 0.0063  0.17
Marg3      0.83      0.83    0.85      0.17 5.1    0.015 0.0065  0.17
Marg4      0.83      0.84    0.85      0.17 5.1    0.015 0.0064  0.17
Marg5      0.83      0.83    0.85      0.17 5.0    0.015 0.0065  0.17
Marg6      0.83      0.83    0.85      0.17 5.0    0.015 0.0066  0.17
Marg7      0.84      0.84    0.85      0.18 5.2    0.015 0.0066  0.18
Str1       0.84      0.84    0.85      0.18 5.1    0.015 0.0068  0.17
Str2       0.84      0.84    0.85      0.18 5.2    0.015 0.0070  0.18
Str3       0.84      0.84    0.86      0.18 5.2    0.014 0.0066  0.18
Str4       0.84      0.84    0.86      0.18 5.3    0.014 0.0064  0.18
Str5       0.84      0.84    0.86      0.18 5.2    0.014 0.0067  0.18
Ang1       0.84      0.84    0.85      0.18 5.2    0.014 0.0067  0.18
Ang2       0.84      0.84    0.86      0.18 5.3    0.014 0.0064  0.18
Ang3       0.84      0.84    0.85      0.18 5.2    0.015 0.0067  0.18

 Item statistics 
        n raw.r std.r r.cor r.drop mean   sd
Obj1  259  0.50  0.51  0.48   0.44  2.8 0.87
Obj2  259  0.53  0.54  0.51   0.47  2.6 0.91
Obj3  259  0.49  0.49  0.46   0.41  2.6 0.99
Obj4  259  0.51  0.51  0.49   0.44  2.6 1.05
Obj5  259  0.50  0.50  0.47   0.43  2.3 0.94
Obj6  259  0.41  0.41  0.37   0.34  2.4 0.93
Obj7  259  0.55  0.54  0.52   0.47  2.5 1.20
Obj8  259  0.45  0.46  0.43   0.38  2.5 0.90
Obj9  259  0.41  0.41  0.37   0.34  2.7 0.97
Obj10 259  0.41  0.42  0.38   0.35  2.2 0.83
Marg1 259  0.55  0.55  0.54   0.49  2.7 0.91
Marg2 259  0.56  0.56  0.55   0.50  2.8 0.89
Marg3 259  0.50  0.50  0.47   0.42  2.4 1.05
Marg4 259  0.47  0.48  0.45   0.41  2.5 0.87
Marg5 259  0.54  0.54  0.52   0.47  2.3 0.92
Marg6 259  0.52  0.53  0.50   0.46  2.7 0.94
Marg7 259  0.41  0.41  0.36   0.33  2.5 1.04
Str1  259  0.44  0.45  0.41   0.37  2.7 0.93
Str2  259  0.42  0.42  0.38   0.34  2.6 0.91
Str3  259  0.37  0.37  0.32   0.29  2.3 0.98
Str4  259  0.31  0.32  0.27   0.24  2.2 0.80
Str5  259  0.38  0.37  0.32   0.29  2.5 1.05
Ang1  259  0.39  0.38  0.34   0.31  2.6 1.04
Ang2  259  0.36  0.35  0.31   0.28  2.3 1.05
Ang3  259  0.40  0.40  0.36   0.32  2.4 0.91

Non missing response frequency for each item
         0    1    2    3    4    5 miss
Obj1  0.01 0.07 0.27 0.49 0.16 0.01    0
Obj2  0.01 0.07 0.36 0.41 0.12 0.03    0
Obj3  0.02 0.11 0.32 0.39 0.14 0.02    0
Obj4  0.01 0.14 0.32 0.33 0.16 0.04    0
Obj5  0.02 0.16 0.39 0.33 0.09 0.01    0
Obj6  0.01 0.15 0.37 0.36 0.09 0.01    0
Obj7  0.04 0.16 0.31 0.29 0.13 0.06    0
Obj8  0.02 0.11 0.36 0.42 0.09 0.01    0
Obj9  0.01 0.10 0.33 0.37 0.17 0.02    0
Obj10 0.02 0.15 0.47 0.31 0.04 0.00    0
Marg1 0.00 0.07 0.34 0.39 0.17 0.02    0
Marg2 0.00 0.07 0.29 0.44 0.18 0.01    0
Marg3 0.03 0.16 0.32 0.34 0.12 0.02    0
Marg4 0.01 0.11 0.39 0.39 0.10 0.00    0
Marg5 0.01 0.18 0.39 0.33 0.08 0.01    0
Marg6 0.01 0.09 0.31 0.40 0.18 0.02    0
Marg7 0.02 0.16 0.28 0.39 0.13 0.03    0
Str1  0.01 0.06 0.36 0.37 0.17 0.03    0
Str2  0.01 0.08 0.36 0.40 0.14 0.02    0
Str3  0.02 0.17 0.42 0.27 0.12 0.01    0
Str4  0.01 0.14 0.52 0.28 0.05 0.00    0
Str5  0.02 0.15 0.31 0.32 0.20 0.00    0
Ang1  0.02 0.14 0.31 0.36 0.15 0.03    0
Ang2  0.03 0.22 0.32 0.33 0.08 0.02    0
Ang3  0.02 0.13 0.39 0.38 0.07 0.01    0</code></pre>
<p>Alpha for the total scale score is 0.84.</p>
<p>And now each of the subscales:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="PCA.html#cb298-1" tabindex="-1"></a>ObjAlpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(Objectification)  <span class="co">#creating an object from this analysis so I can extract and manipulate the item statistics (specifically the r.drop)</span></span>
<span id="cb298-2"><a href="PCA.html#cb298-2" tabindex="-1"></a>ObjAlpha</span></code></pre></div>
<pre><code>
Reliability analysis   
Call: psych::alpha(x = Objectification)

  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r
      0.76      0.77    0.76      0.25 3.3 0.022  2.5 0.55     0.25

    95% confidence boundaries 
         lower alpha upper
Feldt     0.72  0.76  0.81
Duhachek  0.72  0.76  0.81

 Reliability if an item is dropped:
      raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r
Obj1       0.74      0.74    0.73      0.24 2.9    0.024 0.0030  0.25
Obj2       0.74      0.74    0.73      0.24 2.8    0.024 0.0032  0.24
Obj3       0.75      0.75    0.73      0.25 3.0    0.024 0.0036  0.25
Obj4       0.74      0.74    0.72      0.24 2.9    0.024 0.0032  0.25
Obj5       0.74      0.75    0.73      0.25 2.9    0.024 0.0028  0.25
Obj6       0.76      0.76    0.74      0.26 3.2    0.023 0.0026  0.26
Obj7       0.75      0.75    0.73      0.25 3.0    0.023 0.0032  0.25
Obj8       0.74      0.74    0.73      0.24 2.9    0.024 0.0030  0.25
Obj9       0.75      0.76    0.74      0.26 3.1    0.023 0.0033  0.26
Obj10      0.75      0.75    0.74      0.25 3.1    0.023 0.0032  0.25

 Item statistics 
        n raw.r std.r r.cor r.drop mean   sd
Obj1  259  0.59  0.60  0.54   0.47  2.8 0.87
Obj2  259  0.61  0.62  0.56   0.49  2.6 0.91
Obj3  259  0.57  0.57  0.49   0.43  2.6 0.99
Obj4  259  0.63  0.61  0.56   0.49  2.6 1.05
Obj5  259  0.58  0.58  0.51   0.44  2.3 0.94
Obj6  259  0.49  0.50  0.40   0.35  2.4 0.93
Obj7  259  0.60  0.57  0.50   0.43  2.5 1.20
Obj8  259  0.58  0.59  0.52   0.45  2.5 0.90
Obj9  259  0.52  0.51  0.42   0.37  2.7 0.97
Obj10 259  0.52  0.53  0.44   0.39  2.2 0.83

Non missing response frequency for each item
         0    1    2    3    4    5 miss
Obj1  0.01 0.07 0.27 0.49 0.16 0.01    0
Obj2  0.01 0.07 0.36 0.41 0.12 0.03    0
Obj3  0.02 0.11 0.32 0.39 0.14 0.02    0
Obj4  0.01 0.14 0.32 0.33 0.16 0.04    0
Obj5  0.02 0.16 0.39 0.33 0.09 0.01    0
Obj6  0.01 0.15 0.37 0.36 0.09 0.01    0
Obj7  0.04 0.16 0.31 0.29 0.13 0.06    0
Obj8  0.02 0.11 0.36 0.42 0.09 0.01    0
Obj9  0.01 0.10 0.33 0.37 0.17 0.02    0
Obj10 0.02 0.15 0.47 0.31 0.04 0.00    0</code></pre>
<p>Alpha for the Assumptions of Beauty and Sexual Objectification scale is 0.77.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="PCA.html#cb300-1" tabindex="-1"></a>MargAlpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(Marginalization)  <span class="co">#creating an object from this analysis so I can extract and manipulate the item statistics (specifically the r.drop)</span></span>
<span id="cb300-2"><a href="PCA.html#cb300-2" tabindex="-1"></a>MargAlpha</span></code></pre></div>
<pre><code>
Reliability analysis   
Call: psych::alpha(x = Marginalization)

  raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
      0.75      0.75    0.73       0.3   3 0.024  2.6 0.6      0.3

    95% confidence boundaries 
         lower alpha upper
Feldt      0.7  0.75  0.79
Duhachek   0.7  0.75  0.80

 Reliability if an item is dropped:
      raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r
Marg1      0.69      0.69    0.66      0.27 2.3    0.030 0.0038  0.27
Marg2      0.71      0.71    0.68      0.29 2.5    0.028 0.0054  0.29
Marg3      0.72      0.73    0.70      0.31 2.6    0.027 0.0059  0.30
Marg4      0.73      0.73    0.70      0.31 2.8    0.026 0.0055  0.31
Marg5      0.71      0.72    0.69      0.30 2.5    0.028 0.0062  0.31
Marg6      0.73      0.74    0.71      0.32 2.8    0.026 0.0064  0.32
Marg7      0.74      0.74    0.72      0.33 2.9    0.025 0.0045  0.32

 Item statistics 
        n raw.r std.r r.cor r.drop mean   sd
Marg1 259  0.73  0.74  0.69   0.60  2.7 0.91
Marg2 259  0.67  0.68  0.60   0.52  2.8 0.89
Marg3 259  0.64  0.63  0.53   0.46  2.4 1.05
Marg4 259  0.58  0.60  0.49   0.42  2.5 0.87
Marg5 259  0.65  0.66  0.58   0.50  2.3 0.92
Marg6 259  0.59  0.59  0.47   0.41  2.7 0.94
Marg7 259  0.58  0.56  0.43   0.37  2.5 1.04

Non missing response frequency for each item
         0    1    2    3    4    5 miss
Marg1 0.00 0.07 0.34 0.39 0.17 0.02    0
Marg2 0.00 0.07 0.29 0.44 0.18 0.01    0
Marg3 0.03 0.16 0.32 0.34 0.12 0.02    0
Marg4 0.01 0.11 0.39 0.39 0.10 0.00    0
Marg5 0.01 0.18 0.39 0.33 0.08 0.01    0
Marg6 0.01 0.09 0.31 0.40 0.18 0.02    0
Marg7 0.02 0.16 0.28 0.39 0.13 0.03    0</code></pre>
<p>Alpha for the Silenced and Marginalized Scale is 0.75.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="PCA.html#cb302-1" tabindex="-1"></a>StrongAlpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(Strong)  <span class="co">#creating an object from this analysis so I can extract and manipulate the item statistics (specifically the r.drop)</span></span>
<span id="cb302-2"><a href="PCA.html#cb302-2" tabindex="-1"></a>StrongAlpha</span></code></pre></div>
<pre><code>
Reliability analysis   
Call: psych::alpha(x = Strong)

  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r
      0.56      0.57    0.52      0.21 1.3 0.043  2.5 0.56     0.21

    95% confidence boundaries 
         lower alpha upper
Feldt     0.47  0.56  0.64
Duhachek  0.48  0.56  0.64

 Reliability if an item is dropped:
     raw_alpha std.alpha G6(smc) average_r  S/N alpha se  var.r med.r
Str1      0.46      0.47    0.40      0.18 0.89    0.054 0.0032  0.19
Str2      0.53      0.53    0.47      0.22 1.13    0.048 0.0042  0.23
Str3      0.47      0.48    0.41      0.19 0.91    0.053 0.0027  0.21
Str4      0.51      0.51    0.45      0.21 1.05    0.050 0.0035  0.21
Str5      0.55      0.55    0.48      0.24 1.23    0.045 0.0017  0.22

 Item statistics 
       n raw.r std.r r.cor r.drop mean   sd
Str1 259  0.65  0.65  0.52   0.39  2.7 0.93
Str2 259  0.57  0.58  0.38   0.28  2.6 0.91
Str3 259  0.65  0.64  0.51   0.38  2.3 0.98
Str4 259  0.56  0.60  0.43   0.32  2.2 0.80
Str5 259  0.58  0.55  0.33   0.25  2.5 1.05

Non missing response frequency for each item
        0    1    2    3    4    5 miss
Str1 0.01 0.06 0.36 0.37 0.17 0.03    0
Str2 0.01 0.08 0.36 0.40 0.14 0.02    0
Str3 0.02 0.17 0.42 0.27 0.12 0.01    0
Str4 0.01 0.14 0.52 0.28 0.05 0.00    0
Str5 0.02 0.15 0.31 0.32 0.20 0.00    0</code></pre>
<p>Alpha for the Strong Black Woman Stereotype is 0.57.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="PCA.html#cb304-1" tabindex="-1"></a>AngryAlpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(Angry)  <span class="co">#creating an object from this analysis so I can extract and manipulate the item statistics (specifically the r.drop)</span></span>
<span id="cb304-2"><a href="PCA.html#cb304-2" tabindex="-1"></a>AngryAlpha</span></code></pre></div>
<pre><code>
Reliability analysis   
Call: psych::alpha(x = Angry)

  raw_alpha std.alpha G6(smc) average_r  S/N   ase mean  sd median_r
      0.49      0.49    0.39      0.24 0.95 0.055  2.4 0.7     0.24

    95% confidence boundaries 
         lower alpha upper
Feldt     0.37  0.49  0.59
Duhachek  0.38  0.49  0.59

 Reliability if an item is dropped:
     raw_alpha std.alpha G6(smc) average_r  S/N alpha se var.r med.r
Ang1      0.40      0.40    0.25      0.25 0.67    0.074    NA  0.25
Ang2      0.37      0.38    0.23      0.23 0.60    0.077    NA  0.23
Ang3      0.39      0.39    0.24      0.24 0.63    0.076    NA  0.24

 Item statistics 
       n raw.r std.r r.cor r.drop mean   sd
Ang1 259  0.71  0.70  0.43   0.30  2.6 1.04
Ang2 259  0.72  0.71  0.45   0.31  2.3 1.05
Ang3 259  0.67  0.70  0.44   0.31  2.4 0.91

Non missing response frequency for each item
        0    1    2    3    4    5 miss
Ang1 0.02 0.14 0.31 0.36 0.15 0.03    0
Ang2 0.03 0.22 0.32 0.33 0.08 0.02    0
Ang3 0.02 0.13 0.39 0.38 0.07 0.01    0</code></pre>
<p>Alpha for the Angry Black Woman Stereotyps is 0.49.</p>
</div>
<div id="correlating-items-with-other-subscale-totals" class="section level4 hasAnchor" number="8.7.1.2">
<h4><span class="header-section-number">8.7.1.2</span> Correlating items with other subscale totals<a href="PCA.html#correlating-items-with-other-subscale-totals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="PCA.html#cb306-1" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">corr.test</span>(dfGRMS[<span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>,</span>
<span id="cb306-2"><a href="PCA.html#cb306-2" tabindex="-1"></a>    <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marginalized&quot;</span>, <span class="st">&quot;Strong&quot;</span>,</span>
<span id="cb306-3"><a href="PCA.html#cb306-3" tabindex="-1"></a>    <span class="st">&quot;Angry&quot;</span>)])</span>
<span id="cb306-4"><a href="PCA.html#cb306-4" tabindex="-1"></a>Obj_othR</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = dfGRMS[c(&quot;Obj1&quot;, &quot;Obj2&quot;, &quot;Obj3&quot;, &quot;Obj4&quot;, 
    &quot;Obj5&quot;, &quot;Obj6&quot;, &quot;Obj7&quot;, &quot;Obj8&quot;, &quot;Obj9&quot;, &quot;Obj10&quot;, &quot;Marginalized&quot;, 
    &quot;Strong&quot;, &quot;Angry&quot;)])
Correlation matrix 
             Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7 Obj8 Obj9 Obj10 Marginalized
Obj1         1.00 0.35 0.25 0.27 0.28 0.25 0.28 0.35 0.15  0.24         0.28
Obj2         0.35 1.00 0.31 0.25 0.27 0.23 0.31 0.28 0.26  0.24         0.35
Obj3         0.25 0.31 1.00 0.24 0.28 0.28 0.20 0.25 0.21  0.22         0.30
Obj4         0.27 0.25 0.24 1.00 0.39 0.23 0.28 0.30 0.26  0.28         0.33
Obj5         0.28 0.27 0.28 0.39 1.00 0.15 0.18 0.29 0.25  0.20         0.30
Obj6         0.25 0.23 0.28 0.23 0.15 1.00 0.20 0.14 0.21  0.12         0.22
Obj7         0.28 0.31 0.20 0.28 0.18 0.20 1.00 0.31 0.19  0.28         0.36
Obj8         0.35 0.28 0.25 0.30 0.29 0.14 0.31 1.00 0.19  0.23         0.31
Obj9         0.15 0.26 0.21 0.26 0.25 0.21 0.19 0.19 1.00  0.20         0.22
Obj10        0.24 0.24 0.22 0.28 0.20 0.12 0.28 0.23 0.20  1.00         0.22
Marginalized 0.28 0.35 0.30 0.33 0.30 0.22 0.36 0.31 0.22  0.22         1.00
Strong       0.27 0.24 0.25 0.18 0.26 0.17 0.26 0.14 0.20  0.17         0.34
Angry        0.15 0.16 0.13 0.14 0.15 0.18 0.24 0.05 0.11  0.14         0.38
             Strong Angry
Obj1           0.27  0.15
Obj2           0.24  0.16
Obj3           0.25  0.13
Obj4           0.18  0.14
Obj5           0.26  0.15
Obj6           0.17  0.18
Obj7           0.26  0.24
Obj8           0.14  0.05
Obj9           0.20  0.11
Obj10          0.17  0.14
Marginalized   0.34  0.38
Strong         1.00  0.30
Angry          0.30  1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
             Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7 Obj8 Obj9 Obj10 Marginalized
Obj1         0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.16  0.00         0.00
Obj2         0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  0.00         0.00
Obj3         0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 0.02  0.01         0.00
Obj4         0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00  0.00         0.00
Obj5         0.00 0.00 0.00 0.00 0.00 0.16 0.07 0.00 0.00  0.02         0.00
Obj6         0.00 0.00 0.00 0.00 0.01 0.00 0.03 0.18 0.02  0.18         0.01
Obj7         0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.04  0.00         0.00
Obj8         0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.04  0.01         0.00
Obj9         0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  0.03         0.01
Obj10        0.00 0.00 0.00 0.00 0.00 0.05 0.00 0.00 0.00  0.00         0.01
Marginalized 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  0.00         0.00
Strong       0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.02 0.00  0.01         0.00
Angry        0.02 0.01 0.04 0.03 0.02 0.00 0.00 0.40 0.08  0.03         0.00
             Strong Angry
Obj1           0.00  0.16
Obj2           0.00  0.12
Obj3           0.00  0.18
Obj4           0.06  0.18
Obj5           0.00  0.17
Obj6           0.09  0.05
Obj7           0.00  0.00
Obj8           0.18  0.40
Obj9           0.03  0.18
Obj10          0.09  0.18
Marginalized   0.00  0.00
Strong         0.00  0.00
Angry          0.00  0.00

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="PCA.html#cb308-1" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">corr.test</span>(dfGRMS[<span class="fu">c</span>(<span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>,</span>
<span id="cb308-2"><a href="PCA.html#cb308-2" tabindex="-1"></a>    <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Objectified&quot;</span>, <span class="st">&quot;Strong&quot;</span>, <span class="st">&quot;Angry&quot;</span>)])</span>
<span id="cb308-3"><a href="PCA.html#cb308-3" tabindex="-1"></a>Marg_othR</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = dfGRMS[c(&quot;Marg1&quot;, &quot;Marg2&quot;, &quot;Marg3&quot;, &quot;Marg4&quot;, 
    &quot;Marg5&quot;, &quot;Marg6&quot;, &quot;Marg7&quot;, &quot;Objectified&quot;, &quot;Strong&quot;, &quot;Angry&quot;)])
Correlation matrix 
            Marg1 Marg2 Marg3 Marg4 Marg5 Marg6 Marg7 Objectified Strong Angry
Marg1        1.00  0.43  0.41  0.38  0.41  0.35  0.31        0.33   0.21  0.28
Marg2        0.43  1.00  0.35  0.23  0.40  0.27  0.33        0.32   0.32  0.33
Marg3        0.41  0.35  1.00  0.32  0.25  0.25  0.20        0.30   0.22  0.23
Marg4        0.38  0.23  0.32  1.00  0.30  0.26  0.16        0.33   0.15  0.24
Marg5        0.41  0.40  0.25  0.30  1.00  0.29  0.28        0.36   0.26  0.22
Marg6        0.35  0.27  0.25  0.26  0.29  1.00  0.20        0.40   0.22  0.21
Marg7        0.31  0.33  0.20  0.16  0.28  0.20  1.00        0.25   0.13  0.19
Objectified  0.33  0.32  0.30  0.33  0.36  0.40  0.25        1.00   0.38  0.26
Strong       0.21  0.32  0.22  0.15  0.26  0.22  0.13        0.38   1.00  0.30
Angry        0.28  0.33  0.23  0.24  0.22  0.21  0.19        0.26   0.30  1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
            Marg1 Marg2 Marg3 Marg4 Marg5 Marg6 Marg7 Objectified Strong Angry
Marg1           0     0     0  0.00     0     0  0.00           0   0.01  0.00
Marg2           0     0     0  0.00     0     0  0.00           0   0.00  0.00
Marg3           0     0     0  0.00     0     0  0.01           0   0.00  0.00
Marg4           0     0     0  0.00     0     0  0.02           0   0.03  0.00
Marg5           0     0     0  0.00     0     0  0.00           0   0.00  0.00
Marg6           0     0     0  0.00     0     0  0.01           0   0.00  0.01
Marg7           0     0     0  0.01     0     0  0.00           0   0.04  0.01
Objectified     0     0     0  0.00     0     0  0.00           0   0.00  0.00
Strong          0     0     0  0.02     0     0  0.04           0   0.00  0.00
Angry           0     0     0  0.00     0     0  0.00           0   0.00  0.00

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="PCA.html#cb310-1" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">corr.test</span>(dfGRMS[<span class="fu">c</span>(<span class="st">&quot;Str1&quot;</span>, <span class="st">&quot;Str2&quot;</span>, <span class="st">&quot;Str3&quot;</span>, <span class="st">&quot;Str4&quot;</span>, <span class="st">&quot;Str5&quot;</span>,</span>
<span id="cb310-2"><a href="PCA.html#cb310-2" tabindex="-1"></a>    <span class="st">&quot;Objectified&quot;</span>, <span class="st">&quot;Marginalized&quot;</span>, <span class="st">&quot;Angry&quot;</span>)])</span>
<span id="cb310-3"><a href="PCA.html#cb310-3" tabindex="-1"></a>Str_othR</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = dfGRMS[c(&quot;Str1&quot;, &quot;Str2&quot;, &quot;Str3&quot;, &quot;Str4&quot;, 
    &quot;Str5&quot;, &quot;Objectified&quot;, &quot;Marginalized&quot;, &quot;Angry&quot;)])
Correlation matrix 
             Str1 Str2 Str3 Str4 Str5 Objectified Marginalized Angry
Str1         1.00 0.21 0.30 0.23 0.23        0.28         0.26  0.16
Str2         0.21 1.00 0.20 0.20 0.12        0.28         0.24  0.21
Str3         0.30 0.20 1.00 0.27 0.18        0.18         0.18  0.20
Str4         0.23 0.20 0.27 1.00 0.12        0.18         0.14  0.10
Str5         0.23 0.12 0.18 0.12 1.00        0.21         0.20  0.23
Objectified  0.28 0.28 0.18 0.18 0.21        1.00         0.51  0.26
Marginalized 0.26 0.24 0.18 0.14 0.20        0.51         1.00  0.38
Angry        0.16 0.21 0.20 0.10 0.23        0.26         0.38  1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
             Str1 Str2 Str3 Str4 Str5 Objectified Marginalized Angry
Str1         0.00 0.01 0.00 0.00 0.00        0.00         0.00  0.05
Str2         0.00 0.00 0.02 0.01 0.15        0.00         0.00  0.01
Str3         0.00 0.00 0.00 0.00 0.03        0.03         0.03  0.02
Str4         0.00 0.00 0.00 0.00 0.15        0.03         0.10  0.15
Str5         0.00 0.05 0.00 0.06 0.00        0.01         0.02  0.00
Objectified  0.00 0.00 0.00 0.00 0.00        0.00         0.00  0.00
Marginalized 0.00 0.00 0.00 0.02 0.00        0.00         0.00  0.00
Angry        0.01 0.00 0.00 0.11 0.00        0.00         0.00  0.00

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="PCA.html#cb312-1" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">corr.test</span>(dfGRMS[<span class="fu">c</span>(<span class="st">&quot;Ang1&quot;</span>, <span class="st">&quot;Ang2&quot;</span>, <span class="st">&quot;Ang3&quot;</span>, <span class="st">&quot;Objectified&quot;</span>,</span>
<span id="cb312-2"><a href="PCA.html#cb312-2" tabindex="-1"></a>    <span class="st">&quot;Marginalized&quot;</span>, <span class="st">&quot;Strong&quot;</span>)])</span>
<span id="cb312-3"><a href="PCA.html#cb312-3" tabindex="-1"></a>Ang_othR</span></code></pre></div>
<pre><code>Call:psych::corr.test(x = dfGRMS[c(&quot;Ang1&quot;, &quot;Ang2&quot;, &quot;Ang3&quot;, &quot;Objectified&quot;, 
    &quot;Marginalized&quot;, &quot;Strong&quot;)])
Correlation matrix 
             Ang1 Ang2 Ang3 Objectified Marginalized Strong
Ang1         1.00 0.24 0.23        0.16         0.25   0.31
Ang2         0.24 1.00 0.25        0.15         0.28   0.15
Ang3         0.23 0.25 1.00        0.23         0.28   0.18
Objectified  0.16 0.15 0.23        1.00         0.51   0.38
Marginalized 0.25 0.28 0.28        0.51         1.00   0.34
Strong       0.31 0.15 0.18        0.38         0.34   1.00
Sample Size 
[1] 259
Probability values (Entries above the diagonal are adjusted for multiple tests.) 
             Ang1 Ang2 Ang3 Objectified Marginalized Strong
Ang1         0.00 0.00    0        0.02            0   0.00
Ang2         0.00 0.00    0        0.03            0   0.03
Ang3         0.00 0.00    0        0.00            0   0.01
Objectified  0.01 0.01    0        0.00            0   0.00
Marginalized 0.00 0.00    0        0.00            0   0.00
Strong       0.00 0.02    0        0.00            0   0.00

 To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
</div>
<div id="exctracting-values-binding-them-together-and-joining-the-files" class="section level4 hasAnchor" number="8.7.1.3">
<h4><span class="header-section-number">8.7.1.3</span> Exctracting values, binding them together, and joining the files<a href="PCA.html#exctracting-values-binding-them-together-and-joining-the-files" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="PCA.html#cb314-1" tabindex="-1"></a><span class="co"># names(Obj_other) Extracting the item-level statistics from the</span></span>
<span id="cb314-2"><a href="PCA.html#cb314-2" tabindex="-1"></a><span class="co"># alpha object</span></span>
<span id="cb314-3"><a href="PCA.html#cb314-3" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(Obj_othR<span class="sc">$</span>r)  <span class="co">#Makes the item-total(other) correlation matrix a df</span></span>
<span id="cb314-4"><a href="PCA.html#cb314-4" tabindex="-1"></a><span class="co"># Adding variable names so we don&#39;t get lost</span></span>
<span id="cb314-5"><a href="PCA.html#cb314-5" tabindex="-1"></a>Obj_othR<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>,</span>
<span id="cb314-6"><a href="PCA.html#cb314-6" tabindex="-1"></a>    <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marginalized&quot;</span>, <span class="st">&quot;Strong&quot;</span>, <span class="st">&quot;Angry&quot;</span>)</span>
<span id="cb314-7"><a href="PCA.html#cb314-7" tabindex="-1"></a><span class="co"># deleting the ROWS with the total scale scores (the columns)</span></span>
<span id="cb314-8"><a href="PCA.html#cb314-8" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> Obj_othR[<span class="sc">!</span>Obj_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Marginalized&quot;</span>, ]</span>
<span id="cb314-9"><a href="PCA.html#cb314-9" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> Obj_othR[<span class="sc">!</span>Obj_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Strong&quot;</span>, ]</span>
<span id="cb314-10"><a href="PCA.html#cb314-10" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> Obj_othR[<span class="sc">!</span>Obj_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Angry&quot;</span>, ]</span>
<span id="cb314-11"><a href="PCA.html#cb314-11" tabindex="-1"></a>Obj_othR[, <span class="st">&quot;Objectified&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co">#We need a column for this to bind the items, later.</span></span>
<span id="cb314-12"><a href="PCA.html#cb314-12" tabindex="-1"></a>Obj_othR <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(Obj_othR, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-13"><a href="PCA.html#cb314-13" tabindex="-1"></a>    Angry)  <span class="co">#Putting items in order</span></span>
<span id="cb314-14"><a href="PCA.html#cb314-14" tabindex="-1"></a><span class="co"># Item Corrected Total Correlations</span></span>
<span id="cb314-15"><a href="PCA.html#cb314-15" tabindex="-1"></a>ObjAlpha <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(ObjAlpha<span class="sc">$</span>item.stats)  <span class="co">#Grabbing the alpha object we created earlier and making it a df </span></span>
<span id="cb314-16"><a href="PCA.html#cb314-16" tabindex="-1"></a>ObjAlpha<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>,</span>
<span id="cb314-17"><a href="PCA.html#cb314-17" tabindex="-1"></a>    <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>)</span>
<span id="cb314-18"><a href="PCA.html#cb314-18" tabindex="-1"></a><span class="co"># Joining the two and selecting the vars of interest</span></span>
<span id="cb314-19"><a href="PCA.html#cb314-19" tabindex="-1"></a>ObjStats <span class="ot">&lt;-</span> <span class="fu">full_join</span>(ObjAlpha, Obj_othR, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb314-20"><a href="PCA.html#cb314-20" tabindex="-1"></a>ObjStats<span class="sc">$</span>Objectified <span class="ot">&lt;-</span> ObjStats<span class="sc">$</span>r.drop  <span class="co">#Copy the item-corrected total (r.drop) into the Objectified variable</span></span>
<span id="cb314-21"><a href="PCA.html#cb314-21" tabindex="-1"></a>ObjStats <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(ObjStats, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-22"><a href="PCA.html#cb314-22" tabindex="-1"></a>    Angry)</span>
<span id="cb314-23"><a href="PCA.html#cb314-23" tabindex="-1"></a><span class="co"># rm(ObjAlpha, Obj_othR) #It&#39;s messay, dropping all the</span></span>
<span id="cb314-24"><a href="PCA.html#cb314-24" tabindex="-1"></a><span class="co"># no-longer-necessary objects from the Global Environment</span></span>
<span id="cb314-25"><a href="PCA.html#cb314-25" tabindex="-1"></a></span>
<span id="cb314-26"><a href="PCA.html#cb314-26" tabindex="-1"></a></span>
<span id="cb314-27"><a href="PCA.html#cb314-27" tabindex="-1"></a><span class="co"># Extracting the item-level statistics from the alpha object</span></span>
<span id="cb314-28"><a href="PCA.html#cb314-28" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(Marg_othR<span class="sc">$</span>r)  <span class="co">#Makes the item-total(other) correlation matrix a df</span></span>
<span id="cb314-29"><a href="PCA.html#cb314-29" tabindex="-1"></a><span class="co"># Adding variable names so we don&#39;t get lost</span></span>
<span id="cb314-30"><a href="PCA.html#cb314-30" tabindex="-1"></a>Marg_othR<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>, <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>,</span>
<span id="cb314-31"><a href="PCA.html#cb314-31" tabindex="-1"></a>    <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Objectified&quot;</span>, <span class="st">&quot;Strong&quot;</span>, <span class="st">&quot;Angry&quot;</span>)</span>
<span id="cb314-32"><a href="PCA.html#cb314-32" tabindex="-1"></a><span class="co"># deleting the rows with the total scale scores</span></span>
<span id="cb314-33"><a href="PCA.html#cb314-33" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> Marg_othR[<span class="sc">!</span>Marg_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Objectified&quot;</span>, ]</span>
<span id="cb314-34"><a href="PCA.html#cb314-34" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> Marg_othR[<span class="sc">!</span>Marg_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Strong&quot;</span>, ]</span>
<span id="cb314-35"><a href="PCA.html#cb314-35" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> Marg_othR[<span class="sc">!</span>Marg_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Angry&quot;</span>, ]</span>
<span id="cb314-36"><a href="PCA.html#cb314-36" tabindex="-1"></a>Marg_othR[, <span class="st">&quot;Marginalized&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span>  <span class="co">#We need a column for this to bind the items, later.</span></span>
<span id="cb314-37"><a href="PCA.html#cb314-37" tabindex="-1"></a>Marg_othR <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(Marg_othR, Items, Objectified, Marginalized,</span>
<span id="cb314-38"><a href="PCA.html#cb314-38" tabindex="-1"></a>    Strong, Angry)</span>
<span id="cb314-39"><a href="PCA.html#cb314-39" tabindex="-1"></a><span class="co"># Item Corrected Total Correlations</span></span>
<span id="cb314-40"><a href="PCA.html#cb314-40" tabindex="-1"></a>MargAlpha <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(MargAlpha<span class="sc">$</span>item.stats)  <span class="co">#Grabbing the alpha objet we created earlier and making it a df  </span></span>
<span id="cb314-41"><a href="PCA.html#cb314-41" tabindex="-1"></a>MargAlpha<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>, <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>,</span>
<span id="cb314-42"><a href="PCA.html#cb314-42" tabindex="-1"></a>    <span class="st">&quot;Marg7&quot;</span>)</span>
<span id="cb314-43"><a href="PCA.html#cb314-43" tabindex="-1"></a><span class="co"># Joining the two and selecting the vars of interest</span></span>
<span id="cb314-44"><a href="PCA.html#cb314-44" tabindex="-1"></a>MargStats <span class="ot">&lt;-</span> <span class="fu">full_join</span>(MargAlpha, Marg_othR, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb314-45"><a href="PCA.html#cb314-45" tabindex="-1"></a>MargStats<span class="sc">$</span>Marginalized <span class="ot">&lt;-</span> MargStats<span class="sc">$</span>r.drop  <span class="co">#Copy the item-corrected total (r.drop) into the Marginalized variable</span></span>
<span id="cb314-46"><a href="PCA.html#cb314-46" tabindex="-1"></a>MargStats <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(MargStats, Items, Objectified, Marginalized,</span>
<span id="cb314-47"><a href="PCA.html#cb314-47" tabindex="-1"></a>    Strong, Angry)</span>
<span id="cb314-48"><a href="PCA.html#cb314-48" tabindex="-1"></a><span class="co"># rm(MargAlpha, Marg_othR) #It&#39;s messay, dropping all the</span></span>
<span id="cb314-49"><a href="PCA.html#cb314-49" tabindex="-1"></a><span class="co"># no-longer-necessary objects from the Global Environment</span></span>
<span id="cb314-50"><a href="PCA.html#cb314-50" tabindex="-1"></a></span>
<span id="cb314-51"><a href="PCA.html#cb314-51" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(Str_othR<span class="sc">$</span>r)  <span class="co">#Makes the item-total(other) correlation matrix a df</span></span>
<span id="cb314-52"><a href="PCA.html#cb314-52" tabindex="-1"></a><span class="co"># Adding variable names so we don&#39;t get lost</span></span>
<span id="cb314-53"><a href="PCA.html#cb314-53" tabindex="-1"></a>Str_othR<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>, <span class="st">&quot;Strong5&quot;</span>,</span>
<span id="cb314-54"><a href="PCA.html#cb314-54" tabindex="-1"></a>    <span class="st">&quot;Objectified&quot;</span>, <span class="st">&quot;Marginalized&quot;</span>, <span class="st">&quot;Angry&quot;</span>)</span>
<span id="cb314-55"><a href="PCA.html#cb314-55" tabindex="-1"></a><span class="co"># deleting the rows with the total scale scores</span></span>
<span id="cb314-56"><a href="PCA.html#cb314-56" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> Str_othR[<span class="sc">!</span>Str_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Objectified&quot;</span>, ]</span>
<span id="cb314-57"><a href="PCA.html#cb314-57" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> Str_othR[<span class="sc">!</span>Str_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Marginalized&quot;</span>, ]</span>
<span id="cb314-58"><a href="PCA.html#cb314-58" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> Str_othR[<span class="sc">!</span>Str_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Angry&quot;</span>, ]</span>
<span id="cb314-59"><a href="PCA.html#cb314-59" tabindex="-1"></a>Str_othR[, <span class="st">&quot;Strong&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb314-60"><a href="PCA.html#cb314-60" tabindex="-1"></a>Str_othR <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(Str_othR, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-61"><a href="PCA.html#cb314-61" tabindex="-1"></a>    Angry)</span>
<span id="cb314-62"><a href="PCA.html#cb314-62" tabindex="-1"></a><span class="co"># Item Corrected Total Correlations</span></span>
<span id="cb314-63"><a href="PCA.html#cb314-63" tabindex="-1"></a>StrongAlpha <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(StrongAlpha<span class="sc">$</span>item.stats)  <span class="co">#Grabbing the alpha objet we created earlier and making it a df  </span></span>
<span id="cb314-64"><a href="PCA.html#cb314-64" tabindex="-1"></a>StrongAlpha<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>, <span class="st">&quot;Strong5&quot;</span>)</span>
<span id="cb314-65"><a href="PCA.html#cb314-65" tabindex="-1"></a><span class="co"># Joining the two and selecting the vars of interest</span></span>
<span id="cb314-66"><a href="PCA.html#cb314-66" tabindex="-1"></a>StrStats <span class="ot">&lt;-</span> <span class="fu">full_join</span>(StrongAlpha, Str_othR, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb314-67"><a href="PCA.html#cb314-67" tabindex="-1"></a>StrStats<span class="sc">$</span>Strong <span class="ot">&lt;-</span> StrStats<span class="sc">$</span>r.drop  <span class="co">#Copy the item-corrected total (r.drop) into the Strong variable</span></span>
<span id="cb314-68"><a href="PCA.html#cb314-68" tabindex="-1"></a>StrStats <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(StrStats, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-69"><a href="PCA.html#cb314-69" tabindex="-1"></a>    Angry)</span>
<span id="cb314-70"><a href="PCA.html#cb314-70" tabindex="-1"></a><span class="fu">rm</span>(StrongAlpha, Str_othR)  <span class="co">#It&#39;s messay, dropping all the no-longer-necessary objects from the Global Environment</span></span>
<span id="cb314-71"><a href="PCA.html#cb314-71" tabindex="-1"></a></span>
<span id="cb314-72"><a href="PCA.html#cb314-72" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(Ang_othR<span class="sc">$</span>r)  <span class="co">#Makes the item-total(other) correlation matrix a df</span></span>
<span id="cb314-73"><a href="PCA.html#cb314-73" tabindex="-1"></a><span class="co"># Adding variable names so we don&#39;t get lost</span></span>
<span id="cb314-74"><a href="PCA.html#cb314-74" tabindex="-1"></a>Ang_othR<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>, <span class="st">&quot;Objectified&quot;</span>, <span class="st">&quot;Marginalized&quot;</span>,</span>
<span id="cb314-75"><a href="PCA.html#cb314-75" tabindex="-1"></a>    <span class="st">&quot;Strong&quot;</span>)</span>
<span id="cb314-76"><a href="PCA.html#cb314-76" tabindex="-1"></a><span class="co"># deleting the rows with the total scale scores</span></span>
<span id="cb314-77"><a href="PCA.html#cb314-77" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> Ang_othR[<span class="sc">!</span>Ang_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Objectified&quot;</span>, ]</span>
<span id="cb314-78"><a href="PCA.html#cb314-78" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> Ang_othR[<span class="sc">!</span>Ang_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Marginalized&quot;</span>, ]</span>
<span id="cb314-79"><a href="PCA.html#cb314-79" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> Ang_othR[<span class="sc">!</span>Ang_othR<span class="sc">$</span>Items <span class="sc">==</span> <span class="st">&quot;Strong&quot;</span>, ]</span>
<span id="cb314-80"><a href="PCA.html#cb314-80" tabindex="-1"></a>Ang_othR[, <span class="st">&quot;Angry&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb314-81"><a href="PCA.html#cb314-81" tabindex="-1"></a>Ang_othR <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(Ang_othR, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-82"><a href="PCA.html#cb314-82" tabindex="-1"></a>    Angry)</span>
<span id="cb314-83"><a href="PCA.html#cb314-83" tabindex="-1"></a><span class="co"># Item Corrected Total Correlations</span></span>
<span id="cb314-84"><a href="PCA.html#cb314-84" tabindex="-1"></a>AngryAlpha <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(AngryAlpha<span class="sc">$</span>item.stats)  <span class="co">#Grabbing the alpha objet we created earlier and making it a df  </span></span>
<span id="cb314-85"><a href="PCA.html#cb314-85" tabindex="-1"></a>AngryAlpha<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)</span>
<span id="cb314-86"><a href="PCA.html#cb314-86" tabindex="-1"></a><span class="co"># Joining the two and selecting the vars of interest</span></span>
<span id="cb314-87"><a href="PCA.html#cb314-87" tabindex="-1"></a>AngStats <span class="ot">&lt;-</span> <span class="fu">full_join</span>(AngryAlpha, Ang_othR, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb314-88"><a href="PCA.html#cb314-88" tabindex="-1"></a>AngStats<span class="sc">$</span>Angry <span class="ot">&lt;-</span> AngStats<span class="sc">$</span>r.drop  <span class="co">#Copy the item-corrected total (r.drop) into the Angry variable</span></span>
<span id="cb314-89"><a href="PCA.html#cb314-89" tabindex="-1"></a>AngStats <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(AngStats, Items, Objectified, Marginalized, Strong,</span>
<span id="cb314-90"><a href="PCA.html#cb314-90" tabindex="-1"></a>    Angry)</span>
<span id="cb314-91"><a href="PCA.html#cb314-91" tabindex="-1"></a><span class="fu">rm</span>(AngryAlpha, Ang_othR)  <span class="co">#It&#39;s messay, dropping all the no-longer-necessary objects from the Global Environment</span></span>
<span id="cb314-92"><a href="PCA.html#cb314-92" tabindex="-1"></a></span>
<span id="cb314-93"><a href="PCA.html#cb314-93" tabindex="-1"></a><span class="co"># Adding all the variables into a single table</span></span>
<span id="cb314-94"><a href="PCA.html#cb314-94" tabindex="-1"></a>ItemAnalysis <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ObjStats, MargStats, StrStats, AngStats)</span>
<span id="cb314-95"><a href="PCA.html#cb314-95" tabindex="-1"></a></span>
<span id="cb314-96"><a href="PCA.html#cb314-96" tabindex="-1"></a><span class="co"># Preparing and adding the r.drop for total scale score</span></span>
<span id="cb314-97"><a href="PCA.html#cb314-97" tabindex="-1"></a>TotAlpha <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(GRMSalpha<span class="sc">$</span>item.stats)</span>
<span id="cb314-98"><a href="PCA.html#cb314-98" tabindex="-1"></a>TotAlpha<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>, <span class="st">&quot;Obj7&quot;</span>,</span>
<span id="cb314-99"><a href="PCA.html#cb314-99" tabindex="-1"></a>    <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>, <span class="st">&quot;Marg5&quot;</span>,</span>
<span id="cb314-100"><a href="PCA.html#cb314-100" tabindex="-1"></a>    <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>, <span class="st">&quot;Strong5&quot;</span>,</span>
<span id="cb314-101"><a href="PCA.html#cb314-101" tabindex="-1"></a>    <span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)</span>
<span id="cb314-102"><a href="PCA.html#cb314-102" tabindex="-1"></a>TotAlpha <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(TotAlpha, Items, r.drop)  <span class="co">#deleting the rows with the total scale scores</span></span>
<span id="cb314-103"><a href="PCA.html#cb314-103" tabindex="-1"></a></span>
<span id="cb314-104"><a href="PCA.html#cb314-104" tabindex="-1"></a></span>
<span id="cb314-105"><a href="PCA.html#cb314-105" tabindex="-1"></a><span class="co"># Adding the r.drop for the total scale score</span></span>
<span id="cb314-106"><a href="PCA.html#cb314-106" tabindex="-1"></a>ItemAnalysis <span class="ot">&lt;-</span> <span class="fu">full_join</span>(TotAlpha, ItemAnalysis, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)</span>
<span id="cb314-107"><a href="PCA.html#cb314-107" tabindex="-1"></a></span>
<span id="cb314-108"><a href="PCA.html#cb314-108" tabindex="-1"></a><span class="co"># Adding the values from the orthogonal rotation I had to add</span></span>
<span id="cb314-109"><a href="PCA.html#cb314-109" tabindex="-1"></a><span class="co"># &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb314-110"><a href="PCA.html#cb314-110" tabindex="-1"></a>pcaORTH_loadings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">unclass</span>(pcaORTH<span class="sc">$</span>loadings))</span>
<span id="cb314-111"><a href="PCA.html#cb314-111" tabindex="-1"></a><span class="co"># Item names for joining (and to make sure we know which variable is</span></span>
<span id="cb314-112"><a href="PCA.html#cb314-112" tabindex="-1"></a><span class="co"># which)</span></span>
<span id="cb314-113"><a href="PCA.html#cb314-113" tabindex="-1"></a>pcaORTH_loadings<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>,</span>
<span id="cb314-114"><a href="PCA.html#cb314-114" tabindex="-1"></a>    <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>,</span>
<span id="cb314-115"><a href="PCA.html#cb314-115" tabindex="-1"></a>    <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>,</span>
<span id="cb314-116"><a href="PCA.html#cb314-116" tabindex="-1"></a>    <span class="st">&quot;Strong5&quot;</span>, <span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)</span>
<span id="cb314-117"><a href="PCA.html#cb314-117" tabindex="-1"></a></span>
<span id="cb314-118"><a href="PCA.html#cb314-118" tabindex="-1"></a><span class="co"># Deleting those lower rows</span></span>
<span id="cb314-119"><a href="PCA.html#cb314-119" tabindex="-1"></a>pcaORTH_loadings <span class="ot">&lt;-</span> <span class="fu">rename</span>(pcaORTH_loadings, <span class="at">objORTH =</span> RC1, <span class="at">margORTH =</span> RC2,</span>
<span id="cb314-120"><a href="PCA.html#cb314-120" tabindex="-1"></a>    <span class="at">strORTH =</span> RC3, <span class="at">angORTH2 =</span> RC4)</span>
<span id="cb314-121"><a href="PCA.html#cb314-121" tabindex="-1"></a></span>
<span id="cb314-122"><a href="PCA.html#cb314-122" tabindex="-1"></a><span class="co"># Joining with the Item Stats</span></span>
<span id="cb314-123"><a href="PCA.html#cb314-123" tabindex="-1"></a>Comparisons <span class="ot">&lt;-</span> <span class="fu">full_join</span>(ItemAnalysis, pcaORTH_loadings, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)  <span class="co">#I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb314-124"><a href="PCA.html#cb314-124" tabindex="-1"></a></span>
<span id="cb314-125"><a href="PCA.html#cb314-125" tabindex="-1"></a><span class="co"># Adding the oblique loadings</span></span>
<span id="cb314-126"><a href="PCA.html#cb314-126" tabindex="-1"></a>pcaOBLQ_loadings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">unclass</span>(pcaOBL<span class="sc">$</span>loadings))  <span class="co">#I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb314-127"><a href="PCA.html#cb314-127" tabindex="-1"></a>pcaOBLQ_loadings<span class="sc">$</span>Items <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Obj1&quot;</span>, <span class="st">&quot;Obj2&quot;</span>, <span class="st">&quot;Obj3&quot;</span>, <span class="st">&quot;Obj4&quot;</span>, <span class="st">&quot;Obj5&quot;</span>, <span class="st">&quot;Obj6&quot;</span>,</span>
<span id="cb314-128"><a href="PCA.html#cb314-128" tabindex="-1"></a>    <span class="st">&quot;Obj7&quot;</span>, <span class="st">&quot;Obj8&quot;</span>, <span class="st">&quot;Obj9&quot;</span>, <span class="st">&quot;Obj10&quot;</span>, <span class="st">&quot;Marg1&quot;</span>, <span class="st">&quot;Marg2&quot;</span>, <span class="st">&quot;Marg3&quot;</span>, <span class="st">&quot;Marg4&quot;</span>,</span>
<span id="cb314-129"><a href="PCA.html#cb314-129" tabindex="-1"></a>    <span class="st">&quot;Marg5&quot;</span>, <span class="st">&quot;Marg6&quot;</span>, <span class="st">&quot;Marg7&quot;</span>, <span class="st">&quot;Strong1&quot;</span>, <span class="st">&quot;Strong2&quot;</span>, <span class="st">&quot;Strong3&quot;</span>, <span class="st">&quot;Strong4&quot;</span>,</span>
<span id="cb314-130"><a href="PCA.html#cb314-130" tabindex="-1"></a>    <span class="st">&quot;Strong5&quot;</span>, <span class="st">&quot;Angry1&quot;</span>, <span class="st">&quot;Angry2&quot;</span>, <span class="st">&quot;Angry3&quot;</span>)  <span class="co">#Item names for joining (and to make sure we know which variable is which)</span></span>
<span id="cb314-131"><a href="PCA.html#cb314-131" tabindex="-1"></a><span class="co"># Deleting those lower rows pcaOBLQ_loadings &lt;-</span></span>
<span id="cb314-132"><a href="PCA.html#cb314-132" tabindex="-1"></a><span class="co"># pcaOBLQ_loadings[!pcaORTH_loadings$Items == &#39;GRMSTot&#39;,]</span></span>
<span id="cb314-133"><a href="PCA.html#cb314-133" tabindex="-1"></a><span class="co"># pcaOBLQ_loadings &lt;- pcaOBLQ_loadings[!pcaORTH_loadings$Items ==</span></span>
<span id="cb314-134"><a href="PCA.html#cb314-134" tabindex="-1"></a><span class="co"># &#39;Objectified&#39;,] pcaOBLQ_loadings &lt;-</span></span>
<span id="cb314-135"><a href="PCA.html#cb314-135" tabindex="-1"></a><span class="co"># pcaOBLQ_loadings[!pcaORTH_loadings$Items == &#39;Marginalized&#39;,]</span></span>
<span id="cb314-136"><a href="PCA.html#cb314-136" tabindex="-1"></a><span class="co"># pcaOBLQ_loadings &lt;- pcaOBLQ_loadings[!pcaORTH_loadings$Items ==</span></span>
<span id="cb314-137"><a href="PCA.html#cb314-137" tabindex="-1"></a><span class="co"># &#39;Strong&#39;,] pcaOBLQ_loadings &lt;-</span></span>
<span id="cb314-138"><a href="PCA.html#cb314-138" tabindex="-1"></a><span class="co"># pcaOBLQ_loadings[!pcaORTH_loadings$Items == &#39;Angry&#39;,]</span></span>
<span id="cb314-139"><a href="PCA.html#cb314-139" tabindex="-1"></a>pcaOBLQ_loadings <span class="ot">&lt;-</span> <span class="fu">rename</span>(pcaOBLQ_loadings, <span class="at">margOBLQ =</span> TC1, <span class="at">objOBLQ =</span> TC2,</span>
<span id="cb314-140"><a href="PCA.html#cb314-140" tabindex="-1"></a>    <span class="at">strOBLQ =</span> TC3, <span class="at">angOBLQ =</span> TC4)</span>
<span id="cb314-141"><a href="PCA.html#cb314-141" tabindex="-1"></a></span>
<span id="cb314-142"><a href="PCA.html#cb314-142" tabindex="-1"></a><span class="co"># Joining with the Item Stats</span></span>
<span id="cb314-143"><a href="PCA.html#cb314-143" tabindex="-1"></a>Comparisons <span class="ot">&lt;-</span> <span class="fu">full_join</span>(Comparisons, pcaOBLQ_loadings, <span class="at">by =</span> <span class="st">&quot;Items&quot;</span>)  <span class="co">#I had to add &#39;unclass&#39; to the loadings to render them into a df</span></span>
<span id="cb314-144"><a href="PCA.html#cb314-144" tabindex="-1"></a></span>
<span id="cb314-145"><a href="PCA.html#cb314-145" tabindex="-1"></a><span class="fu">write.csv</span>(Comparisons, <span class="at">file =</span> <span class="st">&quot;GRMS_Comparisons.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">row.names =</span> <span class="cn">FALSE</span>,</span>
<span id="cb314-146"><a href="PCA.html#cb314-146" tabindex="-1"></a>    <span class="at">col.names =</span> <span class="cn">TRUE</span>)  <span class="co">#Writes the table to a .csv file where you can open it with Excel and format</span></span></code></pre></div>
<pre><code>Warning in write.csv(Comparisons, file = &quot;GRMS_Comparisons.csv&quot;, sep = &quot;,&quot;, :
attempt to set &#39;col.names&#39; ignored</code></pre>
<pre><code>Warning in write.csv(Comparisons, file = &quot;GRMS_Comparisons.csv&quot;, sep = &quot;,&quot;, :
attempt to set &#39;sep&#39; ignored</code></pre>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="PCA.html#cb317-1" tabindex="-1"></a><span class="fu">saveRDS</span>(Comparisons, <span class="st">&quot;GRMS_Comparisons.rds&quot;</span>)  <span class="co">#Writes the file as an .rds so that if anything is specially formatted, it is retained</span></span></code></pre></div>
</div>
<div id="interpreting-the-result" class="section level4 hasAnchor" number="8.7.1.4">
<h4><span class="header-section-number">8.7.1.4</span> Interpreting the result<a href="PCA.html#interpreting-the-result" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The result of this work is a table that includes:</p>
<ul>
<li><strong>r.drop</strong> Corrected item-total (entire GRMS) coefficients</li>
<li><strong>Item-total correlations</strong> of the items correlated with their own subscale (bold; correlation does not include the item being correlated) and the other subscales</li>
<li><strong>PCA: Orthogonal rotation</strong> factor loadings of the four-scales with a rotation that maximizes the independents (uncorrelatedness) of the scales</li>
<li><strong>PCA: Oblique rotation</strong> factor loadings of the four-scales with a rotation that permits correlation between subscales</li>
</ul>
<div class="float" id="id">
<img src="images/PCA/ComparisonsTable.png" class="class" width="600" height="400" alt="Image of a table of values from the item analysis and PCA solutions with orthogonal and oblique rotations" />
<div class="figcaption">Image of a table of values from the item analysis and PCA solutions with orthogonal and oblique rotations</div>
</div>
<p>We expect to see similar results across the item-analysis, PCA orthogonal, and PCA oblique solutions. Our biggest interest is in whether items change scale membership and/or have cross-loadings. Overall, we are looking for items that <em>load</em> higher on their own scales than they do on other scales.</p>
<ul>
<li>When there are a number of cross-loadings, it means that the item will not discriminate well (think within-in scale discriminant validity).</li>
<li>If there are a number of cross-loadings, there will likely be stronger correlations between subscales (indicating that an oblique rotation is/was an appropriate choice).</li>
<li>Low/no cross-loadings, supports the choices of an orthogonal (uncorrelated) solution.</li>
<li>Within-scale convergent validity is supported when an item has a strong, positive loading on its own scale and low/zero loadings on the other scales..</li>
</ul>
<p>Our simulation from the Lewis and Neville’s <span class="citation">(<a href="#ref-lewis_construction_2015">2015</a>)</span> GRMS produced slightly different results from their original data. Specifically, our “Angry1” item cross-loaded on both the Strong Angry subscales with slightly stronger loadings on the Strong (incorrect) subscale.The items behaved much better in the original article.</p>
</div>
</div>
</div>
<div id="practice-problems-6" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Practice Problems<a href="PCA.html#practice-problems-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In each of these lessons I provide suggestions for practice that allow you to select one or more problems that are graded in difficulty. In psychometrics, I strongly recommend that you have started with a dataset that has a minimum of three subscales and use it for all of the assignments in the OER. In any case, please plan to:</p>
<ul>
<li>Properly format and prepare the data.</li>
<li>Conduct diagnostic tests to determine the suitability of the data for PCA.</li>
<li>Conduct tests to guide the decisions about number of components to extract.</li>
<li>Conduct orthogonal and oblique rotations (at least two each with different numbers of extracted components).</li>
<li>Select one solution and preparing an APA style results section (with table and figure).</li>
</ul>
<div id="problem-1-play-around-with-this-simulation.-3" class="section level3 hasAnchor" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> Problem #1: Play around with this simulation.<a href="PCA.html#problem-1-play-around-with-this-simulation.-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Copy the script for the simulation and then change (at least) one thing in the simulation to see how it impacts the results. If PCA is new to you, perhaps you just change the number in “set.seed(240311)” from 240311 to something else. Your results should <em>parallel</em> those obtained in the lecture, making it easier for you to check your work as you go. Don’t be surprised if the factor loadings wiggle around a little. Do try to make sense of them.</p>
</div>
<div id="problem-2-conduct-a-pca-with-another-simulated-set-of-data-in-the-oer." class="section level3 hasAnchor" number="8.8.2">
<h3><span class="header-section-number">8.8.2</span> Problem #2: Conduct a PCA with another simulated set of data in the OER.<a href="PCA.html#problem-2-conduct-a-pca-with-another-simulated-set-of-data-in-the-oer." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The second option involves utilizing one of the simulated datasets available in this OER. The <a href="sims.html#sims">last lesson</a> in the OER contains three simulations that could be used for all of the statistics-based practice suggestions. Especially if you started with one of these examples in an earlier lesson, I highly recommend you continue with that.</p>
<p>Alternatively, Keum et al.’s Gendered Racial Microaggressions Scale for Asian American Women <span class="citation">(<a href="#ref-keum_gendered_2018">Keum et al., 2018</a>)</span> will be used in the lessons on confirmatory factor analysis and Conover et al.’s <span class="citation">(<a href="#ref-conover_development_2017">Conover et al., 2017</a>)</span> Ableist Microaggressions Scale is used in the lesson on invariance testing. Both of these would be suitable for the PCA and PAF homework assignments.</p>
</div>
<div id="problem-3-try-something-entirely-new.-3" class="section level3 hasAnchor" number="8.8.3">
<h3><span class="header-section-number">8.8.3</span> Problem #3: Try something entirely new.<a href="PCA.html#problem-3-try-something-entirely-new.-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from the ReCentering Psych Stats survey described in the <a href="#qualTRIXdata">Qualtrics lesson</a>, or data from an open science repository), complete a PCA analysis. The data should allow for at least three factors/subscales.</p>
</div>
<div id="grading-rubric-3" class="section level3 hasAnchor" number="8.8.4">
<h3><span class="header-section-number">8.8.4</span> Grading Rubric<a href="PCA.html#grading-rubric-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using the lecture and workflow (chart) as a guide, please work through all the steps listed in the proposed assignment/grading rubric.</p>
<table>
<colgroup>
<col width="54%" />
<col width="25%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Check and, if needed, format data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Determine how many components to extract (e.g., scree plot, eigenvalues, theory).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Conduct an orthogonal rotation with a minimum of two different numbers of component extractions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Conduct an oblique rotation with a minimum of two different numbers of component extractions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Determine which factor solution (e.g., orthogonal or oblique; with which number of components) you will suggest.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. APA style results section with table and figure of one of the solutions.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="homeworked-example-3" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Homeworked Example<a href="PCA.html#homeworked-example-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="https://youtu.be/LPtAwkICR0w">Screencast Link</a></p>
<p>For more information about the data used in this homeworked example, please refer to the description and codebook located at the end of the <a href="https://lhbikos.github.io/ReCenterPsychStats/ReCintro.html#introduction-to-the-data-set-used-for-homeworked-examples">introduction</a> in first volume of ReCentering Psych Stats.</p>
<p>As a brief review, this data is part of an IRB-approved study, with consent to use in teaching demonstrations and to be made available to the general public via the open science framework. Hence, it is appropriate to use in this context. You will notice there are student- and teacher- IDs. These numbers are not actual student and teacher IDs, rather they were further re-identified so that they could not be connected to actual people.</p>
<p>Because this is an actual dataset, if you wish to work the problem along with me, you will need to download the <a href="https://github.com/lhbikos/ReC_Psychometrics/blob/main/Worked_Examples/ReC.rds">ReC.rds</a> data file from the Worked_Examples folder in the ReC_Psychometrics project on the GitHub.</p>
<p>The course evaluation items can be divided into three subscales:</p>
<ul>
<li><strong>Valued by the student</strong> includes the items: ValObjectives, IncrUnderstanding, IncrInterest</li>
<li><strong>Traditional pedagogy</strong> includes the items: ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation</li>
<li><strong>Socially responsive pedagogy</strong> includes the items: InclusvClassrm, EquitableEval, MultPerspectives, DEIintegration</li>
</ul>
<p>In this homewoRked example I will conduct a principal components analysis. My hope is that the results will support my solution of three dimensions: valued-by-the-student, traditional pedagogy, socially responsive pedagogy.</p>
<div id="check-and-if-needed-format-data-1" class="section level3 hasAnchor" number="8.9.1">
<h3><span class="header-section-number">8.9.1</span> Check and, if needed, format data<a href="PCA.html#check-and-if-needed-format-data-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="PCA.html#cb318-1" tabindex="-1"></a>big <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;ReC.rds&quot;</span>)</span></code></pre></div>
<p>With the next code I will create an item-level df with only the items used in the three scales.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="PCA.html#cb319-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb319-2"><a href="PCA.html#cb319-2" tabindex="-1"></a>items <span class="ot">&lt;-</span> big <span class="sc">%&gt;%</span></span>
<span id="cb319-3"><a href="PCA.html#cb319-3" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(ValObjectives, IncrUnderstanding, IncrInterest, ClearResponsibilities,</span>
<span id="cb319-4"><a href="PCA.html#cb319-4" tabindex="-1"></a>        EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation,</span>
<span id="cb319-5"><a href="PCA.html#cb319-5" tabindex="-1"></a>        MultPerspectives, InclusvClassrm, DEIintegration, EquitableEval)</span></code></pre></div>
<p>Some of the analyses require non-missing data in the df.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="PCA.html#cb320-1" tabindex="-1"></a>items <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(items)</span></code></pre></div>
<p>Let’s check the structure of the data.</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="PCA.html#cb321-1" tabindex="-1"></a><span class="fu">str</span>(items)</span></code></pre></div>
<pre><code>Classes &#39;data.table&#39; and &#39;data.frame&#39;:  267 obs. of  12 variables:
 $ ValObjectives        : int  5 5 4 4 5 5 5 4 5 3 ...
 $ IncrUnderstanding    : int  2 3 4 3 4 5 2 4 5 4 ...
 $ IncrInterest         : int  5 3 4 2 4 5 3 2 5 1 ...
 $ ClearResponsibilities: int  5 5 4 4 5 5 4 4 5 3 ...
 $ EffectiveAnswers     : int  5 3 5 3 5 4 3 2 3 3 ...
 $ Feedback             : int  5 3 4 2 5 5 4 4 5 2 ...
 $ ClearOrganization    : int  3 4 3 4 4 5 4 4 5 2 ...
 $ ClearPresentation    : int  4 4 4 2 5 4 4 4 5 2 ...
 $ MultPerspectives     : int  5 5 4 5 5 5 5 5 5 1 ...
 $ InclusvClassrm       : int  5 5 5 5 5 5 5 4 5 3 ...
 $ DEIintegration       : int  5 5 5 5 5 5 5 5 5 2 ...
 $ EquitableEval        : int  5 5 3 5 5 5 5 3 5 3 ...
 - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; 
 - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:43] 6 20 106 109 112 113 114 117 122 128 ...
  ..- attr(*, &quot;names&quot;)= chr [1:43] &quot;6&quot; &quot;20&quot; &quot;106&quot; &quot;109&quot; ...</code></pre>
</div>
<div id="conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant" class="section level3 hasAnchor" number="8.9.2">
<h3><span class="header-section-number">8.9.2</span> Conduct and interpret the three diagnostic tests to determine if PCA is appropriate as an analysis (KMO, Bartlett’s, determinant)<a href="PCA.html#conduct-and-interpret-the-three-diagnostic-tests-to-determine-if-pca-is-appropriate-as-an-analysis-kmo-bartletts-determinant" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="kmo" class="section level4 hasAnchor" number="8.9.2.1">
<h4><span class="header-section-number">8.9.2.1</span> KMO<a href="PCA.html#kmo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Kaiser-Meyer-Olkin (KMO) index is an index of <em>sampling adequacy</em> to let us know if the sample size is sufficient relative to the statistical characteristics of the data.</p>
<p>General crieria (1974, Kaiser):</p>
<ul>
<li>bare minimum of .5</li>
<li>values between .5 and .7 as mediocre</li>
<li>values between .7 and .8 are good</li>
<li>values above .9 are superb</li>
</ul>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="PCA.html#cb323-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">KMO</span>(items)</span></code></pre></div>
<pre><code>Kaiser-Meyer-Olkin factor adequacy
Call: psych::KMO(r = items)
Overall MSA =  0.91
MSA for each item = 
        ValObjectives     IncrUnderstanding          IncrInterest 
                 0.94                  0.89                  0.89 
ClearResponsibilities      EffectiveAnswers              Feedback 
                 0.91                  0.93                  0.94 
    ClearOrganization     ClearPresentation      MultPerspectives 
                 0.94                  0.91                  0.93 
       InclusvClassrm        DEIintegration         EquitableEval 
                 0.86                  0.78                  0.95 </code></pre>
<p>With a KMO of 0.91, the data seems appropriate to continue with the PCA.</p>
</div>
<div id="bartletts" class="section level4 hasAnchor" number="8.9.2.2">
<h4><span class="header-section-number">8.9.2.2</span> Bartlett’s<a href="PCA.html#bartletts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Barlett’s test let’s us know if the matrix is an <em>identity matrix</em> (i.e., where elements on the off-diagonal would be 0.0 and elements on the diagonal would be 1.0). Stated another way – items only correlate with “themselves” and not other variables.</p>
<p>When <span class="math inline">\(p &lt; 0.05\)</span> the matrix is not an identity matrix. That is, there are some relationships between variables that can be analyzed.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="PCA.html#cb325-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">cortest.bartlett</span>(items)</span></code></pre></div>
<pre><code>R was not square, finding R from data</code></pre>
<pre><code>$chisq
[1] 1897.769

$p.value
[1] 0

$df
[1] 66</code></pre>
<p>The Barlett’s test, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span>, indicating that the correlation matrix is not an identity matrix and, on that dimension, is suitable for analysis.</p>
</div>
<div id="determinant" class="section level4 hasAnchor" number="8.9.2.3">
<h4><span class="header-section-number">8.9.2.3</span> Determinant<a href="PCA.html#determinant" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Multicollinearity or singularity is diagnosed by the determinant. The determinant should be greater than 0.00001. If smaller, then there may be an issue with multicollinearity (variables that are too highly correlated) or singularity (variables that are perfectly correlated).</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="PCA.html#cb328-1" tabindex="-1"></a>items <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(items)</span>
<span id="cb328-2"><a href="PCA.html#cb328-2" tabindex="-1"></a><span class="fu">det</span>(<span class="fu">cor</span>(items)) </span></code></pre></div>
<pre><code>[1] 0.0006985496</code></pre>
<p>The value of the determinant is 0.0007; greater than 0.00001. We are not concerned with multicollinearity or singularity.</p>
<p>Summary from data screening:</p>
<blockquote>
<p>Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was 0.91, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span> indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0007 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
</div>
</div>
<div id="determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory" class="section level3 hasAnchor" number="8.9.3">
<h3><span class="header-section-number">8.9.3</span> Determine how many components to extract (e.g., scree plot, eigenvalues, theory)<a href="PCA.html#determine-how-many-components-to-extract-e.g.-scree-plot-eigenvalues-theory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Step #1: creating a principal components model with the same number of components as items</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="PCA.html#cb330-1" tabindex="-1"></a>pca1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="fu">length</span>(items), <span class="at">rotate =</span> <span class="st">&quot;none&quot;</span>)  <span class="co"># using raw data and letting the length function automatically calculate the # factors as a function of how many columns in the raw data</span></span>
<span id="cb330-2"><a href="PCA.html#cb330-2" tabindex="-1"></a>pca1</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = length(items), rotate = &quot;none&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9
ValObjectives         0.57 -0.13  0.42  0.68 -0.08  0.03  0.03 -0.06 -0.04
IncrUnderstanding     0.68 -0.37  0.39 -0.28  0.08  0.09 -0.12  0.25 -0.04
IncrInterest          0.73 -0.19  0.41 -0.17  0.32 -0.05  0.06 -0.12  0.03
ClearResponsibilities 0.81 -0.08 -0.37  0.04 -0.20  0.02 -0.03  0.09 -0.10
EffectiveAnswers      0.80 -0.16 -0.20 -0.09 -0.03  0.05  0.48 -0.05  0.07
Feedback              0.77  0.06 -0.28  0.11  0.32 -0.29  0.01  0.09 -0.31
ClearOrganization     0.79 -0.27 -0.12  0.04 -0.22 -0.22 -0.20  0.19  0.20
ClearPresentation     0.85 -0.21  0.00 -0.11 -0.24  0.01  0.05 -0.18  0.04
MultPerspectives      0.79  0.26 -0.11 -0.05  0.13 -0.14 -0.23 -0.35  0.17
InclusvClassrm        0.66  0.50  0.24 -0.20 -0.30  0.11 -0.06 -0.07 -0.28
DEIintegration        0.50  0.75  0.19  0.03  0.02 -0.12  0.14  0.25  0.21
EquitableEval         0.73  0.13 -0.27  0.13  0.22  0.52 -0.12  0.07  0.07
                       PC10  PC11  PC12 h2                   u2 com
ValObjectives          0.05  0.02  0.04  1 -0.00000000000000022 2.9
IncrUnderstanding      0.27  0.00  0.07  1  0.00000000000000389 3.7
IncrInterest          -0.28  0.15 -0.09  1  0.00000000000000111 3.0
ClearResponsibilities  0.05  0.36 -0.11  1  0.00000000000000089 2.2
EffectiveAnswers       0.03 -0.01  0.19  1  0.00000000000000078 2.1
Feedback               0.02 -0.14 -0.02  1  0.00000000000000089 2.6
ClearOrganization     -0.23 -0.09  0.11  1  0.00000000000000033 2.5
ClearPresentation      0.08 -0.21 -0.28  1  0.00000000000000122 1.9
MultPerspectives       0.18  0.06  0.12  1  0.00000000000000100 2.4
InclusvClassrm        -0.13 -0.03  0.12  1  0.00000000000000056 3.7
DEIintegration         0.06  0.01 -0.11  1  0.00000000000000033 2.6
EquitableEval         -0.08 -0.09 -0.02  1  0.00000000000000011 2.7

                       PC1  PC2  PC3  PC4  PC5  PC6  PC7  PC8  PC9 PC10 PC11
SS loadings           6.38 1.23 0.95 0.67 0.52 0.47 0.39 0.37 0.32 0.27 0.24
Proportion Var        0.53 0.10 0.08 0.06 0.04 0.04 0.03 0.03 0.03 0.02 0.02
Cumulative Var        0.53 0.63 0.71 0.77 0.81 0.85 0.88 0.91 0.94 0.96 0.98
Proportion Explained  0.53 0.10 0.08 0.06 0.04 0.04 0.03 0.03 0.03 0.02 0.02
Cumulative Proportion 0.53 0.63 0.71 0.77 0.81 0.85 0.88 0.91 0.94 0.96 0.98
                      PC12
SS loadings           0.20
Proportion Var        0.02
Cumulative Var        1.00
Proportion Explained  0.02
Cumulative Proportion 1.00

Mean item complexity =  2.7
Test of the hypothesis that 12 components are sufficient.

The root mean square of the residuals (RMSR) is  0 
 with the empirical chi square  0  with prob &lt;  NA 

Fit based upon off diagonal values = 1</code></pre>
<p>The eigenvalue-greater-than-one criteria suggests 2 factors (but the third component has an SSloading of .95 – it’s close to three).</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="PCA.html#cb332-1" tabindex="-1"></a><span class="fu">plot</span>(pca1<span class="sc">$</span>values, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-109-1.png" width="672" />
The scree plot looks like one factor.</p>
<p>Ugh.</p>
<ul>
<li>I want 3 factors (we could think of this as a priori theory); would account for 71% of variance.</li>
<li>Eigenvalues-greater-than-one criteria suggests two; could account for 63% of variance.</li>
<li>Scree plot suggests 1 (would account for 53% of variance)</li>
</ul>
<p><em>Note</em>: The lecture has more on evaluating communalities and uniquenesses and how this information can also inform the number of components we want to extract. Because it is easy to get lost (very lost) I will skip over this for now. If you were to create a measure and use PCA as an exploratory approach to understanding the dimensionality of an instrument, you would likely want to investigate further and report on these.</p>
</div>
<div id="conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions" class="section level3 hasAnchor" number="8.9.4">
<h3><span class="header-section-number">8.9.4</span> Conduct an orthogonal extraction and rotation with a minimum of two different factor extractions<a href="PCA.html#conduct-an-orthogonal-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>An orthogonal two factor solution</strong></p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="PCA.html#cb333-1" tabindex="-1"></a>pcaORTH2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="dv">2</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb333-2"><a href="PCA.html#cb333-2" tabindex="-1"></a>pcaORTH2f</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 2, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       RC1  RC2   h2   u2 com
ValObjectives         0.55 0.19 0.34 0.66 1.2
IncrUnderstanding     0.77 0.05 0.59 0.41 1.0
IncrInterest          0.72 0.23 0.57 0.43 1.2
ClearResponsibilities 0.73 0.36 0.66 0.34 1.5
EffectiveAnswers      0.76 0.29 0.67 0.33 1.3
Feedback              0.62 0.46 0.59 0.41 1.8
ClearOrganization     0.81 0.18 0.69 0.31 1.1
ClearPresentation     0.83 0.27 0.76 0.24 1.2
MultPerspectives      0.53 0.64 0.70 0.30 1.9
InclusvClassrm        0.29 0.77 0.68 0.32 1.3
DEIintegration        0.03 0.90 0.80 0.20 1.0
EquitableEval         0.55 0.50 0.55 0.45 2.0

                       RC1  RC2
SS loadings           4.93 2.68
Proportion Var        0.41 0.22
Cumulative Var        0.41 0.63
Proportion Explained  0.65 0.35
Cumulative Proportion 0.65 1.00

Mean item complexity =  1.4
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.07 
 with the empirical chi square  170.34  with prob &lt;  0.000000000000000045 

Fit based upon off diagonal values = 0.98</code></pre>
<p>Sorting the scores into a table can help see the results more clearly. The “cut = #” command will not show the factor scores for factor loading &lt; .30. I would do this “to see”, but I would include all the values in an APA style table.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="PCA.html#cb335-1" tabindex="-1"></a>pca_tableOR2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaORTH2f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 2, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item  RC1  RC2   h2   u2 com
ClearPresentation        8 0.83      0.76 0.24 1.2
ClearOrganization        7 0.81      0.69 0.31 1.1
IncrUnderstanding        2 0.77      0.59 0.41 1.0
EffectiveAnswers         5 0.76      0.67 0.33 1.3
ClearResponsibilities    4 0.73 0.36 0.66 0.34 1.5
IncrInterest             3 0.72      0.57 0.43 1.2
Feedback                 6 0.62 0.46 0.59 0.41 1.8
ValObjectives            1 0.55      0.34 0.66 1.2
EquitableEval           12 0.55 0.50 0.55 0.45 2.0
DEIintegration          11      0.90 0.80 0.20 1.0
InclusvClassrm          10      0.77 0.68 0.32 1.3
MultPerspectives         9 0.53 0.64 0.70 0.30 1.9

                       RC1  RC2
SS loadings           4.93 2.68
Proportion Var        0.41 0.22
Cumulative Var        0.41 0.63
Proportion Explained  0.65 0.35
Cumulative Proportion 0.65 1.00

Mean item complexity =  1.4
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.07 
 with the empirical chi square  170.34  with prob &lt;  0.000000000000000045 

Fit based upon off diagonal values = 0.98</code></pre>
<p>F1: Includes everything else.
F2: Includes the SCR items (although MultPerspectives cross-loads onto F1; Similarly, EquitableEval is on F1)</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="PCA.html#cb337-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaORTH2f)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-112-1.png" width="672" />
Plotting these figures from the program can facilitate conceptual understanding of what is going on – and can be a “check” to your work.</p>
<p>In the lecture I made a “biggish deal” about PCA being <em>components</em> (not <em>factor</em>) analysis. Although the two approaches can lead to similar results/conclusions, there are some significant differences “under the hood.” PCA can be thought of more as regression where the items predict the component. Consequently, the arrows go <em>from</em> the item, <em>to</em> the component. Starting with the next lesson, the arrows will go from the factor to the item – because the factors (or latent variables) are assumed to predict the scores on the items (i.e., “depression” would predict how someone rates items that assess hopelessness, sleep, anhedonia, and so forth).</p>
<p><strong>An orthogonal three factor solution</strong></p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="PCA.html#cb338-1" tabindex="-1"></a>pcaORTH3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;varimax&quot;</span>)</span>
<span id="cb338-2"><a href="PCA.html#cb338-2" tabindex="-1"></a>pcaORTH3f</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 3, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                       RC1  RC3  RC2   h2   u2 com
ValObjectives         0.16 0.67 0.21 0.52 0.48 1.3
IncrUnderstanding     0.29 0.81 0.04 0.75 0.25 1.3
IncrInterest          0.30 0.78 0.23 0.74 0.26 1.5
ClearResponsibilities 0.85 0.22 0.14 0.80 0.20 1.2
EffectiveAnswers      0.75 0.37 0.12 0.71 0.29 1.5
Feedback              0.75 0.19 0.28 0.67 0.33 1.4
ClearOrganization     0.70 0.47 0.03 0.71 0.29 1.8
ClearPresentation     0.65 0.56 0.14 0.76 0.24 2.1
MultPerspectives      0.63 0.24 0.51 0.71 0.29 2.2
InclusvClassrm        0.26 0.30 0.76 0.74 0.26 1.6
DEIintegration        0.15 0.07 0.90 0.84 0.16 1.1
EquitableEval         0.70 0.15 0.33 0.62 0.38 1.5

                       RC1  RC3  RC2
SS loadings           3.93 2.64 1.99
Proportion Var        0.33 0.22 0.17
Cumulative Var        0.33 0.55 0.71
Proportion Explained  0.46 0.31 0.23
Cumulative Proportion 0.46 0.77 1.00

Mean item complexity =  1.5
Test of the hypothesis that 3 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  115.69  with prob &lt;  0.000000000041 

Fit based upon off diagonal values = 0.99</code></pre>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="PCA.html#cb340-1" tabindex="-1"></a>pca_tableOR3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaORTH3f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 3, rotate = &quot;varimax&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item  RC1  RC3  RC2   h2   u2 com
ClearResponsibilities    4 0.85           0.80 0.20 1.2
EffectiveAnswers         5 0.75 0.37      0.71 0.29 1.5
Feedback                 6 0.75           0.67 0.33 1.4
EquitableEval           12 0.70      0.33 0.62 0.38 1.5
ClearOrganization        7 0.70 0.47      0.71 0.29 1.8
ClearPresentation        8 0.65 0.56      0.76 0.24 2.1
MultPerspectives         9 0.63      0.51 0.71 0.29 2.2
IncrUnderstanding        2      0.81      0.75 0.25 1.3
IncrInterest             3      0.78      0.74 0.26 1.5
ValObjectives            1      0.67      0.52 0.48 1.3
DEIintegration          11           0.90 0.84 0.16 1.1
InclusvClassrm          10      0.30 0.76 0.74 0.26 1.6

                       RC1  RC3  RC2
SS loadings           3.93 2.64 1.99
Proportion Var        0.33 0.22 0.17
Cumulative Var        0.33 0.55 0.71
Proportion Explained  0.46 0.31 0.23
Cumulative Proportion 0.46 0.77 1.00

Mean item complexity =  1.5
Test of the hypothesis that 3 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  115.69  with prob &lt;  0.000000000041 

Fit based upon off diagonal values = 0.99</code></pre>
<p>F1: Traditional Pedagogy
F2: Valued-by-Me
F3: SCRPed–except Equitable Eval * MultPerspectives are on TradPed; MultPerspectives cross-load</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="PCA.html#cb342-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaORTH3f)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-115-1.png" width="672" />
The three factor solution gets really close to my goals of (a) traditional pedagogy, (b) valued by the student, and (c) socially responsive pedagogy. The trouble is that I would prefer “multiple perspectives” to load with the socially responsive pedagogy factor.</p>
</div>
<div id="conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions" class="section level3 hasAnchor" number="8.9.5">
<h3><span class="header-section-number">8.9.5</span> Conduct an oblique extraction and rotation with a minimum of two different factor extractions<a href="PCA.html#conduct-an-oblique-extraction-and-rotation-with-a-minimum-of-two-different-factor-extractions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>An oblique two factor solution</strong></p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="PCA.html#cb343-1" tabindex="-1"></a>pcaOBL2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="dv">2</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb343-2"><a href="PCA.html#cb343-2" tabindex="-1"></a>pcaOBL2f</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 2, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                        TC1   TC2   h2   u2 com
ValObjectives          0.58  0.01 0.34 0.66 1.0
IncrUnderstanding      0.84 -0.21 0.59 0.41 1.1
IncrInterest           0.76  0.00 0.57 0.43 1.0
ClearResponsibilities  0.75  0.13 0.66 0.34 1.1
EffectiveAnswers       0.80  0.05 0.67 0.33 1.0
Feedback               0.61  0.27 0.59 0.41 1.4
ClearOrganization      0.86 -0.08 0.69 0.31 1.0
ClearPresentation      0.87  0.00 0.76 0.24 1.0
MultPerspectives       0.50  0.49 0.70 0.30 2.0
InclusvClassrm         0.21  0.71 0.68 0.32 1.2
DEIintegration        -0.10  0.93 0.80 0.20 1.0
EquitableEval          0.53  0.34 0.55 0.45 1.7

                       TC1  TC2
SS loadings           5.50 2.11
Proportion Var        0.46 0.18
Cumulative Var        0.46 0.63
Proportion Explained  0.72 0.28
Cumulative Proportion 0.72 1.00

 With component correlations of 
     TC1  TC2
TC1 1.00 0.43
TC2 0.43 1.00

Mean item complexity =  1.2
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.07 
 with the empirical chi square  170.34  with prob &lt;  0.000000000000000045 

Fit based upon off diagonal values = 0.98</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="PCA.html#cb345-1" tabindex="-1"></a>pca_tableOBL2f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaOBL2f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 2, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   TC1   TC2   h2   u2 com
ClearPresentation        8  0.87       0.76 0.24 1.0
ClearOrganization        7  0.86       0.69 0.31 1.0
IncrUnderstanding        2  0.84       0.59 0.41 1.1
EffectiveAnswers         5  0.80       0.67 0.33 1.0
IncrInterest             3  0.76       0.57 0.43 1.0
ClearResponsibilities    4  0.75       0.66 0.34 1.1
Feedback                 6  0.61       0.59 0.41 1.4
ValObjectives            1  0.58       0.34 0.66 1.0
EquitableEval           12  0.53  0.34 0.55 0.45 1.7
MultPerspectives         9  0.50  0.49 0.70 0.30 2.0
DEIintegration          11        0.93 0.80 0.20 1.0
InclusvClassrm          10        0.71 0.68 0.32 1.2

                       TC1  TC2
SS loadings           5.50 2.11
Proportion Var        0.46 0.18
Cumulative Var        0.46 0.63
Proportion Explained  0.72 0.28
Cumulative Proportion 0.72 1.00

 With component correlations of 
     TC1  TC2
TC1 1.00 0.43
TC2 0.43 1.00

Mean item complexity =  1.2
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.07 
 with the empirical chi square  170.34  with prob &lt;  0.000000000000000045 

Fit based upon off diagonal values = 0.98</code></pre>
<p>Fairly similar results to the orthogonal variation of this – with EquitableEval and MultPerspectives cross-loading, with stronger loadings on the TradPed/Valued dimension.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="PCA.html#cb347-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaOBL2f)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-118-1.png" width="672" />
The curved curved line and value between TC1 and TC2 illustrates that in the oblique solution the components are allowed to correlate. There was no such path on the orthogonal figures. This is because the rotation required the components to be uncorrelated.</p>
<p><strong>An oblique three factor solution</strong></p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="PCA.html#cb348-1" tabindex="-1"></a>pcaOBL3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb348-2"><a href="PCA.html#cb348-2" tabindex="-1"></a>pcaOBL3f</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                        TC1   TC3   TC2   h2   u2 com
ValObjectives         -0.08  0.71  0.15 0.52 0.48 1.1
IncrUnderstanding      0.06  0.84 -0.07 0.75 0.25 1.0
IncrInterest           0.05  0.79  0.13 0.74 0.26 1.1
ClearResponsibilities  0.95 -0.06 -0.05 0.80 0.20 1.0
EffectiveAnswers       0.76  0.15 -0.06 0.71 0.29 1.1
Feedback               0.80 -0.06  0.12 0.67 0.33 1.1
ClearOrganization      0.68  0.29 -0.15 0.71 0.29 1.5
ClearPresentation      0.57  0.41 -0.02 0.76 0.24 1.8
MultPerspectives       0.59  0.03  0.39 0.71 0.29 1.7
InclusvClassrm         0.08  0.22  0.73 0.74 0.26 1.2
DEIintegration         0.00 -0.02  0.92 0.84 0.16 1.0
EquitableEval          0.75 -0.10  0.18 0.62 0.38 1.2

                       TC1  TC3  TC2
SS loadings           4.23 2.50 1.83
Proportion Var        0.35 0.21 0.15
Cumulative Var        0.35 0.56 0.71
Proportion Explained  0.49 0.29 0.21
Cumulative Proportion 0.49 0.79 1.00

 With component correlations of 
     TC1  TC3  TC2
TC1 1.00 0.58 0.39
TC3 0.58 1.00 0.25
TC2 0.39 0.25 1.00

Mean item complexity =  1.2
Test of the hypothesis that 3 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  115.69  with prob &lt;  0.000000000041 

Fit based upon off diagonal values = 0.99</code></pre>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="PCA.html#cb350-1" tabindex="-1"></a>pca_tableOBL3f <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaOBL3f, <span class="at">cut =</span> <span class="fl">0.3</span>, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   TC1   TC3   TC2   h2   u2 com
ClearResponsibilities    4  0.95             0.80 0.20 1.0
Feedback                 6  0.80             0.67 0.33 1.1
EffectiveAnswers         5  0.76             0.71 0.29 1.1
EquitableEval           12  0.75             0.62 0.38 1.2
ClearOrganization        7  0.68             0.71 0.29 1.5
MultPerspectives         9  0.59        0.39 0.71 0.29 1.7
ClearPresentation        8  0.57  0.41       0.76 0.24 1.8
IncrUnderstanding        2        0.84       0.75 0.25 1.0
IncrInterest             3        0.79       0.74 0.26 1.1
ValObjectives            1        0.71       0.52 0.48 1.1
DEIintegration          11              0.92 0.84 0.16 1.0
InclusvClassrm          10              0.73 0.74 0.26 1.2

                       TC1  TC3  TC2
SS loadings           4.23 2.50 1.83
Proportion Var        0.35 0.21 0.15
Cumulative Var        0.35 0.56 0.71
Proportion Explained  0.49 0.29 0.21
Cumulative Proportion 0.49 0.79 1.00

 With component correlations of 
     TC1  TC3  TC2
TC1 1.00 0.58 0.39
TC3 0.58 1.00 0.25
TC2 0.39 0.25 1.00

Mean item complexity =  1.2
Test of the hypothesis that 3 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  115.69  with prob &lt;  0.000000000041 

Fit based upon off diagonal values = 0.99</code></pre>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="PCA.html#cb352-1" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">fa.diagram</span>(pcaOBL3f)</span></code></pre></div>
<p><img src="08-EFA_PCA_files/figure-html/unnamed-chunk-121-1.png" width="672" />
The results are quite similar to the orthogonal solution.</p>
</div>
<div id="determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest" class="section level3 hasAnchor" number="8.9.6">
<h3><span class="header-section-number">8.9.6</span> Determine which factor solution (e.g., orthogonal or oblique; which number of factors) you will suggest<a href="PCA.html#determine-which-factor-solution-e.g.-orthogonal-or-oblique-which-number-of-factors-you-will-suggest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the oblique output we see that the correlations between the three subscales range from 0.25 to 0.58. These are high. Therefore, I will choose a 3-component, oblique, solution.</p>
</div>
<div id="apa-style-results-section-with-table-and-figure-of-one-of-the-solutions" class="section level3 hasAnchor" number="8.9.7">
<h3><span class="header-section-number">8.9.7</span> APA style results section with table and figure of one of the solutions<a href="PCA.html#apa-style-results-section-with-table-and-figure-of-one-of-the-solutions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>The dimensionality of the 12 course evaluation items was analyzed using principal components analysis. First, data were screened to determine the suitability of the data for this analyses. Data screening were conducted to determine the suitability of the data for this analyses. The Kaiser-Meyer-Olkin measure of sampling adequacy (KMO; Kaiser, 1970) represents the ratio of the squared correlation between variables to the squared partial correlation between variables. KMO ranges from 0.00 to 1.00; values closer to 1.00 indicate that the patterns of correlations are relatively compact and that component analysis should yield distinct and reliable components (Field, 2012). In our dataset, the KMO value was 0.91, indicating acceptable sampling adequacy. The Barlett’s Test of Sphericity examines whether the population correlation matrix resembles an identity matrix (Field, 2012). When the <em>p</em> value for the Bartlett’s test is &lt; .05, we are fairly certain we have clusters of correlated variables. In our dataset, <span class="math inline">\(\chi^2(66) = 1897.77, p &lt; 0.001\)</span> indicating the correlations between items are sufficiently large enough for principal components analysis. The determinant of the correlation matrix alerts us to any issues of multicollinearity or singularity and should be larger than 0.00001. Our determinant was 0.0007 and, again, indicated that our data was suitable for the analysis.</p>
</blockquote>
<blockquote>
<p>Four criteria were used to determine the number of components to extract: a priori theory, the scree test, the eigenvalue-greater-than-one criteria, and the interpretability of the solution. Kaiser’s eigenvalue-greater-than-one criteria suggested two components, and, in combination explained 63% of the variance. The inflexion in the scree plot justified retaining one component. A priorily, we researchers were expecting three components – which would explain 71% of the variance. Correspondingly, we investigated two and three component solutions with orthogonal (varimax) and oblique (oblimin) procedures. Given the significant correlations (ranging from .25 to .58) and the correspondence of items loading on the a priorili hypothesized components, we determined that an oblique, three-component, solution was most appropriate.</p>
</blockquote>
<blockquote>
<p>The rotated solution, as shown in Table 1 and Figure 1, yielded three interpretable components, each listed with the proportion of variance accounted for: traditional pedagogy (35%), valued-by-me (21%), and socially and culturally responsive pedagogy (15%).</p>
</blockquote>
<p>Regarding the Table 1, I would include a table with ALL the values, bolding those with component membership. This is easy, though, because we can export it to a .csv file and</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="PCA.html#cb353-1" tabindex="-1"></a>pcaOBL3fb <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(items, <span class="at">nfactors =</span> <span class="dv">3</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>)</span>
<span id="cb353-2"><a href="PCA.html#cb353-2" tabindex="-1"></a>pca_tableOBL3fb <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">print.psych</span>(pcaOBL3fb, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = items, nfactors = 3, rotate = &quot;oblimin&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      item   TC1   TC3   TC2   h2   u2 com
ClearResponsibilities    4  0.95 -0.06 -0.05 0.80 0.20 1.0
Feedback                 6  0.80 -0.06  0.12 0.67 0.33 1.1
EffectiveAnswers         5  0.76  0.15 -0.06 0.71 0.29 1.1
EquitableEval           12  0.75 -0.10  0.18 0.62 0.38 1.2
ClearOrganization        7  0.68  0.29 -0.15 0.71 0.29 1.5
MultPerspectives         9  0.59  0.03  0.39 0.71 0.29 1.7
ClearPresentation        8  0.57  0.41 -0.02 0.76 0.24 1.8
IncrUnderstanding        2  0.06  0.84 -0.07 0.75 0.25 1.0
IncrInterest             3  0.05  0.79  0.13 0.74 0.26 1.1
ValObjectives            1 -0.08  0.71  0.15 0.52 0.48 1.1
DEIintegration          11  0.00 -0.02  0.92 0.84 0.16 1.0
InclusvClassrm          10  0.08  0.22  0.73 0.74 0.26 1.2

                       TC1  TC3  TC2
SS loadings           4.23 2.50 1.83
Proportion Var        0.35 0.21 0.15
Cumulative Var        0.35 0.56 0.71
Proportion Explained  0.49 0.29 0.21
Cumulative Proportion 0.49 0.79 1.00

 With component correlations of 
     TC1  TC3  TC2
TC1 1.00 0.58 0.39
TC3 0.58 1.00 0.25
TC2 0.39 0.25 1.00

Mean item complexity =  1.2
Test of the hypothesis that 3 components are sufficient.

The root mean square of the residuals (RMSR) is  0.06 
 with the empirical chi square  115.69  with prob &lt;  0.000000000041 

Fit based upon off diagonal values = 0.99</code></pre>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="PCA.html#cb355-1" tabindex="-1"></a>pcaOBL3fb_table <span class="ot">&lt;-</span> <span class="fu">round</span>(pcaOBL3fb<span class="sc">$</span>loadings, <span class="dv">3</span>)</span>
<span id="cb355-2"><a href="PCA.html#cb355-2" tabindex="-1"></a><span class="fu">write.table</span>(pcaOBL3fb_table, <span class="at">file =</span> <span class="st">&quot;pcaOBL3f_table.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="at">col.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb355-3"><a href="PCA.html#cb355-3" tabindex="-1"></a>    <span class="at">row.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb355-4"><a href="PCA.html#cb355-4" tabindex="-1"></a>pcaOBL3fb_table</span></code></pre></div>
<pre><code>
Loadings:
                      TC1    TC3    TC2   
ValObjectives                 0.712  0.151
IncrUnderstanding             0.844       
IncrInterest                  0.787  0.132
ClearResponsibilities  0.947              
EffectiveAnswers       0.764  0.154       
Feedback               0.800         0.119
ClearOrganization      0.685  0.293 -0.149
ClearPresentation      0.574  0.413       
MultPerspectives       0.593         0.391
InclusvClassrm                0.218  0.730
DEIintegration                       0.921
EquitableEval          0.751         0.184

                 TC1   TC3   TC2
SS loadings    3.854 2.185 1.655
Proportion Var 0.321 0.182 0.138
Cumulative Var 0.321 0.503 0.641</code></pre>
</div>
<div id="explanation-to-grader-1" class="section level3 hasAnchor" number="8.9.8">
<h3><span class="header-section-number">8.9.8</span> Explanation to grader<a href="PCA.html#explanation-to-grader-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>

</div>
</div>
</div>
<h3>REFERENCES<a href="REFS.html#REFS" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-conover_development_2017" class="csl-entry">
Conover, K. J., Israel, T., &amp; Nylund-Gibson, K. (2017). Development and <span>Validation</span> of the <span>Ableist</span> <span>Microaggressions</span> <span>Scale</span>. <em>The Counseling Psychologist</em>, <em>45</em>(4), 30. <a href="https://doi.org/10.1177/001 1000017715317">https://doi.org/10.1177/001 1000017715317</a>
</div>
<div id="ref-field_discovering_2012" class="csl-entry">
Field, A. P. (2012). <em>Discovering statistics using <span>R</span></em>. Sage.
</div>
<div id="ref-keum_gendered_2018" class="csl-entry">
Keum, B. T., Brady, J. L., Sharma, R., Lu, Y., Kim, Y. H., &amp; Thai, C. J. (2018). Gendered <span>Racial</span> <span>Microaggressions</span> <span>Scale</span> for <span>Asian</span> <span>American</span> <span>Women</span>: <span>Development</span> and initial validation. <em>Journal of Counseling Psychology</em>, <em>65</em>(5), 571–585. <a href="https://doi.org/10.1037/cou0000305">https://doi.org/10.1037/cou0000305</a>
</div>
<div id="ref-lewis_construction_2015" class="csl-entry">
Lewis, J. A., &amp; Neville, H. A. (2015). Construction and initial validation of the <span>Gendered</span> <span>Racial</span> <span>Microaggressions</span> <span>Scale</span> for <span>Black</span> women. <em>Journal of Counseling Psychology</em>, <em>62</em>(2), 289–302. <a href="https://doi.org/10.1037/cou0000062">https://doi.org/10.1037/cou0000062</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="exploratory-factor-analysis-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="PAF.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lhbikos/ReC_Psychometrics/edit/BRANCH/08-EFA_PCA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ReC_Psychometrics.pdf", "ReC_Psychometrics.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
