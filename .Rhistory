standardized=FALSE)
#used to retrieve column indices used in the rescaling script below
col_index <- as.data.frame(colnames(dfSzy))
#The code below loops through each column of the dataframe and assigns the scaling accordingly
#Rows 1 thru 6 are the Perceptions of LGBTQ Campus Climate Scale
#Rows 7 thru 15 are the Sexual Orientation-Based Campus Victimization Scale
#Rows 16 thru 20 are the College Satisfaction Scale
#Rows 21 thru 26 are the Institutional and Goals Commitment Scale
#Rows 27 thru 33 are the GAD7
#Rows 34 thru 42 are the PHQ9
for(i in 1:ncol(dfSzy)){
if(i >= 1 & i <= 6){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 7 & i <= 15){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 16 & i <= 20){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 21 & i <= 26){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 5))
}
if(i >= 27 & i <= 33){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 34 & i <= 42){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
}
#rounding to integers so that the data resembles that which was collected
library(tidyverse)
dfSzy <- dfSzy %>% round(0)
#quick check of my work
#psych::describe(dfSzy)
#Reversing the supportive item on the Perceptions of LGBTQ Campus Climate Scale so that the exercises will be consistent with the format in which the data was collected
dfSzy <- dfSzy %>%
dplyr::mutate(supportiveNR = 8 - supportive)
#Reversing three items on the Institutional and Goals Commitments scale so that the exercises will be consistent with the format in which the data was collected
dfSzy <- dfSzy %>%
dplyr::mutate(not_graduateNR = 8 - not_graduate)%>%
dplyr::mutate(undecidedNR = 8 - undecided)%>%
dplyr::mutate(grades_unimportantNR = 8 - grades_unimportant)
dfSzy <- dplyr::select(dfSzy, -c(supportive, not_graduate, undecided, grades_unimportant))
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
saveRDS(SzyDF, "SzyDF.rds")
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
saveRDS(dfSzy, "SzyDF.rds")
#bring back the simulated dat from an .rds file
#dfSzy <- readRDS("SzyDF.rds")
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
#saveRDS(dfSzy, "SzyDF.rds")
#bring back the simulated dat from an .rds file
dfSzy <- readRDS("SzyDF.rds")
#write the simulated data  as a .csv
write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#write the simulated data  as a .csv
#write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#bring back the simulated dat from a .csv file
dfSzy <- read.csv ("SzyDF.csv", header = TRUE)
SimCor_mu <- c(3.13, 2.68, 3.58, 3.16, 2.66, 2.76)
SimCor_sd <- c(0.82, 1.04, 1.26, 0.83, 1.05, .99)
simCor <- matrix (c(1,	0.64,	0.77,	0.44,	0.33,	0.29,
0.64,	1,	0.53,	0.35,	0.46,	0.34,
0.77,	0.53,	1,	0.27,	0.4,	0.47,
0.44,	0.35,	0.27,	1,	0.63,	0.62,
0.33,	0.46,	0.4,	0.63,	1,	0.57,
0.29,	0.34,	0.47,	0.62,	0.57,	1),
ncol = 6)
scovMat <- SimCor_sd %*% t(SimCor_sd)*simCor
set.seed(210829)
retest_df <- MASS::mvrnorm(n = 646, mu = SimCor_mu, Sigma = scovMat, empirical = TRUE)
colnames(retest_df) <- c("TotalT1", "ResponseT1", "StigmaT1", "TotalT2", "ResponseT2", "StigmaT2")
retest_df  <- as.data.frame(retest_df) #converts to a df so we can use in R
library(dplyr)
retest_df <- retest_df %>% dplyr::mutate(ID = row_number()) #add ID to each row
retest_df <- retest_df %>%dplyr::select(ID, everything())#moving the ID number to the first column; requires
retest_df2 <- retest_df %>%
dplyr::select (c(-ID))
retest_df2 <- retest_df %>%
dplyr::select (c(-ID))
apaTables::apa.cor.table(data = retest_df2, landscape=TRUE, table.number = 1, filename="Table_1_Retest.doc")
Szymanski_generating_model <- '
#measurement model
CollegeResponse  =~ .88*cold + .73*unresponsive + .73*supportive
Stigma =~ .86*negative + .76*heterosexism + .71*harassed
Victimization =~ .8*Vic1 + .8*Vic2 + .8*Vic3 + .8*Vic4 + .8*Vic5 + .8*Vic6 + .8*Vic7 + .8*Vic8 + .8*Vic9
CollSat =~ .8*Sat1 + .8*Sat2 + .8*Sat3 + .8*Sat4 + .8*Sat5
Persistence =~ .69*graduation_importance + .63*right_decision + .62*will_register + .59*not_graduate + .45*undecided + .44*grades_unimportant
Anxiety =~ .851*nervous + .887*worry_control + .894*much_worry + 674*cant_relax + .484*restless + .442*irritable + 716*afraid
Depression =~ .798*anhedonia + .425*down +  .591*sleep +  .913*lo_energy +  .441*appetite +  .519*selfworth +  .755*concentration +  .454*too_slowfast + .695*s_ideation
#Means
CollegeResponse ~ 2.71*1
Stigma ~3.61*1
Victimization ~ 0.11*1
CollSat ~ 5.61*1
Persistence ~ 4.41*1
Anxiety ~ 1.45*1
Depression ~1.29*1
#Correlations
CollegeResponse ~~ .58*Stigma
CollegeResponse ~~ -.25*Victimization
CollegeResponse ~~  -.59*CollSat
CollegeResponse ~~  -.29*Persistence
CollegeResponse ~~  .17*Anxiety
CollegeResponse ~~  .18*Depression
Stigma ~~ .37*Victimization
Stigma ~~  -.41*CollSat
Stigma ~~  -.19*Persistence
Stigma ~~  .27*Anxiety
Stigma ~~  .24*Depression
Victimization ~~  -.22*CollSat
Victimization ~~  -.04*Persistence
Victimization ~~  .23*Anxiety
Victimization ~~  .21*Depression
CollSat ~~  .53*Persistence
CollSat ~~  -.29*Anxiety
CollSat ~~  -.32*Depression
Persistence ~~  -.22*Anxiety
Persistence ~~  -.26*Depression
Anxiety ~~  .76*Depression
'
set.seed(240218)
dfSzy <- lavaan::simulateData(model = Szymanski_generating_model,
model.type = "sem",
meanstructure = T,
sample.nobs=646,
standardized=FALSE)
View(dfSzy)
col_index <- as.data.frame(colnames(dfSzy))
View(col_index)
for(i in 1:ncol(dfSzy)){
if(i >= 1 & i <= 6){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 7 & i <= 15){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 16 & i <= 20){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 21 & i <= 26){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 5))
}
if(i >= 27 & i <= 33){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 34 & i <= 42){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
}
View(dfSzy)
#rounding to integers so that the data resembles that which was collected
library(tidyverse)
dfSzy <- dfSzy %>% round(0)
View(dfSzy)
dfSzy <- dfSzy %>%
dplyr::mutate(supportiveNR = 8 - supportive)
dfSzy <- dfSzy %>%
dplyr::mutate(not_graduateNR = 8 - not_graduate)%>%
dplyr::mutate(undecidedNR = 8 - undecided)%>%
dplyr::mutate(grades_unimportantNR = 8 - grades_unimportant)
dfSzy <- dplyr::select(dfSzy, -c(supportive, not_graduate, undecided, grades_unimportant))
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
saveRDS(dfSzy, "SzyDF.rds")
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
#saveRDS(dfSzy, "SzyDF.rds")
#bring back the simulated dat from an .rds file
dfSzy <- readRDS("SzyDF.rds")
View(dfSzy)
View(dfSzy)
#write the simulated data  as a .csv
write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#write the simulated data  as a .csv
#write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#bring back the simulated dat from a .csv file
dfSzy <- read.csv("SzyDF.csv", header = TRUE)
View(dfSzy)
View(dfSzy)
library(tidyverse)
dfSzy<- dfSzy %>%
dplyr::mutate(unsupportive = 8 - supportiveNR)#when reverse-coding, subtract the variable from one number higher than the scaling
#When unhashtagged, this code provides item-level descriptive statistics
#psych::describe(dfSzy)
LGBTQT1 <- dplyr::select(dfSzy, cold, unresponsive, unsupportive, negative, heterosexism, harassed)
ResponseT1 <- dplyr::select(dfSzy, cold, unresponsive, unsupportive)
StigmaT1 <- dplyr::select(dfSzy, negative, heterosexism, harassed)
View(dfSzy)
View(LGBTQT1)
View(ResponseT1)
View(StigmaT1)
split <- psych::splitHalf (LGBTQT1, raw = TRUE, brute = TRUE)
split #show the results of the analysis
hist(split$raw,breaks = 101, xlab = "Split-half reliability",
main = "Split-half reliabilities of 6 LGBTQ items")
split <- psych::splitHalf (LGBTQT1, raw = TRUE, brute = TRUE)
split #show the results of the analysis
hist(split$raw,breaks = 101, xlab = "Split-half reliability",
main = "Split-half reliabilities of 6 LGBTQ items")
splitRx <- psych::splitHalf (ResponseT1, raw = TRUE, brute = TRUE)
splitRx #show the results of the analysis
hist(splitRx$raw,breaks = 101, xlab = "Split-half reliability",
main = "Split-half reliabilities of 3 items of the College Response subscale")
splitSt <- psych::splitHalf (StigmaT1, raw = TRUE, brute = TRUE)
splitSt #show the results of the analysis
hist(splitRx$raw,breaks = 101, xlab = "Split-half reliability",
main = "Split-half reliabilities of 3 items of the Stigma subscale")
View(LGBTQT1)
psych::alpha(LGBTQT1)
psych::alpha(ResponseT1)
psych::alpha(StigmaT1)
View(LGBTQT1)
View(ResponseT1)
View(StigmaT1)
psych::omegaSem(LGBTQT1, nfactors=2)
.54/.74
SimCor_mu <- c(3.13, 2.68, 3.58, 3.16, 2.66, 2.76)
SimCor_sd <- c(0.82, 1.04, 1.26, 0.83, 1.05, .99)
simCor <- matrix (c(1,	0.64,	0.77,	0.44,	0.33,	0.29,
0.64,	1,	0.53,	0.35,	0.46,	0.34,
0.77,	0.53,	1,	0.27,	0.4,	0.47,
0.44,	0.35,	0.27,	1,	0.63,	0.62,
0.33,	0.46,	0.4,	0.63,	1,	0.57,
0.29,	0.34,	0.47,	0.62,	0.57,	1),
ncol = 6)
scovMat <- SimCor_sd %*% t(SimCor_sd)*simCor
set.seed(210829)
retest_df <- MASS::mvrnorm(n = 646, mu = SimCor_mu, Sigma = scovMat, empirical = TRUE)
colnames(retest_df) <- c("TotalT1", "ResponseT1", "StigmaT1", "TotalT2", "ResponseT2", "StigmaT2")
retest_df  <- as.data.frame(retest_df) #converts to a df so we can use in R
library(dplyr)
retest_df <- retest_df %>% dplyr::mutate(ID = row_number()) #add ID to each row
retest_df <- retest_df %>%dplyr::select(ID, everything())#moving the ID number to the first column; requires
View(retest_df)
retest_df2 <- retest_df %>%
dplyr::select (c(-ID))
apaTables::apa.cor.table(data = retest_df2, landscape=TRUE, table.number = 1, filename="Table_1_Retest.doc")
big <- readRDS("ReC.rds")
View(big)
str(big)
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
# Creating the new variables
big$Valued <- sjstats::mean_n(big[, ValuedVars], .66)
big$TradPed <- sjstats::mean_n(big[, TradPedVars], .75)
big$SRPed <- sjstats::mean_n(big[, SRPedVars], .75)
View(big)
library(tidyverse)
items <- big%>%
dplyr::select (ValObjectives, IncrUnderstanding, IncrInterest, ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, MultPerspectives, InclusvClassrm, DEIintegration,EquitableEval)
View(items)
psych::alpha(items)
psych::alpha(items[,Valued_vars])
psych::alpha(items[,ValuedVars])
psych::alpha(items[,SRPedVars])
psych::omegaSem(items, nfactors=3)
.82/.94
big <- readRDS("ReC.rds")
str(big)
library(tidyverse)
items <- big%>%
dplyr::select (ValObjectives, IncrUnderstanding, IncrInterest, ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, MultPerspectives, InclusvClassrm, DEIintegration,EquitableEval)
View(items)
psych::alpha(items)
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
psych::alpha(items[,ValuedVars])
psych::alpha(items[,TradPedVars])
psych::alpha(items[,SRPedVars])
psych::omegaSem(items, nfactors=3)
.82/.94
items$Valued <- sjstats::mean_n(items[,Valued_Vars], .75)
items$Valued <- sjstats::mean_n(items[,ValuedVars], .75)
items$TradPed <- sjstats::mean_n(items[,TradPedVars], .75)
items$SCRPed <- sjstats::mean_n(items[,SRPedVars], .75)
items$Total <- sjstats::mean_n(items, .75)
items$Valued <- sjstats::mean_n(items[,ValuedVars], .75)
items$TradPed <- sjstats::mean_n(items[,TradPedVars], .75)
items$SCRPed <- sjstats::mean_n(items[,SRPedVars], .75)
items$Total <- sjstats::mean_n(items, .75)
View(items)
scores<-items%>%
dplyr::select(Valued, TradPed, SCRPed, Total)
psych::describe(scores)
big <- readRDS("ReC.rds")
View(big)
str(big)
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
# Making the list of variables
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
# Creating the new variables
big$Valued <- sjstats::mean_n(big[, ValuedVars], .66)
big$TradPed <- sjstats::mean_n(big[, TradPedVars], .75)
big$SRPed <- sjstats::mean_n(big[, SRPedVars], .75)
# If the scoring code above does not work for you, try the format
# below which involves inserting to periods in front of the variable
# list. One example is provided. dfLewis$Belonging <-
# sjstats::mean_n(dfLewis[, ..Belonging_vars], 0.80)
View(big)
library(tidyverse)
tiny <- big %>%
dplyr::select(Valued, TradPed, SRPed, OvInstructor)
View(tiny)
apaTables::apa.cor.table(big[c("Valued", "TradPed", "SRPed", "OvInstructor")], filename="ReC_cortable.doc", table.number = 1, show.sig.stars=TRUE, landscape=TRUE)
library(tidyverse)
tiny <- big %>%
dplyr::select(Valued, TradPed, SRPed, OvInstructor)
cocor::cocor(formula = ~Valued + OvInstructor | TradPed + OvInstructor, data = big)
cocor::cocor(formula = ~TradPed + OvInstructor | SRPed + OvInstructor, data = big)
cocor::cocor(formula = ~Valued + OvInstructor | SRPed + OvInstructor, data = big)
big <- na.omit(big)#included b/c there was uneven missingness and the subsequent comparison required equal sample sizes in the regression models
Step1 <- lm(Valued ~ TradPed, data = big)
Step2 <- lm(Valued ~ TradPed + SRPed, data = big)
summary(Step1)
summary(Step2)
anova(Step1, Step2)
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
big <- readRDS("ReC.rds")
str(big)
ValuedVars <- c("ValObjectives", "IncrUnderstanding", "IncrInterest")
TradPedVars <- c("ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation")
SRPedVars <- c("InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
big$Valued <- sjstats::mean_n(big[, ValuedVars], .66)
big$TradPed <- sjstats::mean_n(big[, TradPedVars], .75)
big$SRPed <- sjstats::mean_n(big[, SRPedVars], .75)
Total <- c("ValObjectives", "IncrUnderstanding", "IncrInterest", "ClearResponsibilities", "EffectiveAnswers", "Feedback", "ClearOrganization", "ClearPresentation", "InclusvClassrm", "EquitableEval", "MultPerspectives", "DEIintegration")
big$Total <- sjstats::mean_n(big[, Total], .80)
View(big)
apaTables::apa.cor.table(big[c("Valued", "TradPed", "SRPed", "OvInstructor")], filename="ReC_cortable.doc", table.number = 1, show.sig.stars=TRUE, landscape=TRUE)
cocor::cocor(formula = ~Valued + OvInstructor | TradPed + OvInstructor, data = big)
cocor::cocor(formula = ~TradPed + OvInstructor | SRPed + OvInstructor, data = big)
cocor::cocor(formula = ~Valued + OvInstructor | SRPed + OvInstructor, data = big)
big <- na.omit(big)
Step1 <- lm(Valued ~ TradPed, data = big)
summary(Step1)
options(scipen=999)
summary(Step1)
big <- na.omit(big)#included b/c there was uneven missingness and the subsequent comparison required equal sample sizes in the regression models
Step1 <- lm(Valued ~ TradPed, data = big)
Step2 <- lm(Valued ~ TradPed + SRPed, data = big)
summary(Step1)
summary(Step2)
anova(Step1, Step2)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
Szymanski_generating_model <- '
#measurement model
CollegeResponse  =~ .88*cold + .73*unresponsive + .73*supportive
Stigma =~ .86*negative + .76*heterosexism + .71*harassed
Victimization =~ .8*Vic1 + .8*Vic2 + .8*Vic3 + .8*Vic4 + .8*Vic5 + .8*Vic6 + .8*Vic7 + .8*Vic8 + .8*Vic9
CollSat =~ .8*Sat1 + .8*Sat2 + .8*Sat3 + .8*Sat4 + .8*Sat5
Persistence =~ .69*graduation_importance + .63*right_decision + .62*will_register + .59*not_graduate + .45*undecided + .44*grades_unimportant
Anxiety =~ .851*nervous + .887*worry_control + .894*much_worry + 674*cant_relax + .484*restless + .442*irritable + 716*afraid
Depression =~ .798*anhedonia + .425*down +  .591*sleep +  .913*lo_energy +  .441*appetite +  .519*selfworth +  .755*concentration +  .454*too_slowfast + .695*s_ideation
#Means
CollegeResponse ~ 2.71*1
Stigma ~3.61*1
Victimization ~ 0.11*1
CollSat ~ 5.61*1
Persistence ~ 4.41*1
Anxiety ~ 1.45*1
Depression ~1.29*1
#Correlations
CollegeResponse ~~ .58*Stigma
CollegeResponse ~~ -.25*Victimization
CollegeResponse ~~  -.59*CollSat
CollegeResponse ~~  -.29*Persistence
CollegeResponse ~~  .17*Anxiety
CollegeResponse ~~  .18*Depression
Stigma ~~ .37*Victimization
Stigma ~~  -.41*CollSat
Stigma ~~  -.19*Persistence
Stigma ~~  .27*Anxiety
Stigma ~~  .24*Depression
Victimization ~~  -.22*CollSat
Victimization ~~  -.04*Persistence
Victimization ~~  .23*Anxiety
Victimization ~~  .21*Depression
CollSat ~~  .53*Persistence
CollSat ~~  -.29*Anxiety
CollSat ~~  -.32*Depression
Persistence ~~  -.22*Anxiety
Persistence ~~  -.26*Depression
Anxiety ~~  .76*Depression
'
set.seed(240218)
dfSzy <- lavaan::simulateData(model = Szymanski_generating_model,
model.type = "sem",
meanstructure = T,
sample.nobs=646,
standardized=FALSE)
#used to retrieve column indices used in the rescaling script below
View(dfSzy)
#used to retrieve column indices used in the rescaling script below
col_index <- as.data.frame(colnames(dfSzy))
View(dfSzy)
View(col_index)
for(i in 1:ncol(dfSzy)){
if(i >= 1 & i <= 6){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 7 & i <= 15){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 16 & i <= 20){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 7))
}
if(i >= 21 & i <= 26){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(1, 5))
}
if(i >= 27 & i <= 33){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
if(i >= 34 & i <= 42){
dfSzy[,i] <- scales::rescale(dfSzy[,i], c(0, 3))
}
}
library(tidyverse)
dfSzy <- dfSzy %>% round(0)
library(tidyverse)
dfSzy <- dfSzy %>% round(0)
View(dfSzy)
dfSzy <- dfSzy %>%
dplyr::mutate(supportiveNR = 8 - supportive)
dfSzy <- dfSzy %>%
dplyr::mutate(not_graduateNR = 8 - not_graduate)%>%
dplyr::mutate(undecidedNR = 8 - undecided)%>%
dplyr::mutate(grades_unimportantNR = 8 - grades_unimportant)
dfSzy <- dplyr::select(dfSzy, -c(supportive, not_graduate, undecided, grades_unimportant))
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
saveRDS(dfSzy, "SzyDF.rds")
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
#saveRDS(dfSzy, "SzyDF.rds")
#bring back the simulated dat from an .rds file
dfSzy <- readRDS("SzyDF.rds")
#write the simulated data  as a .csv
write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#write the simulated data  as a .csv
#write.table(dfSzy, file="SzyDF.csv", sep=",", col.names=TRUE, row.names=FALSE)
#bring back the simulated dat from a .csv file
dfSzy <- read.csv("SzyDF.csv", header = TRUE)
View(dfSzy)
dfSzy<- dfSzy %>%
dplyr::mutate(unsupportive = 8 - supportiveNR) #scaling 1 to 7; so we subtract from 8
psych::describe(dfSzy)
View(dfSzy)
dfSzy<- dfSzy %>%
dplyr::mutate(unsupportive = 8 - supportiveNR) #scaling 1 to 7; so we subtract from 8
psych::describe(dfSzy)
View(dfSzy)
dfSzy<- dfSzy %>%
dplyr::mutate(unsupportive = 8 - supportiveNR) #scaling 1 to 7; so we subtract from 8
#psych::describe(dfSzy)
View(dfSzy)
LGBTQvars <- c('cold', 'unresponsive', 'negative', 'heterosexism', 'harassed', 'unsupportive')
ResponseVars <- c('cold', 'unresponsive', 'unsupportive')
Stigmavars <- c('negative', 'heterosexism', 'harassed')
dfSzy$Total <- sjstats::mean_n(dfSzy[, LGBTQvars], .80)#will create the mean for each individual if 80% of variables are present (this means there must be at least 5 of 6)
dfSzy$Response <- sjstats::mean_n(dfSzy[, ResponseVars], .66)#will create the mean for each individual if 66% of variables are present (in this case 1 variable can be missing)
dfSzy$Stigma <- sjstats::mean_n(dfSzy[, Stigmavars], .66)#will create the mean for each individual if 66% of variables are present (in this case 1 variable can be missing)
View(dfSzy)
LGBTQ <- dplyr::select(dfSzy, cold, unresponsive, unsupportive, negative, heterosexism, harassed)
Response <- dplyr::select(dfSzy, cold, unresponsive, unsupportive)
Stigma <- dplyr::select(dfSzy, negative, heterosexism, harassed)
View(LGBTQ)
View(Response)
View(Stigma)
LGBTQalpha <- psych::alpha(LGBTQ)#Although unnecessary, I have saved the output as objects because I will use the objects to create a table
LGBTQalpha
minus_harassed <- dplyr::select(dfSzy, cold, unresponsive, unsupportive, negative, heterosexism)
View(minus_harassed)
psych::alpha(minus_harassed)
RESPalpha <- psych::alpha(Response)
RESPalpha
STIGalpha <- psych::alpha(Stigma)
STIGalpha
View(dfSzy)
apaTables::apa.cor.table(dfSzy[c("cold", "unresponsive", "unsupportive", "Stigma")])
apaTables::apa.cor.table(dfSzy[c("negative", "heterosexism", "harassed", "Response")])
big <- readRDS("ReC.rds")
View(big)
library(tidyverse)
items <- big%>%
dplyr::select (ValObjectives, IncrUnderstanding, IncrInterest, ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, MultPerspectives, InclusvClassrm, DEIintegration,EquitableEval)
View(items)
str(items)
psych::alpha(items)
Valued_vars <- c('ValObjectives', 'IncrUnderstanding', 'IncrInterest')
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers', 'Feedback', 'ClearOrganization', 'ClearPresentation')
SCRPed_vars <- c('MultPerspectives', 'InclusvClassrm', 'DEIintegration','EquitableEval')
psych::alpha(items[,Valued_vars])
psych::alpha(items[,TradPed_vars])
psych::alpha(items[,SCRPed_vars])
items$Valued <- sjstats::mean_n(items[,Valued_vars], .75)
items$TradPed <- sjstats::mean_n(items[,TradPed_vars], .75)
items$SCRPed <- sjstats::mean_n(items[,SCRPed_vars], .75)
items$Total <- sjstats::mean_n(items, .75)
apaTables::apa.cor.table(items[c('ValObjectives', 'IncrUnderstanding', 'IncrInterest', 'TradPed')])
apaTables::apa.cor.table(items[c('ValObjectives', 'IncrUnderstanding', 'IncrInterest', 'SCRPed')])
apaTables::apa.cor.table(items[c('ClearResponsibilities', 'EffectiveAnswers', 'Feedback', 'ClearOrganization', 'ClearPresentation', 'Valued')])
apaTables::apa.cor.table(items[c('ClearResponsibilities', 'EffectiveAnswers', 'Feedback', 'ClearOrganization', 'ClearPresentation', 'SCRPed')])
apaTables::apa.cor.table(items[c('MultPerspectives', 'InclusvClassrm', 'DEIintegration','EquitableEval', 'Valued')])
apaTables::apa.cor.table(items[c('MultPerspectives', 'InclusvClassrm', 'DEIintegration','EquitableEval', 'TradPed')])
